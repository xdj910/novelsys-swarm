{
  "scan_metadata": {
    "timestamp": "20250922_140508",
    "scan_version": "v5.0",
    "completion_status": "complete",
    "semantic_modules": 10,
    "extraction_fields": 17
  },
  "statistics": {
    "total_components": 69,
    "commands": 12,
    "coordinators": 10,
    "agents": 47,
    "critical_violations": 4,
    "major_violations": 7,
    "minor_violations": 0,
    "orphan_patterns": 141
  },
  "components": [
    {
      "name": "architecture-test",
      "description": "Execute Claude Code architecture standardization validation tests for system stability and compliance",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\architecture-test.md",
      "component_type": "command",
      "line_count": 163,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Execute Claude Code architecture standardization validation tests for system stability and compliance",
        "argument-hint": "<test-type>"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "description: Execute Claude Code architecture standardization validation tests for system stability ",
        "Execute comprehensive Claude Code architecture validation tests to verify recursion protection, arch",
        "This command executes a comprehensive architecture test suite through a coordinator-managed workflow",
        "3. Complete all phases for full architecture validation",
        "### Architecture Validation Test Execution"
      ],
      "violations": [
        "MAJOR: Command exceeds 120 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references"
      ]
    },
    {
      "name": "art-brainstorm",
      "description": "Setup new article type with strategy development",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\art-brainstorm.md",
      "component_type": "command",
      "line_count": 76,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Setup new article type with strategy development",
        "argument-hint": "[type_name] or no arguments to see available types"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "subagent"
      ],
      "business_logic": [
        "This command initiates the strategic brainstorming process for new article types or manages existing",
        "Use the art-workflow-coordinator subagent to orchestrate the interactive brainstorming workflow.",
        "- Routing decision: Direct to article creation if ready",
        "## Brainstorming Workflow Components",
        "**Strategic Development Process (Phase 1):**"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": []
    },
    {
      "name": "art",
      "description": "Smart article creation with type routing",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\art.md",
      "component_type": "command",
      "line_count": 85,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Smart article creation with type routing",
        "argument-hint": "[topic] or no arguments to continue current work"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "coordinator",
        "subagent"
      ],
      "business_logic": [
        "4. Routes to appropriate workflow phase",
        "For new article creation, use the art-workflow-coordinator subagent to orchestrate the complete 9-ph",
        "- Language requirement: All outputs must be in English",
        "- Citation requirement: All sources must include precise URLs",
        "## Business Context Preservation"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": []
    },
    {
      "name": "brainstorm",
      "description": "Interactive brainstorming system for writing projects",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\brainstorm.md",
      "component_type": "command",
      "line_count": 89,
      "has_unicode": true,
      "yaml_frontmatter": {
        "name": "brainstorm",
        "description": "Interactive brainstorming system for writing projects"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [
          "- Project management is **optional** - system works without it",
          "- Falls back gracefully if project-manager unavailable",
          "- Preserves all existing brainstorm-coordinator functionality",
          "- Compatible with existing knowledge_base structure"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator"
      ],
      "business_logic": [
        "4. Process user input",
        "This ensures existing workflows continue to work while adding project management as an optional enha"
      ],
      "violations": [
        "CRITICAL: Contains Unicode characters"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "coordinator_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references"
      ]
    },
    {
      "name": "continue",
      "description": "Quickly resume work on the most recent project",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\continue.md",
      "component_type": "command",
      "line_count": 124,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "continue",
        "description": "Quickly resume work on the most recent project"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator"
      ],
      "business_logic": [
        "### Step 3: Route to Appropriate Workflow",
        "2. Correct workflow routing: 100%"
      ],
      "violations": [
        "MAJOR: Command exceeds 120 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "coordinator_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": []
    },
    {
      "name": "human-in-loop-test",
      "description": "Test human-in-the-loop workflow with sequential agent execution and approval points",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\human-in-loop-test.md",
      "component_type": "command",
      "line_count": 82,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Test human-in-the-loop workflow with sequential agent execution and approval points",
        "argument-hint": "<test-scenario>"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Test human-in-the-loop workflow with sequential agent execution and approval points",
        "Test the 5-layer architecture with human approval points in sequential agent execution.",
        "This command tests human-in-the-loop workflows where:",
        "- Human approval required at key decision points",
        "- `simple` - Single approval point"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "coordinator_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "undefined_template_variables"
      ]
    },
    {
      "name": "multi-coordinator-test",
      "description": "Test multi-coordinator collaboration in complex scenarios",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\multi-coordinator-test.md",
      "component_type": "command",
      "line_count": 117,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Test multi-coordinator collaboration in complex scenarios",
        "argument-hint": "<complexity> <data-size>"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "Test a Command calling multiple Coordinators in collaboration, validating complex multi-phase task p",
        "- Analyzes requirements and creates execution plan",
        "- Task -> test-data-parser-agent (process input data)",
        "- Task -> test-data-analyzer-agent (analyze processed data)",
        "**Phase 3: Collaboration Validation**"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "undefined_template_variables"
      ]
    },
    {
      "name": "parallel-test",
      "description": "Execute real parallel execution test to validate Claude Code concurrent capabilities",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\parallel-test.md",
      "component_type": "command",
      "line_count": 70,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Execute real parallel execution test to validate Claude Code concurrent capabilities",
        "argument-hint": "<test-mode>"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "- **Architecture Validation**: Claude Code supports real parallel execution",
        "This test validates the core Claude Code architecture principle that agents can execute independentl"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "undefined_template_variables",
        "potential_broken_references"
      ]
    },
    {
      "name": "python-pipeline-test",
      "description": "Test Python script pipeline through multiple agents with data transformation",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\python-pipeline-test.md",
      "component_type": "command",
      "line_count": 86,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Test Python script pipeline through multiple agents with data transformation",
        "argument-hint": "<data-size>"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": [
          "- [ ] Agent 1 Python script generates data successfully",
          "- [ ] Agent 2 Python script reads and transforms data",
          "- [ ] Agent 3 Python script analyzes transformed data",
          "- [ ] Data flows correctly through pipeline",
          "- [ ] No data loss between stages",
          "- [ ] Final output readable by Main Claude",
          "- Original data statistics from Agent 1",
          "- Transformation summary from Agent 2",
          "- Analysis results from Agent 3",
          "- Pipeline execution metrics"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "pipeline",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "This command tests a data processing pipeline where:",
        "### Python Pipeline Test Workflow"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "coordinator_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references"
      ]
    },
    {
      "name": "test-auto-registry",
      "description": "Test automatic registry update integration",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\test-auto-registry.md",
      "component_type": "command",
      "line_count": 62,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Test automatic registry update integration",
        "argument-hint": "no arguments needed"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "subagent"
      ],
      "business_logic": [
        "Use the art-workflow-coordinator subagent to generate a sample execution plan and verify:",
        "## Validation Criteria",
        "This test confirms the automatic registry update system eliminates manual intervention requirements."
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": []
    },
    {
      "name": "validate-trigger-words",
      "description": "Scan all components for potential trigger word issues",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\validate-trigger-words.md",
      "component_type": "command",
      "line_count": 30,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Scan all components for potential trigger word issues"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "coordinator_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": []
    },
    {
      "name": "system-check",
      "description": "Run comprehensive system health check and architecture analysis",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/commands\\novel\\system-check.md",
      "component_type": "command",
      "line_count": 49,
      "has_unicode": false,
      "yaml_frontmatter": {
        "description": "Run comprehensive system health check and architecture analysis"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "Performs complete system architecture analysis, compliance validation, and health assessment.",
        "- Comprehensive CLAUDE.md compliance validation",
        "- Complete I/O patterns, execution contexts, and business logic",
        "Analyze system health requirements and create execution plan for three-phase analysis:",
        "- Phase 2: Architecture analysis with full ComponentMetadata - I/O patterns, prompts, execution cont"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "direct_delegation",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling"
      ]
    },
    {
      "name": "art-workflow-coordinator",
      "description": "Orchestrates the complete 9-phase article production workflow",
      "tools": "Read, Write, Bash, Grep",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Central workflow orchestration without execution - planning only",
      "file_path": ".claude/agents\\art-workflow-coordinator.md",
      "component_type": "coordinator",
      "line_count": 903,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-workflow-coordinator",
        "description": "Orchestrates the complete 9-phase article production workflow",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Central workflow orchestration without execution - planning only",
        "model": "claude-sonnet-4-20250514"
      },
      "io_spec": {
        "input_requirements": [
          "- Orchestration request: article creation, brainstorming, or status check",
          "- Article topic: user-provided subject or \"continue current work\"",
          "- Registry context: current system state and work progress",
          "- Action type: new_article, continue_work, setup_type, or status_check",
          "- Working directory context: base path for relative path resolution"
        ],
        "file_reads": [
          "- `.claude/data/articles/registry.json` - System state and work tracking",
          "- `.claude/data/articles/{type}/strategy/` - Article type configurations",
          "- `.claude/data/articles/{type}/content/{article}/metadata.json` - Current work progress",
          "- `.claude/data/articles/ARTICLE_WORKFLOW_DETAIL.md` - Phase specifications and requirements",
          "- Structured JSON execution plan in response text",
          "- Phase-specific agent tasks and requirements",
          "- AUTOMATIC registry update tasks included in every phase plan",
          "- Path templates with working directory context for Main Claude to resolve",
          "- Quality checkpoints and success criteria",
          "---",
          "- **Phase 0**: System initialization (one-time setup) - Handled by Main Claude directly",
          "- **Phase 1**: Brainstorming & strategy development (per type)",
          "- **Phase 2**: Article initiation & folder structure creation",
          "- **Phase 3**: Research collection with materials integration (Phase 3A: materials check, Phase 3B: research agents)",
          "- **Phase 4**: Content creation (article writing)",
          "- **Phase 5**: Quality review (fact-checking + scoring)",
          "- **Phase 6**: Revision cycle (human-in-loop decisions)",
          "- **Phase 7**: Visual production (image generation guides)",
          "- **Phase 8**: Platform optimization (3 platform versions)",
          "- **Phase 9**: Publishing (multi-platform deployment)",
          "- Article progress tracking never falls behind",
          "- System state remains consistent",
          "- Statistics are updated in real-time",
          "- Zero manual intervention required",
          "- Check registry.json for system status",
          "- Identify current work progress",
          "- Determine article type configuration",
          "- Map status to phase number (0-9)",
          "- Identify next required actions",
          "- Check for blocking conditions",
          "- Return JSON plan for next phase actions",
          "- Specify agent requirements and tasks",
          "- AUTOMATICALLY include registry update task",
          "- Include working directory context and path templates",
          "- Include quality checkpoints",
          "- **Standard pattern**: `.claude/data/articles/{article_type}/strategy/voice_guide.md`",
          "- **Relative from article directory**: `../../../strategy/voice_guide.md`",
          "- **No multiple search paths**: Single, predictable location only",
          "- **Error handling**: Plans specify exact path, agents error if not found",
          "- Bulletproof path resolution",
          "- Easy debugging when missing",
          "- Consistent across all phases",
          "- No complex search logic needed",
          "- Phase completion percentages",
          "- Quality threshold compliance (85/100 minimum)",
          "- Agent deliverable verification",
          "- Human approval checkpoint management",
          "- AUTOMATIC registry state consistency (NEW)",
          "- Citation format compliance throughout pipeline",
          "- **Voice guide standardization success (NEW v2.0)**",
          "- **Materials integration effectiveness (NEW v3.0)**",
          "- `{article_type_dir}` = `.claude/data/articles/{type}`",
          "- `{article_dir}` = `.claude/data/articles/{type}/content/{article_id}`",
          "- `{strategy_dir}` = `../../../strategy` (relative to working_directory)",
          "- `{agent_outputs_dir}` = `agent_outputs` (relative to working_directory) **NEW**",
          "- `{user_materials_dir}` = `user_materials` (relative to working_directory) **NEW**",
          "- `{processed_dir}` = `processed` (relative to working_directory) **NEW**",
          "- `{drafts_dir}` = `drafts` (relative to working_directory)",
          "- `{reports_dir}` = `reports` (relative to working_directory)",
          "- `{visuals_dir}` = `visuals` (relative to working_directory)",
          "- `{published_dir}` = `published` (relative to working_directory)",
          "- **Always**: `../../../strategy/voice_guide.md` (relative to article directory)",
          "- **No variations**: Single path only, no search alternatives",
          "- **Agent expectation**: Voice guide MUST exist at this exact location",
          "- **User materials**: `user_materials/` (user drop zone)",
          "- **Processed insights**: `processed/materials_insights.md` (system analysis)",
          "- **Research outputs**: `agent_outputs/` (system research with materials integration)",
          "- Replace template variables with actual paths",
          "- Provide full working_directory to agents",
          "- Pass resolved paths to agents in prompts",
          "- EXECUTE registry_update task automatically after main tasks",
          "- **Verify voice guide exists at standard path before calling agents**",
          "- **Check for user materials and process if found (Phase 3A)**",
          "- Agents receive working_directory from Main Claude",
          "- All file paths are relative to working_directory",
          "- Voice guide always at `../../../strategy/voice_guide.md`",
          "- Materials insights available at `processed/materials_insights.md` when present",
          "- Research agents output to `agent_outputs/` not `research/` **BREAKING CHANGE**",
          "- No hardcoded paths in agent logic",
          "- Article path: {resolved article directory}",
          "- Update context: {specific phase completion context}",
          "- `execution_order: \"after_main_tasks\"` - Execute after phase work completes",
          "- `execution_order: \"immediate\"` - Execute immediately (for completion phases)",
          "- Every plan includes `\"required\": true` for registry updates",
          "- Main Claude MUST execute the registry update as part of standard workflow",
          "- No human memory or intervention needed - it's built into the plan",
          "- Check user_materials/ directory for any files",
          "- Process readable formats (MD, TXT, JSON, CSV)",
          "- Extract insights and create integration guide",
          "- Handle missing materials gracefully without blocking",
          "- Research agents read processed materials insights first",
          "- Prioritize user-provided data and themes",
          "- Verify claims from user materials with additional sources",
          "- Fill gaps identified in materials analysis",
          "- Output to agent_outputs/ for clear separation",
          "- Phase 3A completes instantly with \"no materials found\"",
          "- Phase 3B proceeds with standard web research",
          "- All downstream phases work identically",
          "- No workflow disruption or blocking",
          "- **User research priority**: User materials insights get top priority",
          "- **Enhanced research**: Web research builds upon user foundation",
          "- **Quality improvement**: Better articles with user domain expertise",
          "- **Clear separation**: user_materials/ (user), processed/ (analysis), agent_outputs/ (system)"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Orchestration request: article creation, brainstorming, or status check",
          "- Article topic: user-provided subject or \"continue current work\"",
          "- Registry context: current system state and work progress",
          "- Action type: new_article, continue_work, setup_type, or status_check",
          "- Working directory context: base path for relative path resolution"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "pipeline",
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "name: art-workflow-coordinator",
        "description: Orchestrates the complete 9-phase article production workflow",
        "thinking: Central workflow orchestration without execution - planning only",
        "### Input Requirements",
        "- `.claude/data/articles/ARTICLE_WORKFLOW_DETAIL.md` - Phase specifications and requirements"
      ],
      "violations": [
        "MAJOR: Agent exceeds 500 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "brainstorm-coordinator",
      "description": "Interactive brainstorming coordinator that guides users through type-specific writing exploration",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Manage interactive brainstorming sessions, present choices, save state, route to appropriate workflows based on content type selection",
      "file_path": ".claude/agents\\brainstorm-coordinator.md",
      "component_type": "coordinator",
      "line_count": 547,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "brainstorm-coordinator",
        "description": "Interactive brainstorming coordinator that guides users through type-specific writing exploration",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Manage interactive brainstorming sessions, present choices, save state, route to appropriate workflows based on content type selection"
      },
      "io_spec": {
        "input_requirements": [
          "- \"Guide brainstorming session. Current input: start. Session state: new. Project ID: none\"",
          "- \"Guide brainstorming session. Current input: start. Session state: new. Project ID: 20250117_143022_mystery\"",
          "- \"Guide brainstorming session. Current input: 4. Session state: exists. Project ID: 20250117_143022_mystery\"",
          "- \"Guide brainstorming session. Current input: continue. Session state: exists. Project ID: 20250117_143022_mystery\""
        ],
        "file_reads": [
          "- Use `storage_mode: \"legacy\"`",
          "- All features work normally",
          "- State saves to `knowledge_base/brainstorm/`",
          "- No project management features",
          "- Read `.claude/data/articles/registry/article_types.json`",
          "- If types exist and are active, offer choice",
          "- Otherwise go to general article flow",
          "- Market research for [genre]",
          "- Audience analysis for [demographic]",
          "- Voice development for [style]"
        ],
        "file_writes": [],
        "output_format": [
          "- If `project_id` != \"none\" AND `storage_mode` == \"project\": Save to `.claude/data/projects/{project_id}/brainstorm/`",
          "- Otherwise: Save to `knowledge_base/brainstorm/`",
          "- If no state file exists for \"continue\", offer to start new",
          "- If invalid input, re-prompt with clarification",
          "- If session corrupted, offer recovery or fresh start",
          "-> Main Claude",
          "-> research agents",
          "-> knowledge_base/[type]/",
          "- Clear navigation through choices",
          "- State properly saved and recovered",
          "- Smooth transition to research phase",
          "- User feels guided but not constrained",
          "- brainstorm_output.json successfully generated",
          "- Exploration depth >= 0.6 overall",
          "- At least one area depth >= 0.5 (research ready)"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- \"Guide brainstorming session. Current input: start. Session state: new. Project ID: none\"",
          "- \"Guide brainstorming session. Current input: start. Session state: new. Project ID: 20250117_143022_mystery\"",
          "- \"Guide brainstorming session. Current input: 4. Session state: exists. Project ID: 20250117_143022_mystery\"",
          "- \"Guide brainstorming session. Current input: continue. Session state: exists. Project ID: 20250117_143022_mystery\""
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator"
      ],
      "business_logic": [
        "thinking: Manage interactive brainstorming sessions, present choices, save state, route to appropria",
        "### Input Requirements",
        "For novel/series types, can transition to full research workflow:",
        "\"trend-analyzer for market validation\",",
        "\"decision_count\": 12,"
      ],
      "violations": [
        "MAJOR: Agent exceeds 500 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "research-coordinator",
      "description": "Use PROACTIVELY when conversation mentions writing project, story ideas, book planning, novel development, or \"I want to write\" - orchestrates PROGRESSIVE research workflow by analyzing current state and suggesting next logical steps",
      "tools": "Read, Write, Bash, Grep",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Analyze conversation context and research progress to suggest 1-2 most relevant next steps, not comprehensive plans. Support user-guided exploration with clear rationale for suggestions. Enable back-tracking and direction changes.",
      "file_path": ".claude/agents\\research-coordinator.md",
      "component_type": "coordinator",
      "line_count": 440,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "research-coordinator",
        "description": "Use PROACTIVELY when conversation mentions writing project, story ideas, book planning, novel development, or \"I want to write\" - orchestrates PROGRESSIVE research workflow by analyzing current state and suggesting next logical steps",
        "thinking": "Analyze conversation context and research progress to suggest 1-2 most relevant next steps, not comprehensive plans. Support user-guided exploration with clear rationale for suggestions. Enable back-tracking and direction changes.",
        "tools": "Read, Write, Bash, Grep",
        "model": "claude-sonnet-4-20250514"
      },
      "io_spec": {
        "input_requirements": [
          "- What user has mentioned about their project",
          "- Any research already completed",
          "- User's apparent interests and preferences",
          "- Signals about direction (broad vs focused)",
          "- Questions or uncertainties expressed"
        ],
        "file_reads": [
          "- Previous research sessions (if any exist)",
          "- Current project files and documentation",
          "- Uses Bash to check research state safely"
        ],
        "file_writes": [
          "- Returns guidance directly to Main Claude (not saved as file)",
          "- Includes next step suggestions with rationale",
          "- None (coordinator only returns guidance)"
        ],
        "output_format": [
          "- Calculate value to current exploration state",
          "- Estimate effort required",
          "- Assess user readiness",
          "- Consider alternative paths",
          "- Provide clear rationale",
          "- Why this step now?",
          "- How does it build on current state?",
          "- What decision will it enable?",
          "- What alternatives exist?",
          "- How much effort is involved?",
          "- Market-focused path (commercial viability)",
          "- Creative-focused path (story development)",
          "- Craft-focused path (writing skills)",
          "- Hybrid approaches",
          "- Switching research focus",
          "- Going broader or narrower",
          "- Changing pace",
          "- Exploring alternatives",
          "- Taking breaks and resuming",
          "- Suggest broad, low-effort exploration",
          "- Focus on sparking interest and ideas",
          "- Provide multiple direction options",
          "- Emphasize discovery over decisions",
          "- \"Explore what's trending in your genre of interest\"",
          "- \"Look at successful books similar to your ideas\"",
          "- \"Generate story concepts around your themes\"",
          "- Suggest targeted, specific research",
          "- Focus on decision-enabling information",
          "- Provide depth in chosen areas",
          "- Support commitment to direction",
          "- \"Deep dive into your target audience preferences\"",
          "- \"Research specific market opportunities in your niche\"",
          "- \"Develop detailed voice options for your style\"",
          "- Present clear options with rationale",
          "- Provide comparison frameworks",
          "- Support decision-making process",
          "- Maintain option flexibility",
          "- \"Compare market size vs competition for your options\"",
          "- \"Test voice approaches with sample writing\"",
          "- \"Research specific vs broad audience targeting\"",
          "- **Input**: Current conversation + exploration state",
          "- **Processing**: Assess position, determine best next steps",
          "- **Output**: 1-2 step suggestions with rationale and alternatives",
          "- **Flow**: Continuous guidance loop, not batch execution",
          "- **Never overwhelm with comprehensive plans** (progressive only)",
          "- **Never execute agents** (guidance only, no Task tool)",
          "- **Never decide for user** (always provide choice and rationale)",
          "- **Never force direction** (support exploration and changes)",
          "- **Never assume user commitment** (meet them where they are)",
          "- **Assess exploration state** accurately from conversation context",
          "- **Suggest logical next steps** with clear value proposition",
          "- **Provide helpful rationale** for each suggestion",
          "- **Support direction changes** and backtracking",
          "- **Maintain exploration momentum** without overwhelming",
          "- **Enable user control** of their research journey",
          "- User feels guided but not overwhelmed",
          "- Next steps feel logical and valuable",
          "- User maintains control of direction",
          "- Exploration builds naturally",
          "- Decisions are well-informed",
          "- Research leads to action"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- What user has mentioned about their project",
          "- Any research already completed",
          "- User's apparent interests and preferences",
          "- Signals about direction (broad vs focused)",
          "- Questions or uncertainties expressed"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "batch",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Use PROACTIVELY when conversation mentions writing project, story ideas, book planning,",
        "- **Decision Point Recognition** - Know when user needs to choose direction",
        "### Input Requirements",
        "\"user_benefit\": \"Make informed decisions about genre viability\"",
        "\"decision_guidance\": {"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "system-check-coordinator",
      "description": "Orchestrates comprehensive system health check with complete architecture analysis",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Plan comprehensive system health check execution - determine timestamp and report paths, validate environment setup, design three-phase execution plan for scanning analysis and reporting, ensure proper data flow between agents, handle error cases gracefully, and return detailed JSON plan for Main Claude to execute",
      "file_path": ".claude/agents\\system-check-coordinator.md",
      "component_type": "coordinator",
      "line_count": 311,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "system-check-coordinator",
        "description": "Orchestrates comprehensive system health check with complete architecture analysis",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Plan comprehensive system health check execution - determine timestamp and report paths, validate environment setup, design three-phase execution plan for scanning analysis and reporting, ensure proper data flow between agents, handle error cases gracefully, and return detailed JSON plan for Main Claude to execute"
      },
      "io_spec": {
        "input_requirements": [
          "- **From Main Claude**:",
          "- Request for system health check",
          "- Optional: specific focus areas or components"
        ],
        "file_reads": [
          "- **Plans to read**: System structure via agents",
          "- **Plans to write**: Reports via agents"
        ],
        "file_writes": [],
        "output_format": [
          "- **Returns to Main Claude**: JSON execution plan",
          "- **Plan includes**: Agent tasks, sequencing, paths, success criteria",
          "- Use current time: new Date().toISOString().replace(/[-:T]/g, '').slice(0,14)",
          "- Format: YYYYMMDDHHMMSS (e.g., 20250114153045)",
          "- Ensures concurrent execution safety",
          "- Base: `.claude/report/[actual_timestamp]/`",
          "- Files: scan data (JSON), analysis results (JSON), final report (Markdown)",
          "- Assume required agents exist (system-scanner, system-analyzer, system-reporter)",
          "- Assume .claude/report/ directory is writable",
          "- Return plan assuming no blocking conditions",
          "- Sequential phases (each depends on previous)",
          "- Clear data flow between phases",
          "- Error handling at each step",
          "- system-scanner: Complete system scanning",
          "- system-analyzer: Relationship and compliance analysis",
          "- system-reporter: Human-readable report generation",
          "- All paths relative to working directory",
          "- Consistent timestamp usage",
          "- Clear input/output mappings",
          "- **Never use Task tool** (I don't have it - prevents recursion)",
          "- **Never call other agents** (only Main Claude can do this)",
          "- **Never execute commands** (only plan them)",
          "- **Never read/write files directly** (only plan for agents to do it)",
          "- **Analyze requirements** thoroughly",
          "- **Design execution strategy** with proper sequencing",
          "- **Return structured JSON plans** for Main Claude",
          "- **Handle error cases** in planning",
          "- **Ensure data flow** between pipeline stages",
          "-> system-scanner",
          "-> system-analyzer",
          "-> system-reporter",
          "- Component inventory and metrics",
          "- Architecture compliance validation",
          "- Relationship and dependency mapping",
          "- Performance and complexity analysis",
          "- Sequential data flow management",
          "- Error handling and recovery",
          "- Result aggregation and display",
          "- Execution optimization",
          "---"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "pipeline",
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "**PLANNING ONLY** - Analyze system health check requirements and return a comprehensive execution pl",
        "### Input Requirements",
        "- **Plan includes**: Agent tasks, sequencing, paths, success criteria",
        "When invoked, analyze requirements and return a structured execution plan for comprehensive system h",
        "\"success_criteria\": \"Complete scan data file created (~1MB) with full semantic extraction\""
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-architecture-coordinator",
      "description": "Orchestrates comprehensive Claude Code architecture validation testing",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Analyze architecture requirements, design validation tests for recursion safety and tool configurations, coordinate test execution sequence, verify compliance criteria, return structured JSON plan",
      "file_path": ".claude/agents\\test-architecture-coordinator.md",
      "component_type": "coordinator",
      "line_count": 237,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-architecture-coordinator",
        "description": "Orchestrates comprehensive Claude Code architecture validation testing",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Analyze architecture requirements, design validation tests for recursion safety and tool configurations, coordinate test execution sequence, verify compliance criteria, return structured JSON plan"
      },
      "io_spec": {
        "input_requirements": [
          "- Test type parameter (full/quick/recursion/architecture/io/compliance)",
          "- Expected test coverage requirements",
          "- Safety and cleanup requirements"
        ],
        "file_reads": [
          "- `.claude/agents/` - To analyze current system architecture",
          "- `.claude/commands/` - To verify command patterns",
          "- READ-ONLY for planning purposes",
          "- Agent assignment: test-environment-setup-agent",
          "- Output indicator: `.claude/testing/environment_ready.flag`",
          "- Directory creation strategy for test isolation",
          "- Component generation for both success and failure scenarios",
          "- Verify no Task tool in any coordinator files",
          "- Verify no Task tool in any agent files",
          "- Confirm only Main Claude can call subagents",
          "- Test command delegation patterns",
          "- Verify layer boundaries and responsibilities",
          "- Check component line limits",
          "- Test atomic write operations",
          "- Verify concurrent read safety",
          "- Validate file-based communication",
          "- Test concurrent agent execution",
          "- Measure efficiency gains",
          "- Verify no race conditions",
          "- Test sequential coordinator execution",
          "- Verify phase dependencies are respected",
          "- Validate data passing between phases",
          "- Main test results from test execution",
          "- I/O pattern test results",
          "- Validation reports from format checking",
          "- Execution logs for detailed analysis",
          "- Multi-coordinator test outputs",
          "- Aggregate all test outcomes",
          "- Calculate overall success metrics",
          "- Identify critical issues and violations",
          "- Generate actionable recommendations",
          "- Executive summary with key metrics",
          "- Detailed results by category",
          "- Performance measurements",
          "- Next steps and improvements",
          "- Primary target: `.claude/testing/temp/` directory only",
          "- Optional: `.claude/testing/fixtures/` if explicitly requested",
          "- Never touch any production directories",
          "- Always preserve test reports for analysis",
          "- Keep framework files for future tests",
          "- Protect all command files absolutely",
          "- Protect all agent files absolutely",
          "- Verify reports are saved before cleanup",
          "- Check all paths start with `.claude/testing/`",
          "- Confirm no production paths in scope",
          "- Log all operations for audit trail",
          "- Confirm temp directory is cleaned",
          "- Verify preserved directories intact",
          "- Validate no production files affected",
          "- Verify no coordinators have Task tool",
          "- Verify no agents have Task tool",
          "- Verify only Main Claude can call subagents",
          "- Each agent has clear I/O boundaries",
          "- No direct agent-to-agent communication",
          "- All data exchange through file system",
          "- Test multiple agents running concurrently",
          "- Verify no race conditions",
          "- Measure efficiency improvement",
          "- Zero recursion violations",
          "- Complete 5-layer architecture compliance",
          "- >50% parallel execution efficiency",
          "- 100% I/O isolation",
          "- Safe cleanup without touching production files",
          "- Have Task tool (would cause recursion)",
          "- Execute tasks directly",
          "- Call other agents",
          "- Write implementation code"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Test type parameter (full/quick/recursion/architecture/io/compliance)",
          "- Expected test coverage requirements",
          "- Safety and cleanup requirements"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "atomic",
        "coordinator",
        "subagent",
        "task tool"
      ],
      "business_logic": [
        "description: Orchestrates comprehensive Claude Code architecture validation testing",
        "thinking: Analyze architecture requirements, design validation tests for recursion safety and tool c",
        "### Input Requirements",
        "- Expected test coverage requirements",
        "- Safety and cleanup requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-content-generation-coordinator",
      "description": "Creates content generation plan based on Phase 1 analysis for multi-coordinator testing",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Analyze Phase 1 requirements, design content generation workflow, coordinate agent tasks and dependencies, handle validation and quality gates",
      "file_path": ".claude/agents\\test-content-generation-coordinator.md",
      "component_type": "coordinator",
      "line_count": 226,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-content-generation-coordinator",
        "description": "Creates content generation plan based on Phase 1 analysis for multi-coordinator testing",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Analyze Phase 1 requirements, design content generation workflow, coordinate agent tasks and dependencies, handle validation and quality gates"
      },
      "io_spec": {
        "input_requirements": [
          "- Phase 1 analysis results",
          "- Content generation requirements"
        ],
        "file_reads": [
          "- `.claude/testing/multi_coordinator_test/phase1_analysis.json` - Phase 1 results",
          "- READ-ONLY for planning purposes",
          "- Verify `.claude/testing/multi_coordinator_test/phase1_analysis.json` is present",
          "- Confirm file is readable and contains valid JSON",
          "- Ensure timestamp indicates recent completion",
          "- Complexity level must be present (simple/complex/advanced)",
          "- Processing strategy must be defined (serial/parallel/distributed)",
          "- Data points count must be specified",
          "- Analysis results must be complete",
          "- Check JSON structure is well-formed",
          "- Validate all expected sections are present",
          "- Confirm no critical data is missing",
          "- All required fields must exist",
          "- Data must be logically consistent",
          "- Phase 1 must report successful completion",
          "- Generate 3 main sections for clarity",
          "- Use basic depth of detail",
          "- Focus on essential information only",
          "- No visualizations needed for simple data",
          "- Streamlined report format",
          "- Create 5 comprehensive sections",
          "- Provide detailed analysis depth",
          "- Include 2 visualizations for key insights",
          "- Balance thoroughness with readability",
          "- Standard report format with all key elements",
          "- Develop 7 detailed sections",
          "- Use comprehensive depth throughout",
          "- Include 4 visualizations for complex data patterns",
          "- Provide exhaustive analysis and insights",
          "- Extended report format with appendices",
          "- Use single-threaded, sequential method",
          "- Assign 1 agent for content generation",
          "- No parallelization needed",
          "- Ensures ordered, consistent output",
          "- Best for maintaining narrative flow",
          "- Employ concurrent execution method",
          "- Utilize 3 agents working in parallel",
          "- Enable parallelization for efficiency",
          "- Sections generated simultaneously",
          "- Merge results into cohesive report",
          "- Implement fully distributed method",
          "- Deploy 5 agents across different tasks",
          "- Maximum parallelization for speed",
          "- Complex coordination of outputs",
          "- Suitable for large-scale content generation",
          "- **Depends on**: test-data-analysis-coordinator (Phase 1)",
          "- **Input**: Phase 1 analysis results",
          "- **Output**: Content generation plan",
          "- **Demonstrates**: Phase dependency handling",
          "- Successful Phase 1 dependency consumption",
          "- Appropriate content structure based on analysis",
          "- Clear generation strategy",
          "- Proper multi-coordinator collaboration",
          "- Ready for execution by agents",
          "- Must verify Phase 1 completion before planning",
          "- Return JSON plans only (not execute)",
          "- Have no Task tool (prevents recursion)",
          "- Cannot call other agents/coordinators",
          "- Demonstrate phase dependency handling"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Phase 1 analysis results",
          "- Content generation requirements",
          "- Output format specifications"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "thinking: Analyze Phase 1 requirements, design content generation workflow, coordinate agent tasks a",
        "### Input Requirements",
        "- Content generation requirements",
        "\"dependency_validation\": {",
        "\"validation_status\": \"verified\","
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-data-analysis-coordinator",
      "description": "Analyzes test requirements and creates data processing plan for multi-coordinator testing",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Analyze test data requirements, design processing workflows for multiple phases, coordinate agent task dependencies, handle error conditions and validation, return structured execution plan",
      "file_path": ".claude/agents\\test-data-analysis-coordinator.md",
      "component_type": "coordinator",
      "line_count": 221,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-data-analysis-coordinator",
        "description": "Analyzes test requirements and creates data processing plan for multi-coordinator testing",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Analyze test data requirements, design processing workflows for multiple phases, coordinate agent task dependencies, handle error conditions and validation, return structured execution plan"
      },
      "io_spec": {
        "input_requirements": [
          "- Task complexity level (simple/complex/advanced)",
          "- Data size parameters (50-500)",
          "- Test context and requirements"
        ],
        "file_reads": [
          "- '.claude/testing/multi_coordinator_test/input.txt' - Test input parameters",
          "- READ-ONLY for analysis purposes",
          "- Require only 1 agent for execution",
          "- Best handled with serial processing",
          "- Estimated completion time: 1 minute",
          "- Suitable for data sizes under 50 items",
          "- Require 3 agents working together",
          "- Benefit from parallel execution",
          "- Estimated completion time: 5 minutes",
          "- Optimal for data sizes 50-300 items",
          "- Require 5 agents for comprehensive processing",
          "- Must use parallel execution for efficiency",
          "- Estimated completion time: 10 minutes",
          "- Necessary for data sizes over 300 items",
          "- Process items one by one in sequence",
          "- Simpler coordination with predictable flow",
          "- Lower resource overhead",
          "- Best for small datasets where parallelization overhead exceeds benefits",
          "- Divide data into batches for parallel processing",
          "- Balance between efficiency and resource usage",
          "- Moderate coordination complexity",
          "- Optimal for medium-sized datasets",
          "- Distribute work across multiple agents",
          "- Maximum parallelization for large datasets",
          "- Higher coordination overhead justified by data volume",
          "- Essential for processing large amounts of data efficiently",
          "- Calculate as data_size  10 MB for working memory",
          "- Accounts for data structures and processing overhead",
          "- Ensures sufficient memory for smooth execution",
          "- Simple tasks: 2 cores (minimal parallel processing)",
          "- Complex/Advanced tasks: 4 cores (maximize parallelization)",
          "- Balances performance with resource availability",
          "- Allocate data_size  5 MB for intermediate files",
          "- Provides space for test artifacts and logs",
          "- Ensures adequate storage for I/O operations",
          "- Simple tasks: 1 thread (serial execution)",
          "- Complex/Advanced tasks: 3 threads (parallel execution)",
          "- Optimizes concurrency without overwhelming the system",
          "- **Input**: Raw test parameters from Main Claude",
          "- **Output**: Analysis plan for next coordinator",
          "- **Next Phase**: test-content-generation-coordinator uses our analysis",
          "- Clear complexity assessment",
          "- Optimal processing strategy selection",
          "- Accurate resource estimation",
          "- Proper phase dependency setup",
          "- Ready for next coordinator consumption",
          "- Return JSON plans only (not execute)",
          "- Have no Task tool (prevents recursion)",
          "- Cannot call other agents/coordinators",
          "- Only analyze and plan, not implement"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Task complexity level (simple/complex/advanced)",
          "- Data size parameters (50-500)",
          "- Test context and requirements"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "batch",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Analyzes test requirements and creates data processing plan for multi-coordinator testi",
        "thinking: Analyze test data requirements, design processing workflows for multiple phases, coordinat",
        "### Input Requirements",
        "- Test context and requirements",
        "\"content\": {\"complexity\": \"complex\", \"processing_mode\": \"comprehensive\"}"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-human-in-loop-coordinator",
      "description": "Orchestrates human-in-the-loop test workflows with approval points and conditional execution",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Design sequential test workflows with human decision points, handle approval/rejection/revision responses through conditional execution planning",
      "file_path": ".claude/agents\\test-human-in-loop-coordinator.md",
      "component_type": "coordinator",
      "line_count": 211,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-human-in-loop-coordinator",
        "description": "Orchestrates human-in-the-loop test workflows with approval points and conditional execution",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Design sequential test workflows with human decision points, handle approval/rejection/revision responses through conditional execution planning"
      },
      "io_spec": {
        "input_requirements": [
          "- Test scenario type (simple/complex/iterative)",
          "- Workflow requirements",
          "- Human interaction preferences"
        ],
        "file_reads": [
          "- Previous workflow state if exists",
          "- `.claude/testing/human_in_loop/workflow_state.json` (if continuing)",
          "- Mark current test phase as completed",
          "- Proceed to next test phase in sequence",
          "- Update test workflow state",
          "- Log test rejection reason",
          "- Terminate test workflow gracefully",
          "- Save final test state for audit",
          "- Capture revision feedback for test",
          "- Re-execute current test phase with modifications",
          "- Track test revision count",
          "- Prevent infinite loops (max 3 revisions)",
          "- I only return test plans, don't execute",
          "- I have no Task tool (prevents recursion)",
          "- Main Claude handles actual test execution",
          "- Human interaction happens at Main Claude level",
          "- Test state persists through file system",
          "- Sequential test agent execution with human approval",
          "- Conditional branching based on test responses",
          "- Test state persistence across interactions",
          "- Revision loops with feedback in testing",
          "- 5-layer architecture preservation in test environment"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Test scenario type (simple/complex/iterative)",
          "- Workflow requirements",
          "- Human interaction preferences"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Orchestrates human-in-the-loop test workflows with approval points and conditional exec",
        "thinking: Design sequential test workflows with human decision points, handle approval/rejection/rev",
        "### Input Requirements",
        "- Workflow requirements",
        "- Previous workflow state if exists"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-parallel-coordinator",
      "description": "Orchestrates real parallel execution testing with multiple agents",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-parallel-coordinator.md",
      "component_type": "coordinator",
      "line_count": 189,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-parallel-coordinator",
        "description": "Orchestrates real parallel execution testing with multiple agents",
        "tools": "Read, Write, Bash, Grep"
      },
      "io_spec": {
        "input_requirements": [
          "- Parallel test execution request",
          "- Performance threshold requirements (default: >50% efficiency gain)",
          "- Test duration parameters"
        ],
        "file_reads": [
          "- `.claude/agents/test-parallel-agent-*.md` - Available parallel test agents",
          "- READ-ONLY for planning purposes",
          "- **True Concurrency**: Agent start times overlap (not sequential)",
          "- **Performance Gain**: Parallel completion significantly faster than serial",
          "- **File Safety**: No corruption during concurrent file access",
          "- **Independence**: Each agent produces unique, valid results",
          "- Serial baseline: ~3x individual agent time",
          "- Parallel execution: ~1.2x individual agent time",
          "- Efficiency gain: 60-70%",
          "- Overlapping timestamps in agent logs",
          "- No file corruption or conflicts"
        ],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Parallel test execution request",
          "- Performance threshold requirements (default: >50% efficiency gain)",
          "- Test duration parameters"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Performance threshold requirements (default: >50% efficiency gain)",
        "\"success_criteria\": {",
        "4. Planning performance analysis and validation",
        "4. **Concurrency Validation**: Verify agents ran simultaneously, not sequentially"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-python-pipeline-coordinator",
      "description": "Orchestrates Python script pipeline test with sequential data processing",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Plan sequential Python script execution through multiple agents with data transformation",
      "file_path": ".claude/agents\\test-python-pipeline-coordinator.md",
      "component_type": "coordinator",
      "line_count": 82,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-python-pipeline-coordinator",
        "description": "Orchestrates Python script pipeline test with sequential data processing",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Plan sequential Python script execution through multiple agents with data transformation"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "pipeline",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Orchestrates Python script pipeline test with sequential data processing",
        "\"pipeline_type\": \"sequential_data_processing\",",
        "\"success_criteria\": {"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-article-initiator",
      "description": "Creates article folder structure and initializes metadata for new articles",
      "tools": "Read, Write, Bash",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "",
      "file_path": ".claude/agents\\art-article-initiator.md",
      "component_type": "agent",
      "line_count": 451,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-article-initiator",
        "description": "Creates article folder structure and initializes metadata for new articles",
        "tools": "Read, Write, Bash",
        "model": "claude-haiku-3-5-20241022"
      },
      "io_spec": {
        "input_requirements": [
          "- Topic: User-provided article subject",
          "- Article type: Target article category (e.g., \"ai_realist\")",
          "- Working directory: Base path for article creation",
          "- Strategy context: Reference to completed strategy files"
        ],
        "file_reads": [
          "- `strategy/strategy_v1.0.md` - Article type configuration",
          "- `strategy/voice_guide.md` - Voice and style requirements"
        ],
        "file_writes": [
          "- `content/{article_id}/metadata.json` - Complete article metadata with materials workflow",
          "- `content/{article_id}/user_materials/README.md` - User guidance for materials",
          "- `content/{article_id}/user_materials/` - Empty directory for user materials",
          "- `content/{article_id}/processed/` - Empty directory for processed materials",
          "- `content/{article_id}/agent_outputs/` - Empty directory for system research",
          "- `content/{article_id}/drafts/` - Empty directory for article drafts",
          "- `content/{article_id}/reports/` - Empty directory for quality reports",
          "- `content/{article_id}/visuals/` - Empty directory for visual production",
          "- `content/{article_id}/published/` - Empty directory for platform versions",
          "- `metadata.json.tmp` for atomic metadata creation",
          "- `README.md.tmp` for atomic README creation"
        ],
        "output_format": [
          "- Success message with article ID",
          "- Full path to created article directory",
          "- Confirmation of 7 subdirectories created (including materials directories)",
          "- Metadata initialization status with materials workflow",
          "- User materials README creation confirmation",
          "- Article ID generated in format: YYYYMMDD_HHMMSS_topic_slug",
          "- All 7 subdirectories exist and accessible",
          "- metadata.json contains valid JSON with materials workflow tracking",
          "- user_materials/README.md created with clear user instructions",
          "- Status set to \"initiated\" and phase set to \"research\"",
          "- Materials workflow initialized in metadata",
          "- Clear error type and failed operation",
          "- Specific path or file that caused failure",
          "- Actionable recovery suggestions"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Topic: User-provided article subject",
          "- Article type: Target article category (e.g., \"ai_realist\")",
          "- Working directory: Base path for article creation",
          "- Strategy context: Reference to completed strategy files"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "**Creates complete article folder structure and initializes metadata.json for new articles with prop",
        "- **Metadata Initialization** - Populates metadata.json with all required fields including citation ",
        "- **Article Workflow Standards** - Understands complete 9-phase workflow structure",
        "### Step 1: Input Processing (with Defensive Handling)",
        "- Read `strategy/voice_guide.md` for voice requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-article-writer",
      "description": "Create complete article draft integrating user materials and comprehensive research findings",
      "tools": "Read, Write",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Comprehensive article writing, research synthesis, user materials integration, voice consistency, statistical foundation, citation compliance",
      "file_path": ".claude/agents\\art-article-writer.md",
      "component_type": "agent",
      "line_count": 422,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-article-writer",
        "description": "Create complete article draft integrating user materials and comprehensive research findings",
        "tools": "Read, Write",
        "model": "claude-sonnet-4-20250514",
        "thinking": "Comprehensive article writing, research synthesis, user materials integration, voice consistency, statistical foundation, citation compliance"
      },
      "io_spec": {
        "input_requirements": [
          "- Article topic and target specifications",
          "- Research integration requirements: synthesize all research findings",
          "- Voice consistency mandate: strict adherence to voice guide",
          "- Quality standards: word count (2000 +/-10%), structure, data integration",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: prioritize user materials insights throughout article"
        ],
        "file_reads": [
          "- `processed/materials_insights.md` - User materials analysis (when available) **NEW**",
          "- `agent_outputs/trends.md` - market trends and statistical foundation **NEW PATH**",
          "- `agent_outputs/audience.md` - target audience psychology and pain points **NEW PATH**",
          "- `agent_outputs/competitors.md` - competitive landscape and differentiation opportunities **NEW PATH**",
          "- `agent_outputs/topic.md` - comprehensive topic exploration and expert perspectives **NEW PATH**",
          "- `../../../strategy/strategy_v1.0.md` - content strategy and positioning guidance",
          "- `../../../strategy/voice_guide.md` - voice, tone, and style specifications (STANDARD LOCATION)",
          "- `metadata.json` - article type, topic, and production requirements"
        ],
        "file_writes": [
          "- `drafts/v1_draft.md` - complete article draft with proper structure, materials integration, and formatting"
        ],
        "output_format": [
          "- Article completion status with word count achieved",
          "- Materials integration summary (user insights featured, prioritization effectiveness)",
          "- Research integration summary (statistics used, examples included)",
          "- Voice consistency self-assessment score",
          "- Content quality evaluation and areas for potential enhancement",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- **Always**: `../../../strategy/voice_guide.md` (relative to article directory)",
          "- **No variations**: Single path only, no search alternatives",
          "- **CRITICAL**: Voice guide MUST exist at this exact location for proper article tone",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "---",
          "- **Materials-First Integration** - Prioritize and seamlessly weave user insights throughout article",
          "- **Research Synthesis** - Combine multiple research sources into coherent narrative",
          "- **Voice Consistency** - Maintain brand voice and tone throughout content",
          "- **Structural Writing** - Create well-organized, engaging article structure",
          "- **Data Integration** - Incorporate statistics and evidence naturally",
          "- **Content Strategy** - Understanding audience-driven content creation",
          "- **Research Integration** - Synthesizing multiple data sources effectively",
          "- **Voice and Style** - Maintaining consistent brand communication",
          "- **Article Structure** - Creating engaging, scannable content formats",
          "- **Citation Management** - Proper inline attribution and source integration",
          "- Key insights and themes to feature prominently",
          "- User-provided data and statistics to prioritize",
          "- Specific angles and perspectives to emphasize",
          "- Expert opinions and quotes to highlight",
          "- Strategic positioning and unique value propositions",
          "- Hook featuring user insight or unique angle",
          "- Problem/opportunity from user materials perspective",
          "- Preview of user-backed solutions/insights",
          "- Lead with user insight or data",
          "- Support with research validation",
          "- Enhance with additional context",
          "- Cite both user and web sources",
          "- Build on user foundation",
          "- Add complementary research",
          "- Maintain user insight prominence",
          "- Research insights that complement user materials",
          "- Fill gaps not covered in user materials",
          "- Provide broader market/industry context",
          "- Synthesize user insights with research findings",
          "- Emphasize unique value from user perspective",
          "- Call to action aligned with user positioning",
          "---",
          "- Word Count: [actual count] (Target: 2000 +/-10%)",
          "- Statistics Included: [count] (User materials: X, Research: Y)",
          "- Materials Integration: [prominent/supporting/none]",
          "- Voice Consistency: [X%] (Target: 90%+)",
          "- Primary themes from user materials: [list]",
          "- User statistics prominently featured: [count]",
          "- User expert quotes highlighted: [count]",
          "- Strategic positioning from user insights: [description]",
          "- Research sources supporting user insights: [count]",
          "- Additional context provided by research: [areas]",
          "- Data validation for user claims: [verification status]",
          "- Gaps filled by research: [areas]",
          "- User insights prominence: [high/medium/low]",
          "- Research support quality: [strong/adequate/weak]",
          "- Narrative flow coherence: [excellent/good/needs work]",
          "- Overall integration success: [rating]",
          "- **Input**: Receive working directory and requirements from Main Claude",
          "- **Materials Priority**: Read processed/materials_insights.md first if available",
          "- **Research Integration**: Synthesize all research from agent_outputs/",
          "- **Voice Compliance**: Strict adherence to ../../../strategy/voice_guide.md",
          "- **Output**: Save comprehensive article to drafts/v1_draft.md",
          "- **Status**: Report materials integration effectiveness and quality metrics",
          "- **Never use Task tool** (prevents recursion)",
          "- **Never ignore user materials** when available",
          "- **Never compromise voice consistency** (90%+ requirement)",
          "- **Never skip statistical requirements** (minimum 10 statistics)",
          "- **Never call other agents** (Main Claude orchestrates)",
          "- **Materials-first integration** when user research is available",
          "- **Seamless research synthesis** from multiple agent outputs",
          "- **Perfect voice consistency** using standardized voice guide path",
          "- **Strategic content positioning** based on user insights",
          "- **High-quality article creation** meeting all requirements",
          "- **Graceful adaptation** between materials/no-materials workflows"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Article topic and target specifications",
          "- Research integration requirements: synthesize all research findings",
          "- Voice consistency mandate: strict adherence to voice guide",
          "- Quality standards: word count (2000 +/-10%), structure, data integration",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: prioritize user materials insights throughout article"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Research integration requirements: synthesize all research findings",
        "- `processed/materials_insights.md` - User materials analysis (when available) **NEW**",
        "- `metadata.json` - article type, topic, and production requirements",
        "### Language & Citation Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-audience-analyst",
      "description": "Analyze target audience psychology and information needs with user materials integration",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Deep audience psychology analysis, demographic research, pain point identification, engagement patterns, user materials integration, behavioral insights",
      "file_path": ".claude/agents\\art-audience-analyst.md",
      "component_type": "agent",
      "line_count": 383,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-audience-analyst",
        "description": "Analyze target audience psychology and information needs with user materials integration",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Deep audience psychology analysis, demographic research, pain point identification, engagement patterns, user materials integration, behavioral insights"
      },
      "io_spec": {
        "input_requirements": [
          "- Target audience focus: specific demographic or psychographic segments",
          "- Article topic context: subject matter for audience relevance",
          "- Audience analysis scope: broad demographic or focused behavioral analysis",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "file_reads": [
          "- `processed/materials_insights.md` - User materials analysis (when available)",
          "- `../../../strategy/strategy_v1.0.md` - target audience definition and goals",
          "- `../../../strategy/voice_guide.md` - communication preferences",
          "- `metadata.json` - topic and article type context",
          "- Web sources for audience research and behavioral data"
        ],
        "file_writes": [
          "- `agent_outputs/audience.md` - comprehensive audience analysis report with materials integration"
        ],
        "output_format": [
          "- Audience profile completeness percentage",
          "- Materials integration status and effectiveness",
          "- Pain point analysis summary with count",
          "- Engagement strategy recommendations",
          "- Content customization suggestions",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "---",
          "- **Audience Psychology Analysis** - Deep behavioral and motivational insights",
          "- **Demographic Research** - Statistical and geographic audience mapping",
          "- **User Materials Integration** - Prioritize and build upon user-provided audience insights",
          "- **Pain Point Identification** - Specific challenges and frustrations analysis",
          "- **Engagement Pattern Analysis** - Content consumption and interaction behaviors",
          "- **Market Research** - Audience segmentation and profiling methodologies",
          "- **Behavioral Psychology** - Understanding decision-making and motivation patterns",
          "- **Digital Analytics** - Online engagement and consumption patterns",
          "- **Content Strategy** - Audience-content alignment optimization",
          "- **Communication Science** - Effective messaging and persuasion techniques",
          "- Audience insights and demographic data from user research",
          "- User-identified pain points and challenges",
          "- Behavioral patterns noted in user materials",
          "- Specific audience segments highlighted by user",
          "- Engagement preferences and communication styles",
          "- Integration of user materials insights with audience research",
          "- Key audience segments identified and their characteristics",
          "- Primary pain points and engagement opportunities",
          "- Key audience insights from user research that were prioritized",
          "- Verification status of user-provided demographic data",
          "- How web research enhanced user audience understanding",
          "- User insight: [summary from materials]",
          "- Demographic verification: [web research confirmation]",
          "- Behavioral enhancements: [additional research insights]",
          "- Engagement patterns: [enhanced with web research]",
          "- Segment description: [comprehensive analysis]",
          "- Demographic profile: [detailed characteristics]",
          "- Behavioral patterns: [research-backed insights]",
          "- Content preferences: [engagement analysis]",
          "- Content format preferences",
          "- Communication channel optimization",
          "- Timing and frequency recommendations",
          "- Persuasion and motivation triggers",
          "- User materials integration approach (if applicable)",
          "- Web research strategy and sources",
          "- Data validation methods",
          "- Source reliability assessment",
          "- Most important audience segments from user materials",
          "- Verification status and confidence levels",
          "- Recommended content focus areas",
          "- Additional audience insights that support user findings",
          "- Behavioral context and psychological triggers",
          "- Engagement optimization recommendations",
          "- Areas where user materials were incomplete",
          "- Additional demographic and behavioral context",
          "- Audience perspectives user materials may have missed",
          "- How to best address identified audience segments",
          "- Which pain points deserve primary focus",
          "- Engagement tactics for maximum impact",
          "- **Input**: Receive working directory and topic from Main Claude",
          "- **Materials Check**: Read processed/materials_insights.md if available",
          "- **Processing**: Integrate user insights with comprehensive audience research",
          "- **Output**: Save enhanced audience analysis to agent_outputs/audience.md",
          "- **Status**: Report materials integration status and research completeness",
          "- **Never use Task tool** (prevents recursion)",
          "- **Never ignore user materials** when available",
          "- **Never output to old research/ directory** (use agent_outputs/)",
          "- **Never skip verification** of user-provided audience data",
          "- **Never call other agents** (Main Claude orchestrates)",
          "- **Seamless materials integration** when user audience data is available",
          "- **Comprehensive audience research** with psychological foundation",
          "- **Demographic verification and validation** of all audience claims",
          "- **Strategic synthesis** of user insights and behavioral research",
          "- **Clear integration guidance** for content optimization",
          "- **Graceful degradation** when no materials are available"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Target audience focus: specific demographic or psychographic segments",
          "- Article topic context: subject matter for audience relevance",
          "- Audience analysis scope: broad demographic or focused behavioral analysis",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- **Materials integration**: process user materials insights when available",
        "- `processed/materials_insights.md` - User materials analysis (when available)",
        "### Language & Citation Requirements",
        "- **Behavioral Psychology** - Understanding decision-making and motivation patterns"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-competitor-scanner",
      "description": "Scan competitive content landscape for gaps and opportunities with user materials integration",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Competitive content analysis, market gap identification, differentiation opportunities, user materials integration, strategic positioning research",
      "file_path": ".claude/agents\\art-competitor-scanner.md",
      "component_type": "agent",
      "line_count": 388,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-competitor-scanner",
        "description": "Scan competitive content landscape for gaps and opportunities with user materials integration",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Competitive content analysis, market gap identification, differentiation opportunities, user materials integration, strategic positioning research"
      },
      "io_spec": {
        "input_requirements": [
          "- Topic area: specific competitive landscape to analyze",
          "- Content type focus: articles, videos, research, whitepapers",
          "- Competitive scope: direct competitors, adjacent markets, or comprehensive analysis",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "file_reads": [
          "- `processed/materials_insights.md` - User materials analysis (when available)",
          "- `../../../strategy/strategy_v1.0.md` - competitive positioning strategy",
          "- `metadata.json` - topic and competitive context",
          "- Web sources for competitive content analysis"
        ],
        "file_writes": [
          "- `agent_outputs/competitors.md` - comprehensive competitive analysis report with materials integration"
        ],
        "output_format": [
          "- Number of competitors analyzed and content diversity assessment",
          "- Materials integration status and competitive positioning insights",
          "- Content gaps identified with opportunity sizing",
          "- Differentiation recommendations based on competitive landscape",
          "- Market positioning insights and strategic opportunities",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "---",
          "- **Competitive Content Analysis** - Comprehensive content landscape mapping",
          "- **Market Gap Identification** - Specific content opportunities and white spaces",
          "- **User Materials Integration** - Prioritize and build upon user-provided competitive insights",
          "- **Differentiation Strategy** - Unique positioning and angle development",
          "- **Strategic Positioning** - Market context and competitive advantages",
          "- **Content Strategy** - Understanding content positioning and differentiation",
          "- **Market Intelligence** - Competitive landscape analysis methodologies",
          "- **Digital Marketing** - Content performance and engagement analysis",
          "- **Business Strategy** - Market positioning and competitive advantages",
          "- **SEO and Content Discovery** - Finding and analyzing competitive content",
          "- Competitive insights and market analysis from user research",
          "- User-identified competitors and positioning",
          "- Content gaps and opportunities noted by user",
          "- Strategic advantages or differentiators highlighted",
          "- Market context and competitive threats",
          "- Integration of user materials insights with competitive research",
          "- Key competitors identified and their content strategies",
          "- Primary content gaps and differentiation opportunities",
          "- Key competitive insights from user research that were prioritized",
          "- Verification status of user-provided competitive data",
          "- How web research enhanced user competitive understanding",
          "- User insight: [summary from materials]",
          "- Competitive verification: [web research confirmation]",
          "- Content strategy analysis: [enhanced research insights]",
          "- Positioning assessment: [enhanced with web research]",
          "- Competitor description: [comprehensive analysis]",
          "- Content strategy: [detailed strategy analysis]",
          "- Market positioning: [research-backed insights]",
          "- Strengths and weaknesses: [competitive assessment]",
          "- Unique positioning angles",
          "- Underserved content areas",
          "- Strategic advantages to leverage",
          "- Market white spaces identified",
          "- Content strategy positioning",
          "- Competitive advantage tactics",
          "- Market entry opportunities",
          "- Risk mitigation strategies",
          "- User materials integration approach (if applicable)",
          "- Web research strategy and sources",
          "- Competitive analysis methods",
          "- Source reliability assessment",
          "- Most important competitive insights from user materials",
          "- Verification status and confidence levels",
          "- Recommended differentiation focus areas",
          "- Additional competitive insights that support user findings",
          "- Market context and strategic positioning",
          "- Content gap opportunities for exploitation",
          "- Areas where user materials were incomplete",
          "- Additional competitive context and analysis",
          "- Market perspectives user materials may have missed",
          "- How to best differentiate from identified competitors",
          "- Which content gaps deserve primary focus",
          "- Competitive advantages to emphasize",
          "- **Input**: Receive working directory and topic from Main Claude",
          "- **Materials Check**: Read processed/materials_insights.md if available",
          "- **Processing**: Integrate user insights with comprehensive competitive research",
          "- **Output**: Save enhanced competitive analysis to agent_outputs/competitors.md",
          "- **Status**: Report materials integration status and research completeness",
          "- **Never use Task tool** (prevents recursion)",
          "- **Never ignore user materials** when available",
          "- **Never output to old research/ directory** (use agent_outputs/)",
          "- **Never skip verification** of user-provided competitive data",
          "- **Never call other agents** (Main Claude orchestrates)",
          "- **Seamless materials integration** when user competitive data is available",
          "- **Comprehensive competitive research** with strategic foundation",
          "- **Competitive verification and validation** of all positioning claims",
          "- **Strategic synthesis** of user insights and market intelligence",
          "- **Clear differentiation guidance** for content positioning",
          "- **Graceful degradation** when no materials are available"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Topic area: specific competitive landscape to analyze",
          "- Content type focus: articles, videos, research, whitepapers",
          "- Competitive scope: direct competitors, adjacent markets, or comprehensive analysis",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- **Materials integration**: process user materials insights when available",
        "- `processed/materials_insights.md` - User materials analysis (when available)",
        "### Language & Citation Requirements",
        "- **Business Strategy** - Market positioning and competitive advantages"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-fact-checker",
      "description": "Verify all factual claims, data accuracy, and logical consistency in articles",
      "tools": "Read, Write, WebSearch",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Verify factual claims systematically, validate sources and statistics, cross-reference data points including user materials, identify potential inaccuracies, generate pass fail assessments",
      "file_path": ".claude/agents\\art-fact-checker.md",
      "component_type": "agent",
      "line_count": 261,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-fact-checker",
        "description": "Verify all factual claims, data accuracy, and logical consistency in articles",
        "tools": "Read, Write, WebSearch",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Verify factual claims systematically, validate sources and statistics, cross-reference data points including user materials, identify potential inaccuracies, generate pass fail assessments"
      },
      "io_spec": {
        "input_requirements": [
          "- Article draft: path to content requiring fact verification",
          "- Research files: supporting materials for cross-reference validation",
          "- Validation level: basic, standard, or rigorous checking depth",
          "- Critical focus areas: specific claims or sections requiring extra attention",
          "- Source priorities: trusted sources for verification preference",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "file_reads": [
          "- `drafts/v1_draft.md` (or latest draft version) - article content to verify",
          "- `agent_outputs/` folder contents - supporting research for cross-reference",
          "- `processed/materials_insights.md` - user materials for additional validation (if available)",
          "- Web sources via WebSearch for independent fact verification",
          "- Previous fact-check reports for consistency across versions"
        ],
        "file_writes": [
          "- `reports/fact_check.md` - comprehensive fact verification report"
        ],
        "output_format": [
          "- Overall fact-check status: PASS/FAIL with critical issue count",
          "- Accuracy percentage and verification confidence level",
          "- Priority correction recommendations ranked by importance",
          "- Source verification summary with credibility assessment",
          "- User materials validation status when applicable",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Research files accessed in local `agent_outputs/` folder",
          "- User materials insights accessed in local `processed/` folder",
          "---",
          "- Verify all numerical claims and statistics",
          "- Cross-reference data with original sources",
          "- Validate data currency and methodology",
          "- Confirm proper attribution and context",
          "- Check user-provided statistics against public sources",
          "- Check all factual assertions against authoritative sources",
          "- Verify expert quotes and attributions",
          "- Validate case studies and examples",
          "- Confirm historical facts and timelines",
          "- Cross-reference user insights with verifiable sources",
          "- Check argument logic and reasoning chains",
          "- Identify contradictions or inconsistencies",
          "- Validate cause-effect relationships",
          "- Assess claim plausibility and evidence strength",
          "- Ensure user materials integration maintains logical consistency",
          "- Evaluate source authority and reliability",
          "- Check for bias or agenda influences",
          "- Verify publication dates and currency",
          "- Assess methodology and research quality",
          "- Evaluate credibility of user-provided sources and insights",
          "- Read article draft completely for context",
          "- Extract all factual claims and assertions",
          "- Identify statistical data and numerical claims",
          "- Map expert quotes and attributions",
          "- Note user insights and materials integration",
          "- Classify claims by verification priority",
          "- Identify high-risk or controversial assertions",
          "- Map claims to available research sources",
          "- Plan verification methodology for each claim type",
          "- Separate user-derived claims for special validation",
          "- Cross-reference claims with agent_outputs files",
          "- Verify statistics match research sources",
          "- Check expert quotes against original research",
          "- Validate examples and case studies from research",
          "- Cross-reference user insights with processed/materials_insights.md",
          "- Verify research source credibility and currency",
          "- Check for potential bias or limitations",
          "- Assess methodology and data quality",
          "- Confirm proper attribution and context",
          "- Evaluate user materials credibility and relevance",
          "- Search for independent verification of key claims",
          "- Cross-reference statistics with original sources",
          "- Verify expert positions and quotes",
          "- Check recent developments or updates",
          "- Validate user-provided data against public sources",
          "- Search for conflicting information or sources",
          "- Assess credibility of conflicting claims",
          "- Identify areas of legitimate debate or uncertainty",
          "- Flag potential accuracy risks",
          "- Check for conflicts between user materials and public sources",
          "- Classify each claim: VERIFIED/UNVERIFIED/DISPUTED",
          "- Calculate overall accuracy percentage",
          "- Identify critical issues requiring correction",
          "- Assess confidence levels for each verification",
          "- Document user materials validation status",
          "- Prioritize corrections by importance and risk",
          "- Provide specific correction language",
          "- Suggest additional sources or verification",
          "- Recommend areas for additional research",
          "- Address any user materials integration issues",
          "- **100% Accuracy Standard**: All verifiable claims must be accurate",
          "- **Source Verification**: All sources checked for credibility and currency",
          "- **Pass/Fail Determination**: Required for human decision process",
          "- **Priority Classification**: Critical vs minor issues clearly identified",
          "- **User Materials Validation**: Cross-reference user insights with verifiable sources",
          "- **Claim Coverage**: 100% of factual assertions checked",
          "- **Source Diversity**: Multiple sources for controversial claims",
          "- **Currency Check**: Data recency validated",
          "- **Credibility Assessment**: Source authority evaluated",
          "- **User Materials Integration**: User insights properly validated",
          "- **PASS**: No critical factual errors, <2% minor inaccuracies, user materials properly validated",
          "- **FAIL**: Any critical factual errors or >5% minor inaccuracies",
          "- **CONDITIONAL**: Correctable issues identified with specific fixes",
          "- **Status:** PASS/FAIL/CONDITIONAL",
          "- **Accuracy Rate:** [Percentage]",
          "- **Critical Issues:** [Count]",
          "- **Minor Issues:** [Count]",
          "- **User Materials Validation:** [Status when applicable]",
          "- **Location:** [Article section/paragraph]",
          "- **Problem:** [Specific inaccuracy]",
          "- **Correction:** [Recommended fix with inline citation]",
          "- **Source:** [Verification source](https://verification-url.com)",
          "- **Location:** Main body, paragraph 3",
          "- **Problem:** States \"15% error rate\" but source shows \"12%\"",
          "- **Correction:** Change to \"12% error rate as documented by [Stanford's AI Safety Study](https://stanford.edu/ai-safety-study)\"",
          "- **Source:** [Original Stanford research](https://stanford.edu/ai-safety-study) (Stanford, 2024)",
          "- Market size: [$21.1 billion verified by Grand View Research](https://www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-healthcare-market)",
          "- Growth rate: [45% projection confirmed by McKinsey](https://www.mckinsey.com/industries/healthcare/our-insights/transforming-healthcare-with-ai)",
          "- Expert quote: [Dr. Smith's position verified via MIT faculty page](https://web.mit.edu/faculty/smith)",
          "- User case study data aligns with [public company reports](https://company-annual-report.com)",
          "- User regulatory insight confirmed by [recent FDA guidance](https://fda.gov/latest-guidance)",
          "- User market data validated against [industry association statistics](https://industry-stats.org)",
          "- User materials provide supporting evidence for 5 article claims",
          "- No contradictions found between user insights and public sources",
          "- User expertise adds credibility to technical explanations",
          "- High credibility: [Stanford Medical School](https://med.stanford.edu), [MIT AI Lab](https://csail.mit.edu)",
          "- Medium credibility: [Industry reports with clear methodology](https://industry-source.com)",
          "- Flagged sources: [Sources requiring additional verification](https://needs-verification.com)",
          "- User materials: [Credibility assessment of user-provided sources and insights]",
          "- [Primary source 1](https://primary-source.com) - for market data verification",
          "- [Primary source 2](https://research-institution.edu) - for academic claims",
          "- [Government source](https://government-agency.gov) - for regulatory information",
          "- [User materials insights](processed/materials_insights.md) - for additional validation",
          "- Working directory provided as absolute path",
          "- Draft files with various naming conventions",
          "- Research folder with multiple file types (agent_outputs/ instead of research/)",
          "- User materials folder and processed insights",
          "- Flexible claim extraction from various content formats",
          "- Verify draft file exists before processing",
          "- Handle missing research files gracefully",
          "- Check for user materials availability before cross-referencing",
          "- Validate web search functionality",
          "- Ensure output directory exists before writing",
          "- Cross-reference all claims with multiple sources when possible",
          "- Document verification confidence levels",
          "- Flag uncertain or disputed claims clearly",
          "- Ensure pass/fail determination is evidence-based",
          "- Validate user materials integration maintains accuracy standards"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Article draft: path to content requiring fact verification",
          "- Research files: supporting materials for cross-reference validation",
          "- Validation level: basic, standard, or rigorous checking depth",
          "- Critical focus areas: specific claims or sections requiring extra attention",
          "- Source priorities: trusted sources for verification preference",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "optional_context": []
      },
      "execution_patterns": [],
      "business_logic": [
        "### Input Requirements",
        "- Research files: supporting materials for cross-reference validation",
        "- Validation level: basic, standard, or rigorous checking depth",
        "- `processed/materials_insights.md` - user materials for additional validation (if available)",
        "- User materials validation status when applicable"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-materials-processor",
      "description": "Processes PDF art materials using enhanced PyMuPDF + PDFPlumber script",
      "tools": "Read, Write, Bash",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Call enhanced Python script for robust PDF processing with proper path handling",
      "file_path": ".claude/agents\\art-materials-processor.md",
      "component_type": "agent",
      "line_count": 234,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-materials-processor",
        "description": "Processes PDF art materials using enhanced PyMuPDF + PDFPlumber script",
        "tools": "Read, Write, Bash",
        "model": "claude-sonnet-4-20250514",
        "thinking": "Call enhanced Python script for robust PDF processing with proper path handling"
      },
      "io_spec": {
        "input_requirements": [
          "- PDF file path: absolute path to PDF file to process",
          "- Processing request: extract text, images, and tables from PDF",
          "- Output directory: where to save processing results",
          "- Optional timeout: processing timeout in minutes (default 30)"
        ],
        "file_reads": [
          "- Input PDF file at specified path",
          "- Enhanced Python script: `.claude/scripts/art-materials-processor-enhanced.py`"
        ],
        "file_writes": [
          "- `{pdf_name}/document.md` - Extracted content in Markdown format",
          "- `{pdf_name}/image_*.png` - Extracted images from PDF",
          "- `{pdf_name}/table_*.png` - Extracted tables as images",
          "- `{pdf_name}/metadata.json` - Processing metadata and statistics"
        ],
        "output_format": [
          "- Processing success/failure status",
          "- Method used (PyMuPDF+PDFPlumber, PyMuPDF-only, or fallback)",
          "- Statistics: text length, images extracted, tables extracted",
          "- Output directory path with processed files",
          "- Processing time and memory usage",
          "---",
          "- Processing method used",
          "- Statistics (text length, images, tables)",
          "- Processing time and memory usage",
          "- Any errors or warnings",
          "- Processing success status",
          "- Method used (PyMuPDF+PDFPlumber preferred)",
          "- Extraction statistics",
          "- File locations for further analysis",
          "- Processing performance metrics",
          "- Text Length: X,XXX characters",
          "- Images Extracted: XX files",
          "- Tables Extracted: XX files",
          "- Total Files Created: XX",
          "- **Windows backslashes**: Script handles path conversion internally",
          "- **Spaces in paths**: Always quote path variables",
          "- **Relative paths**: Convert to absolute when needed",
          "- **Method 1 fails**: Script automatically tries Method 2 (PyMuPDF-only)",
          "- **Method 2 fails**: Script falls back to Method 3 (pdftotext)",
          "- **All methods fail**: Report detailed error information",
          "- **Large PDFs**: Script monitors memory usage and optimizes processing",
          "- **Timeout handling**: Script respects timeout limits",
          "- **Memory cleanup**: Automatic garbage collection between pages",
          "- **Enhanced PDF processing** using the latest PyMuPDF + PDFPlumber script",
          "- **Robust fallback handling** with multiple processing methods",
          "- **Windows path compatibility** with proper forward slash usage",
          "- **Performance monitoring** with memory and time tracking",
          "- **Comprehensive extraction** of text, images, and tables",
          "- **Structured output** with metadata and statistics",
          "- **Error recovery** with detailed failure reporting",
          "- **Never use Task tool** (prevents recursion)",
          "- **Never modify original PDF** (read-only processing)",
          "- **Never assume paths work** (always validate first)",
          "- **Never ignore failures** (always check exit codes and provide details)",
          "- **Never call other agents** (Main Claude orchestrates)"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- PDF file path: absolute path to PDF file to process",
          "- Processing request: extract text, images, and tables from PDF",
          "- Output directory: where to save processing results",
          "- Optional timeout: processing timeout in minutes (default 30)"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "name: art-materials-processor",
        "description: Processes PDF art materials using enhanced PyMuPDF + PDFPlumber script",
        "thinking: Call enhanced Python script for robust PDF processing with proper path handling",
        "### Input Requirements",
        "- PDF file path: absolute path to PDF file to process"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-platform-optimizer",
      "description": "Optimize article content for specific publishing platforms and their unique requirements",
      "tools": "Read, Write",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Analyze platform requirements for Medium Substack ElevenReader, optimize content for each channel with PROPER Medium subtitle and strategic tags, ensure compliance while maintaining message integrity, balance platform constraints with content quality",
      "file_path": ".claude/agents\\art-platform-optimizer.md",
      "component_type": "agent",
      "line_count": 325,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-platform-optimizer",
        "description": "Optimize article content for specific publishing platforms and their unique requirements",
        "tools": "Read, Write",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Analyze platform requirements for Medium Substack ElevenReader, optimize content for each channel with PROPER Medium subtitle and strategic tags, ensure compliance while maintaining message integrity, balance platform constraints with content quality"
      },
      "io_spec": {
        "input_requirements": [
          "- Final article: path to approved, ready-to-publish article content",
          "- Platform targets: specific platforms requiring optimization (Medium, Substack, ElevenReader)",
          "- Language requirement: All content must be in English",
          "- Citation requirement: All sources must use inline hyperlink format",
          "- Optimization level: standard or enhanced platform customization",
          "- Performance goals: specific engagement or reach objectives",
          "- Brand consistency: voice and style requirements to maintain",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "file_reads": [
          "- `drafts/final.md` or `drafts/v*_draft.md` - approved article content (use latest available)",
          "- `strategy/PLATFORM_OPTIMIZATION_STRATEGY.md` - platform-specific optimization guidelines (may be in parent directory)",
          "- `strategy/voice_guide.md` - brand voice consistency requirements (may be in parent directory)",
          "- `metadata.json` - article type and target audience information",
          "- `visuals/visual_production_guide.md` - image placement and specifications (if exists)"
        ],
        "file_writes": [
          "- `published/medium.md` - Medium-optimized version with PROPER subtitle and tags",
          "- `published/substack.md` - Substack-optimized version",
          "- `published/elevenreader.md` - ElevenReader-optimized version"
        ],
        "output_format": [
          "- Platform optimization completion status for all 3 targets",
          "- Compliance verification for platform-specific requirements",
          "- Performance optimization score and expected engagement metrics",
          "- Publishing readiness assessment with any final recommendations",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "- Platform optimization strategy: `../../../strategy/PLATFORM_OPTIMIZATION_STRATEGY.md`",
          "---",
          "- MUST include explanatory subtitle instructions at top of file",
          "- MUST provide exactly 5 strategic tags for Medium discovery",
          "- Tags should be: AI, Enterprise Technology, Digital Transformation, Strategy, Business (or similar strategic variants)",
          "- Subtitle should explain/clarify the main title for Medium readers",
          "- Align content structure with platform discovery algorithms",
          "- Optimize titles and openings for platform-specific engagement patterns",
          "- Implement platform-preferred formatting and organization",
          "- Enhance discoverability through strategic keyword placement",
          "- Adapt reading experience to platform user expectations",
          "- Optimize content length and pacing for platform norms",
          "- Customize call-to-action strategies for platform behaviors",
          "- Enhance engagement through platform-specific interactive elements",
          "- Ensure full compliance with platform content policies",
          "- Optimize formatting for platform publishing tools",
          "- Implement platform-specific SEO and metadata requirements",
          "- Prepare content for platform distribution mechanisms",
          "- Maintain inline hyperlink citations across all platforms",
          "- Ensure all sources use `[descriptive text](https://exact-url.com)` format",
          "- Preserve source credibility and accessibility",
          "- Enhance platform-specific link optimization",
          "- **Title & Subtitle**: CRITICAL - Include subtitle instruction at top of file for Medium editor",
          "- **Subtitle Format**: Clear explanatory subtitle that helps readers understand the title's meaning",
          "- **Strategic Tags**: Exactly 5 tags focusing on: AI, Enterprise Technology, Digital Transformation, Strategy, Business",
          "- **Structure**: Scannable with clear subheadings, bullet points, and short paragraphs",
          "- **Length**: 7-12 minute read (1800-3000 words optimal)",
          "- **Engagement**: Strong opening hook, compelling subtitles, strategic bold text",
          "- **Formatting**: Blockquotes for key insights, numbered lists for actionability",
          "- **SEO**: Keyword-rich title, strategic tags for discovery, compelling subtitle",
          "- **Visual**: Hero image placement, in-line image spacing every 3-4 paragraphs",
          "- **Citations**: Inline hyperlinks optimized for Medium's link handling",
          "- **Primary Tags (choose 5):**",
          "- Artificial Intelligence",
          "- Enterprise Technology",
          "- Digital Transformation",
          "- Business Strategy",
          "- Technology Leadership",
          "- Innovation Management",
          "- AI Strategy",
          "- Business Intelligence",
          "- Tech Leadership",
          "- Strategic Planning",
          "- **Structure**: Newsletter format with personal touch and direct reader address",
          "- **Length**: Email-friendly segments, scannable sections",
          "- **Engagement**: Conversational tone, reader questions, community building",
          "- **Formatting**: Email-optimized line breaks, clear section divisions",
          "- **SEO**: Subject line optimization, preview text enhancement",
          "- **Visual**: Email-safe image formats, strategic visual breaks",
          "- **Citations**: Email-compatible inline links with descriptive text",
          "- **Structure**: Reader-centric format optimized for discovery",
          "- **Length**: Platform-preferred length for maximum reach",
          "- **Engagement**: Community-building elements, reader interaction focus",
          "- **Formatting**: Platform-native formatting requirements",
          "- **SEO**: Platform-specific discovery optimization",
          "- **Visual**: Reader community visual elements, platform-optimized imagery",
          "- **Citations**: Platform-optimized inline hyperlinks for maximum accessibility",
          "- Read PLATFORM_OPTIMIZATION_STRATEGY.md for current guidelines",
          "- Understand voice guide requirements for consistency",
          "- Review metadata for article type and audience context",
          "- Analyze visual production guide for image specifications",
          "- Evaluate final article structure and content quality",
          "- Identify optimization opportunities for each platform",
          "- Map content elements to platform-specific requirements",
          "- Plan customization strategy while maintaining core message",
          "- CREATE explanatory subtitle that clarifies main title",
          "- Add subtitle instruction at top of file for Medium editor",
          "- SELECT exactly 5 strategic tags from approved list",
          "- Optimize title for Medium SEO and engagement",
          "- Structure content with compelling subheadings",
          "- Format for optimal reading experience with visual breaks",
          "- Add platform-specific engagement elements",
          "- Ensure all citations use inline hyperlink format",
          "- Adapt to newsletter format with personal touch",
          "- Optimize for email delivery and mobile reading",
          "- Add community-building elements and reader engagement",
          "- Format for email client compatibility",
          "- Maintain inline citations for email-safe accessibility",
          "- Optimize for platform discovery and reach",
          "- Structure for platform-specific user behavior",
          "- Add reader community engagement elements",
          "- Format for optimal platform performance",
          "- Implement platform-native citation handling",
          "- Verify all versions meet platform content policies",
          "- Confirm formatting compatibility with platform tools",
          "- Validate SEO optimization for each platform",
          "- Ensure visual content placement follows specifications",
          "- VERIFY Medium subtitle and 5 strategic tags included",
          "- Confirm voice guide compliance across all versions",
          "- Validate core message integrity maintained",
          "- Check brand terminology and style consistency",
          "- Ensure value proposition clarity in all versions",
          "---",
          "- 82% of medical AI tools fail in real-world conditions",
          "- [Validation gaps identified](https://mit.edu/validation-study) in current testing methods",
          "- [Cost implications](https://healthcare-economics.com/ai-costs) reach $2.3M per incident",
          "- Title: \"MIT Says 95% of AI Projects Fail. What Should My 5-Person Team Do?\"",
          "- Subtitle: \"Why enterprise failures don't doom your 5-person startup (and what to do instead)\"",
          "- Tags: Artificial Intelligence, Startups, Business Strategy, Technology, Small Business",
          "- Title: \"700 Million People Use ChatGPT. 73% Aren't Working. Your AI Strategy Is Dead Wrong.\"",
          "- Subtitle: \"The hidden productivity crisis that's undermining every AI investment\"",
          "- Tags: Artificial Intelligence, Enterprise Technology, Digital Transformation, Business Strategy, Productivity",
          "- Title: \"McDonald's Lost $300M on AI Voice Ordering. Here's What Your Company Should Learn.\"",
          "- Subtitle: \"The real reasons AI implementations fail and how to avoid the same mistakes\"",
          "- Tags: Artificial Intelligence, Business Strategy, Technology Leadership, Innovation Management, Enterprise Technology",
          "- **100% Policy Compliance**: All content meets platform community guidelines",
          "- **Technical Compatibility**: Formatting works perfectly with platform tools",
          "- **SEO Optimization**: Titles, tags, and metadata optimized for platform discovery",
          "- **Visual Compliance**: Image specifications and placement meet platform requirements",
          "- **Medium Specific**: Subtitle instruction included, exactly 5 strategic tags provided",
          "- **Inline Hyperlinks Only**: No reference lists or bibliography sections",
          "- **Descriptive Link Text**: Clear, descriptive anchor text for all links",
          "- **URL Validity**: All links functional and accessible",
          "- **Platform Optimization**: Links optimized for each platform's handling",
          "- **Engagement Score**: >=85% optimization for platform-specific engagement patterns",
          "- **Discoverability**: Enhanced SEO and algorithmic optimization for each platform",
          "- **Reader Experience**: Platform-optimized formatting and content structure",
          "- **Brand Consistency**: >=95% voice guide compliance across all versions",
          "- **Core Message Integrity**: Essential insights and value maintained across platforms",
          "- **Factual Accuracy**: All statistics and claims preserved accurately",
          "- **Educational Value**: Learning outcomes consistent across platform versions",
          "- **Professional Standards**: High-quality, error-free content on all platforms",
          "- Working directory provided as absolute path",
          "- Strategy files in relative `../../../strategy/` or absolute paths",
          "- Final draft in local `drafts/` folder",
          "- Visual guide in local `visuals/` folder",
          "- Metadata in local directory",
          "- Verify all input files exist before processing",
          "- Handle missing strategy files gracefully",
          "- Validate final article completeness before optimization",
          "- Ensure output directory exists before writing optimized versions",
          "- Cross-reference platform requirements with optimization strategy",
          "- Validate brand voice compliance throughout optimization",
          "- Ensure platform-specific requirements met before completion",
          "- Perform final quality check against all compliance criteria",
          "- VERIFY Medium subtitle and tags are properly formatted",
          "- Regular review of platform algorithm updates",
          "- Adaptation to new platform features and requirements",
          "- Monitoring of platform best practices evolution",
          "- Continuous optimization strategy refinement",
          "- Track optimization effectiveness across platforms",
          "- Gather feedback for strategy refinement",
          "- Adapt techniques based on performance data",
          "- Maintain competitive edge through continuous improvement",
          "- Track performance of different subtitle styles",
          "- Analyze tag effectiveness for discovery",
          "- Monitor engagement patterns with formatted articles",
          "- Refine tag selection based on performance data"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Final article: path to approved, ready-to-publish article content",
          "- Platform targets: specific platforms requiring optimization (Medium, Substack, ElevenReader)",
          "- Language requirement: All content must be in English",
          "- Citation requirement: All sources must use inline hyperlink format",
          "- Optimization level: standard or enhanced platform customization",
          "- Performance goals: specific engagement or reach objectives",
          "- Brand consistency: voice and style requirements to maintain",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "optional_context": []
      },
      "execution_patterns": [],
      "business_logic": [
        "description: Optimize article content for specific publishing platforms and their unique requirement",
        "thinking: Analyze platform requirements for Medium Substack ElevenReader, optimize content for each ",
        "### Input Requirements",
        "- Language requirement: All content must be in English",
        "- Citation requirement: All sources must use inline hyperlink format"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-quality-scorer",
      "description": "Multi-dimensional quality assessment and scoring for article content",
      "tools": "Read, Write",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Evaluate content across 5 dimensions with REALISTIC 95+ scoring standards, calculate weighted scores, analyze strategic alignment with BALANCED voice compliance, identify improvement opportunities, prioritize recommendations by impact including user materials integration assessment",
      "file_path": ".claude/agents\\art-quality-scorer.md",
      "component_type": "agent",
      "line_count": 419,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-quality-scorer",
        "description": "Multi-dimensional quality assessment and scoring for article content",
        "tools": "Read, Write",
        "model": "claude-sonnet-4-20250514",
        "thinking": "Evaluate content across 5 dimensions with REALISTIC 95+ scoring standards, calculate weighted scores, analyze strategic alignment with BALANCED voice compliance, identify improvement opportunities, prioritize recommendations by impact including user materials integration assessment"
      },
      "io_spec": {
        "input_requirements": [
          "- Article draft: path to content requiring quality assessment",
          "- Strategy documents: content strategy and voice guide for alignment checking",
          "- Target metrics: REALISTIC quality thresholds and scoring expectations (95+ target)",
          "- Assessment focus: specific quality dimensions to emphasize",
          "- Comparison baseline: industry standards or previous article benchmarks",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "file_reads": [
          "- `drafts/v1_draft.md` (or latest version) - article content for assessment",
          "- `../../../strategy/strategy_v1.0.md` - content strategy and positioning guidance",
          "- `../../../strategy/voice_guide.md` - voice, tone, and style specifications (STANDARD LOCATION)",
          "- `agent_outputs/` folder contents - research foundation for depth assessment",
          "- `processed/materials_insights.md` - user materials insights for integration assessment (if available)",
          "- `metadata.json` - article type and target requirements"
        ],
        "file_writes": [
          "- `reports/quality_score.md` - comprehensive quality assessment report"
        ],
        "output_format": [
          "- Overall quality score (0-100) with pass/fail determination (95+ target)",
          "- Dimensional scores breakdown across 5 quality categories",
          "- Specific improvement recommendations ranked by impact",
          "- Strategic alignment assessment and brand consistency evaluation",
          "- User materials integration assessment (when applicable)",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- **Primary path**: `../../../strategy/voice_guide.md` (relative to article directory)",
          "- **Absolute pattern**: `.claude/data/articles/{article_type}/strategy/voice_guide.md`",
          "- **Example**: For ai_realist articles -> `.claude/data/articles/ai_realist/strategy/voice_guide.md`",
          "- MUST read voice guide from standard location for scoring",
          "- Voice compliance assessment uses BALANCED interpretation (15/25 points)",
          "- Error if voice guide not found at expected location",
          "- No fallback searching = predictable evaluation",
          "---",
          "- Target 95+ quality scores consistently, not unrealistic 99/100",
          "- Apply BALANCED voice guide interpretation",
          "- Focus on business value and executive appropriateness",
          "- Preserve strategic frameworks and complex business concepts",
          "- Evaluate user materials integration when available",
          "- Information accuracy and completeness",
          "- Research depth and evidence quality",
          "- Logical structure and argument flow",
          "- Unique insights and value delivery",
          "- BALANCED brand voice and tone consistency (15 points - INCREASED)",
          "- Target audience appropriateness",
          "- Content type requirements fulfillment",
          "- Positioning and messaging alignment",
          "- Opening hook effectiveness",
          "- Readability and flow quality",
          "- Visual appeal and scannability",
          "- Call-to-action clarity and persuasiveness",
          "- Grammar, spelling, and syntax accuracy",
          "- Formatting consistency and professionalism",
          "- Length and structure requirements compliance",
          "- Citation format and source quality",
          "- Unique perspective and fresh insights",
          "- Creative presentation and format elements",
          "- Competitive differentiation achievement",
          "- Thought leadership demonstration",
          "- Seamless integration of user insights",
          "- Value addition from user expertise",
          "- Credibility enhancement through user materials",
          "- Preservation of user unique perspectives",
          "- Read article draft completely for holistic assessment",
          "- Analyze content structure and organization",
          "- Evaluate information depth and research integration",
          "- Assess unique value proposition delivery",
          "- Note user materials integration (when present)",
          "- Read voice guide from standard location: `../../../strategy/voice_guide.md`",
          "- Compare content against strategy documents",
          "- Evaluate BALANCED voice guide compliance systematically",
          "- Assess target audience appropriateness",
          "- Check positioning and messaging consistency",
          "- Research integration quality: 0-8 points",
          "- Logical structure and flow: 0-6 points",
          "- Information accuracy and completeness: 0-6 points",
          "- Unique insights and value: 0-5 points",
          "- **BALANCED Voice guide compliance: 0-15 points (INCREASED)**",
          "- Target audience fit: 0-4 points",
          "- Content type compliance: 0-3 points",
          "- Brand positioning alignment: 0-3 points",
          "- Opening hook effectiveness: 0-7 points",
          "- Readability and flow: 0-6 points",
          "- Visual appeal and scannability: 0-6 points",
          "- Call-to-action quality: 0-6 points",
          "- Grammar and syntax: 0-5 points",
          "- Formatting and structure: 0-4 points",
          "- Length requirements: 0-3 points",
          "- Citation quality and format: 0-3 points",
          "- Unique perspective: 0-4 points",
          "- Creative presentation: 0-3 points",
          "- Competitive differentiation: 0-3 points",
          "- Integration quality: 0-4 points (seamless vs forced)",
          "- Value addition: 0-3 points (unique insights provided)",
          "- Credibility enhancement: 0-3 points (user expertise impact)",
          "- Identify lowest-scoring dimensions",
          "- Map specific improvement opportunities",
          "- Assess effort vs impact for each potential fix",
          "- Prioritize recommendations by strategic value",
          "- Evaluate content against business objectives",
          "- Assess competitive positioning achievement",
          "- Map reader value delivery effectiveness",
          "- Identify brand strengthening opportunities",
          "- Evaluate user materials integration effectiveness",
          "- Calculate final weighted score (0-100 + bonus)",
          "- Determine pass/fail status (95+ target)",
          "- Document scoring rationale and evidence",
          "- Create dimensional breakdown visualization",
          "- Rank improvements by impact and effort",
          "- Provide specific actionable guidance",
          "- Map recommendations to quality dimensions",
          "- Estimate potential score improvements",
          "- **EXCELLENT**: Overall score >=95/100 (TARGET STANDARD)",
          "- **GOOD**: Score 90-94 with minor improvements identified",
          "- **PASS**: Score 85-89 with specific improvements required",
          "- **CONDITIONAL**: Score 80-84 with revision needed",
          "- **FAIL**: Score <80 or any critical dimension <60%",
          "- **Target Quality**: 95+ points (consistent target)",
          "- **Good Quality**: 90-94 points (acceptable with minor improvements)",
          "- **Minimum Standard**: 85+ points (requires improvement before approval)",
          "- Content Excellence: >=20/25 points",
          "- Strategic Alignment: >=20/25 points (Voice compliance >=12/15)",
          "- Engagement Factor: >=20/25 points",
          "- Technical Quality: >=12/15 points",
          "- Innovation: >=7/10 points",
          "- User Integration Bonus: Variable based on materials availability",
          "- Blunt but not rude (1.5 points)",
          "- Skeptical but not cynical (1.5 points)",
          "- Data-driven but not boring (1.5 points)",
          "- Helpful but not preachy (1.5 points)",
          "- Sentence rhythm variety (mixing short and longer) (2 points)",
          "- Active voice throughout (1.5 points)",
          "- Present tense for immediacy (1.5 points)",
          "- Maintains business sophistication (1 point)",
          "- Preserves strategic frameworks when valuable (1 point)",
          "- Uses complexity appropriate for C-suite audience (1 point)",
          "- Hook effectiveness and formula application (1 point)",
          "- DON'T penalize individual sentences 16-20 words if they serve business purpose",
          "- DO credit natural rhythm mixing short and longer explanations",
          "- DON'T oversimplify complex business concepts",
          "- DO maintain \"trusted skeptical CTO\" sophistication",
          "- DON'T reduce strategic frameworks to elementary language",
          "- DO preserve business logic and executive-appropriate complexity",
          "- Research Integration: [Score]/8",
          "- Logical Structure: [Score]/6",
          "- Information Accuracy: [Score]/6",
          "- Unique Insights: [Score]/5",
          "- **BALANCED Voice Consistency: [Score]/15** (CRITICAL)",
          "- Tone characteristics: [Score]/6",
          "- Language patterns: [Score]/5",
          "- Executive appropriateness: [Score]/3",
          "- Opening patterns: [Score]/1",
          "- Audience Fit: [Score]/4",
          "- Content Type Compliance: [Score]/3",
          "- Brand Positioning: [Score]/3",
          "- Opening Hook: [Score]/7",
          "- Readability: [Score]/6",
          "- Visual Appeal: [Score]/6",
          "- Call-to-Action: [Score]/6",
          "- Grammar/Syntax: [Score]/5",
          "- Formatting: [Score]/4",
          "- Length Requirements: [Score]/3",
          "- Citation Quality: [Score]/3",
          "- Unique Perspective: [Score]/4",
          "- Creative Presentation: [Score]/3",
          "- Competitive Differentiation: [Score]/3",
          "- Integration Quality: [Score]/4",
          "- Value Addition: [Score]/3",
          "- Credibility Enhancement: [Score]/3",
          "- [List specific voice guide elements successfully applied with BALANCED interpretation]",
          "- [List specific areas needing attention without over-penalizing business complexity]",
          "- [Specific actions to improve voice compliance score while preserving business value]",
          "- Seamless incorporation of user insights: [Assessment]",
          "- Natural flow vs forced insertion: [Evaluation]",
          "- Preservation of user voice while maintaining brand consistency: [Analysis]",
          "- Unique perspectives from user materials: [List key contributions]",
          "- Credibility boost from user expertise: [Assessment of authority enhancement]",
          "- Competitive advantage from user insights: [Differentiation analysis]",
          "- Enhance user insight prominence: [Specific suggestions]",
          "- Improve integration naturalness: [Flow improvement recommendations]",
          "- Leverage user expertise more effectively: [Authority enhancement suggestions]",
          "- Maintains business sophistication appropriate for executives",
          "- Preserves valuable strategic frameworks and concepts",
          "- Achieves realistic 95+ scores consistently",
          "- Balances voice compliance with business value",
          "- Supports \"trusted skeptical CTO\" persona requirements",
          "- Natural flow vs forced insertion",
          "- Preservation of user voice while maintaining brand consistency",
          "- Credibility enhancement through user expertise",
          "- Competitive advantage from user unique insights",
          "- Strategic value of user perspective integration"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Article draft: path to content requiring quality assessment",
          "- Strategy documents: content strategy and voice guide for alignment checking",
          "- Target metrics: REALISTIC quality thresholds and scoring expectations (95+ target)",
          "- Assessment focus: specific quality dimensions to emphasize",
          "- Comparison baseline: industry standards or previous article benchmarks",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "optional_context": []
      },
      "execution_patterns": [],
      "business_logic": [
        "### Input Requirements",
        "- `processed/materials_insights.md` - user materials insights for integration assessment (if availab",
        "- `metadata.json` - article type and target requirements",
        "### Language & Citation Requirements",
        "**Voice Guide Assessment Requirements:**"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-registry-updater",
      "description": "Updates article registry.json during phase transitions",
      "tools": "Read, Write",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "This agent handles registry updates after phase completions - updating current_work status, clearing completed articles, and maintaining statistics. It reads both registry and article metadata to determine appropriate updates.",
      "file_path": ".claude/agents\\art-registry-updater.md",
      "component_type": "agent",
      "line_count": 176,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-registry-updater",
        "description": "Updates article registry.json during phase transitions",
        "tools": "Read, Write",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "This agent handles registry updates after phase completions - updating current_work status, clearing completed articles, and maintaining statistics. It reads both registry and article metadata to determine appropriate updates."
      },
      "io_spec": {
        "input_requirements": [
          "- Article directory path (e.g., \".claude/data/articles/ai_realist/content/20250920_mit_ai_failure_study\")",
          "- Phase completion context (e.g., \"research_completed\", \"article_published\", \"article_failed\")",
          "- Optional: Specific update data (word counts, image counts, platform info)"
        ],
        "file_reads": [
          "- `.claude/data/articles/registry.json` - Current registry state",
          "- `{article_path}/metadata.json` - Article status and phase data"
        ],
        "file_writes": [
          "- `.claude/data/articles/registry.json.tmp` - Updated registry (atomic write pattern)"
        ],
        "output_format": [
          "- Success confirmation with update summary",
          "- Registry state changes applied",
          "- Error details if updates fail",
          "- Load registry.json and article metadata.json",
          "- Determine article type and current status",
          "- Validate data consistency",
          "- Update current_work based on phase transitions",
          "- Clear current_work when articles complete",
          "- Update statistics after major milestones",
          "- Maintain global_stats accuracy",
          "- Clear current_work (same as completion)",
          "- Do NOT update success statistics",
          "- Update last_activity timestamp",
          "- Ensure article path exists",
          "- Verify metadata.json is readable",
          "- Check registry.json exists",
          "- Based on metadata.status and metadata.phase",
          "- Consider the context provided by Main Claude",
          "- Handle edge cases (failures, cancellations)",
          "- Update current_work appropriately",
          "- Calculate new statistics if needed",
          "- Update global_stats",
          "- Set last_activity timestamp",
          "- **Missing files**: Report specific file missing",
          "- **Invalid JSON**: Report parsing errors with line numbers",
          "- **Data inconsistency**: Report conflicts between registry and metadata",
          "- **Write failures**: Preserve original registry, report error details",
          "- Article counts match between type-specific and global stats",
          "- Word counts accurately sum across all articles",
          "- timestamps follow ISO 8601 format",
          "- No orphaned current_work references"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Article directory path (e.g., \".claude/data/articles/ai_realist/content/20250920_mit_ai_failure_study\")",
          "- Phase completion context (e.g., \"research_completed\", \"article_published\", \"article_failed\")",
          "- Optional: Specific update data (word counts, image counts, platform info)"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic"
      ],
      "business_logic": [
        "### Input Requirements",
        "| reviewed | reviewed | revision_decision | Update current_work |",
        "| revised | revised | final_approval | Update current_work |",
        "## Implementation Process"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-topic-explorer",
      "description": "Deep dive exploration of topic subtopics and expert perspectives with user materials integration",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Comprehensive topic exploration, subtopic identification, expert perspective analysis, user materials integration, knowledge synthesis",
      "file_path": ".claude/agents\\art-topic-explorer.md",
      "component_type": "agent",
      "line_count": 387,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-topic-explorer",
        "description": "Deep dive exploration of topic subtopics and expert perspectives with user materials integration",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Comprehensive topic exploration, subtopic identification, expert perspective analysis, user materials integration, knowledge synthesis"
      },
      "io_spec": {
        "input_requirements": [
          "- Main topic: primary subject area for deep exploration",
          "- Exploration scope: breadth vs depth focus for subtopic analysis",
          "- Expert perspective requirements: academic, industry, thought leadership",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "file_reads": [
          "- `processed/materials_insights.md` - User materials analysis (when available)",
          "- `../../../strategy/strategy_v1.0.md` - topic focus and content strategy",
          "- `metadata.json` - main topic and exploration context",
          "- Web sources for comprehensive topic research"
        ],
        "file_writes": [
          "- `agent_outputs/topic.md` - comprehensive topic exploration report with materials integration"
        ],
        "output_format": [
          "- Topic coverage completeness assessment and subtopic count",
          "- Materials integration status and knowledge synthesis effectiveness",
          "- Expert perspectives gathered with credibility assessment",
          "- Knowledge gaps identified and research depth evaluation",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "---",
          "- **Comprehensive Topic Analysis** - Deep exploration of all topic dimensions",
          "- **Subtopic Identification** - Systematic coverage of topic components",
          "- **User Materials Integration** - Prioritize and build upon user-provided knowledge",
          "- **Expert Perspective Research** - Authoritative viewpoints and analysis",
          "- **Knowledge Synthesis** - Comprehensive understanding construction",
          "- **Research Methodology** - Systematic knowledge exploration techniques",
          "- **Information Architecture** - Topic mapping and knowledge organization",
          "- **Expert Source Identification** - Finding authoritative perspectives",
          "- **Knowledge Synthesis** - Combining multiple sources into coherent understanding",
          "- **Academic and Industry Research** - Both theoretical and practical perspectives",
          "- Topic knowledge and expert insights from user research",
          "- User-identified subtopics and knowledge areas",
          "- Expert perspectives and authoritative sources noted",
          "- Knowledge gaps and research directions highlighted",
          "- Specific topic angles and focus areas prioritized",
          "- Integration of user materials insights with expert research",
          "- Key subtopics identified and their interconnections",
          "- Expert perspectives and authoritative insights",
          "- Key topic insights from user research that were prioritized",
          "- Verification status of user-provided knowledge claims",
          "- How web research enhanced user topic understanding",
          "- User insight: [summary from materials]",
          "- Expert verification: [authoritative source confirmation]",
          "- Knowledge enhancement: [additional research insights]",
          "- Current developments: [enhanced with web research]",
          "- Subtopic description: [comprehensive analysis]",
          "- Expert perspectives: [authoritative viewpoints]",
          "- Knowledge depth: [research-backed insights]",
          "- Practical implications: [real-world applications]",
          "- Integrated understanding of topic",
          "- Key insights and implications",
          "- Theoretical and practical perspectives",
          "- Future directions and developments",
          "- Comprehensiveness evaluation",
          "- Knowledge gaps remaining",
          "- Areas for further exploration",
          "- Research quality and depth",
          "- User materials integration approach (if applicable)",
          "- Web research strategy and sources",
          "- Expert source validation methods",
          "- Knowledge synthesis approach",
          "- Most important topic insights from user materials",
          "- Verification status and confidence levels",
          "- Recommended content focus areas",
          "- Additional topic insights that support user findings",
          "- Expert perspectives and authoritative backing",
          "- Knowledge synthesis and integration opportunities",
          "- Areas where user materials were incomplete",
          "- Additional subtopic coverage and depth",
          "- Expert perspectives user materials may have missed",
          "- How to best structure comprehensive topic coverage",
          "- Which subtopics deserve primary focus",
          "- Expert perspectives to emphasize for credibility",
          "- **Input**: Receive working directory and topic from Main Claude",
          "- **Materials Check**: Read processed/materials_insights.md if available",
          "- **Processing**: Integrate user insights with comprehensive topic research",
          "- **Output**: Save enhanced topic analysis to agent_outputs/topic.md",
          "- **Status**: Report materials integration status and research completeness",
          "- **Never use Task tool** (prevents recursion)",
          "- **Never ignore user materials** when available",
          "- **Never output to old research/ directory** (use agent_outputs/)",
          "- **Never skip verification** of user-provided knowledge claims",
          "- **Never call other agents** (Main Claude orchestrates)",
          "- **Seamless materials integration** when user topic knowledge is available",
          "- **Comprehensive topic research** with expert foundation",
          "- **Knowledge verification and validation** of all topic claims",
          "- **Strategic synthesis** of user insights and expert research",
          "- **Clear integration guidance** for comprehensive coverage",
          "- **Graceful degradation** when no materials are available"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Main topic: primary subject area for deep exploration",
          "- Exploration scope: breadth vs depth focus for subtopic analysis",
          "- Expert perspective requirements: academic, industry, thought leadership",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Expert perspective requirements: academic, industry, thought leadership",
        "- **Materials integration**: process user materials insights when available",
        "- `processed/materials_insights.md` - User materials analysis (when available)",
        "### Language & Citation Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-trend-researcher",
      "description": "Research market trends and emerging patterns for article topics with user materials integration",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Research current market trends and emerging patterns, integrate user materials insights, validate data recency and reliability, identify statistical foundations, synthesize insights for content strategy",
      "file_path": ".claude/agents\\art-trend-researcher.md",
      "component_type": "agent",
      "line_count": 382,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-trend-researcher",
        "description": "Research market trends and emerging patterns for article topics with user materials integration",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Research current market trends and emerging patterns, integrate user materials insights, validate data recency and reliability, identify statistical foundations, synthesize insights for content strategy"
      },
      "io_spec": {
        "input_requirements": [
          "- Topic focus: specific subject area for trend analysis",
          "- Target audience context: from strategy documents",
          "- Research scope: broad, focused, or deep analysis level",
          "- Time frame: analysis period (default: last 12 months)",
          "- Industry context: relevant sectors or markets",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "file_reads": [
          "- `processed/materials_insights.md` - User materials analysis (when available)",
          "- `../../../strategy/strategy_v1.0.md` - audience and focus context",
          "- `metadata.json` - topic and article type information",
          "- Web sources via WebSearch and WebFetch tools"
        ],
        "file_writes": [
          "- `agent_outputs/trends.md` - comprehensive trend analysis report with materials integration"
        ],
        "output_format": [
          "- Completion status with trend count and data point summary",
          "- Materials integration status and effectiveness",
          "- Self-assessment of coverage completeness and quality",
          "- Suggestions for additional research areas if gaps identified",
          "- Be written entirely in English",
          "- Use inline hyperlink citations: `[descriptive text](https://exact-url.com)`",
          "- No reference lists or bibliography sections",
          "- Include source year in parentheses when relevant for data: (Source, 2024)",
          "- No mixed language content",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "---",
          "- **Market Trend Analysis** - Identify emerging patterns and market shifts",
          "- **Statistical Research** - Gather quantitative data and metrics",
          "- **User Materials Integration** - Prioritize and build upon user-provided insights",
          "- **Data Validation** - Verify recency and reliability of trend information",
          "- **Competitive Intelligence** - Monitor industry developments and innovations",
          "- **Market Research** - Understanding industry analysis methodologies",
          "- **Data Mining** - Extracting meaningful patterns from multiple sources",
          "- **Trend Forecasting** - Identifying trajectory and impact of emerging trends",
          "- **Statistical Analysis** - Interpreting quantitative market data",
          "- **Source Validation** - Ensuring data quality and reliability",
          "- Key themes and insights from user research",
          "- Data points and statistics already available",
          "- Research gaps identified in materials analysis",
          "- Specific trend areas highlighted by user",
          "- Industry context and focus areas",
          "- Integration of user materials insights with market research",
          "- Key trends identified and their implications",
          "- Statistical foundation and market trajectory",
          "- Key insights from user research that were prioritized",
          "- Verification status of user-provided trends",
          "- How web research enhanced user materials",
          "- User insight: [summary from materials]",
          "- Market verification: [web research confirmation]",
          "- Recent developments: [latest market data]",
          "- Statistics: [enhanced with web research]",
          "- Trend description: [comprehensive analysis]",
          "- Market evidence: [supporting data]",
          "- Growth trajectory: [statistical analysis]",
          "- Industry impact: [implications]",
          "- Strategic opportunities identified",
          "- Market gaps and challenges",
          "- Future trajectory predictions",
          "- User materials integration approach (if applicable)",
          "- Web research strategy and sources",
          "- Data validation methods",
          "- Source reliability assessment",
          "- Most important trends from user materials",
          "- Verification status and confidence levels",
          "- Recommended prominence in article",
          "- Additional trends that support user insights",
          "- Market context and broader implications",
          "- Statistical foundation for claims",
          "- Areas where user materials were incomplete",
          "- Additional context and supporting data",
          "- Market perspective user materials may have missed",
          "- How to best combine user and web insights",
          "- Which trends deserve primary focus",
          "- Statistical support for key arguments",
          "- **Input**: Receive working directory and topic from Main Claude",
          "- **Materials Check**: Read processed/materials_insights.md if available",
          "- **Processing**: Integrate user insights with comprehensive web research",
          "- **Output**: Save enhanced trend analysis to agent_outputs/trends.md",
          "- **Status**: Report materials integration status and research completeness",
          "- **Never use Task tool** (prevents recursion)",
          "- **Never ignore user materials** when available",
          "- **Never output to old research/ directory** (use agent_outputs/)",
          "- **Never skip verification** of user-provided trends",
          "- **Never call other agents** (Main Claude orchestrates)",
          "- **Seamless materials integration** when user research is available",
          "- **Comprehensive market research** with statistical foundation",
          "- **Data verification and validation** of all trend claims",
          "- **Strategic synthesis** of user insights and market intelligence",
          "- **Clear integration guidance** for downstream agents",
          "- **Graceful degradation** when no materials are available"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Topic focus: specific subject area for trend analysis",
          "- Target audience context: from strategy documents",
          "- Research scope: broad, focused, or deep analysis level",
          "- Time frame: analysis period (default: last 12 months)",
          "- Industry context: relevant sectors or markets",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)",
          "- **Materials integration**: process user materials insights when available"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- **Materials integration**: process user materials insights when available",
        "- `processed/materials_insights.md` - User materials analysis (when available)",
        "### Language & Citation Requirements",
        "- **Data Validation** - Verify recency and reliability of trend information"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "art-visual-designer",
      "description": "Design visual elements and create AI generation prompts for article imagery",
      "tools": "Read, Write",
      "model": "claude-haiku-3-5-20241022",
      "thinking": "Analyze content for visual opportunities, design platform-specific requirements, generate optimized AI prompts, plan post-processing workflows",
      "file_path": ".claude/agents\\art-visual-designer.md",
      "component_type": "agent",
      "line_count": 234,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "art-visual-designer",
        "description": "Design visual elements and create AI generation prompts for article imagery",
        "tools": "Read, Write",
        "model": "claude-haiku-3-5-20241022",
        "thinking": "Analyze content for visual opportunities, design platform-specific requirements, generate optimized AI prompts, plan post-processing workflows"
      },
      "io_spec": {
        "input_requirements": [
          "- Final article: path to approved article content",
          "- Platform requirements: target platforms and their image specifications",
          "- Visual style guidance: brand guidelines and aesthetic preferences",
          "- Image quantity: number and types of visuals needed",
          "- Special requirements: specific visual elements or constraints",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "file_reads": [
          "- `drafts/final.md` - approved article content for visual analysis",
          "- `strategy/voice_guide.md` - brand guidelines and aesthetic preferences (may be in parent directory)",
          "- `metadata.json` - article type and target platform context"
        ],
        "file_writes": [
          "- `visuals/visual_production_guide.md` - comprehensive visual production guide with AI prompts"
        ],
        "output_format": [
          "- Visual production readiness status with prompt count",
          "- Platform compliance verification for all target platforms",
          "- AI generation prompt quality assessment",
          "- Brand consistency evaluation across all visual elements",
          "- Main Claude provides: absolute path to article directory",
          "- Example: `D:/NOVELSYS-SWARM/.claude/data/articles/warning/content/20250120_140000_ai_risks/`",
          "- All file operations relative to this working directory",
          "- Strategy files accessed via: `../../../strategy/` or absolute paths resolved by Main Claude",
          "---",
          "- Analyze article content for visual storytelling opportunities",
          "- Identify key concepts requiring visual representation",
          "- Map content sections to optimal visual placements",
          "- Assess visual hierarchy and information flow needs",
          "- Design visuals for Medium, Substack, Beehiiv, and ElevenReader",
          "- Ensure platform compliance for image specifications",
          "- Optimize visual elements for platform discovery algorithms",
          "- Create platform-appropriate visual strategies",
          "- Write detailed, specific prompts for hero images",
          "- Create supporting image prompts for content sections",
          "- Design infographic and data visualization concepts",
          "- Develop consistent visual style specifications",
          "- Apply brand voice guide to visual elements",
          "- Ensure color, style, and aesthetic alignment",
          "- Maintain professional quality standards",
          "- Create cohesive visual narrative throughout",
          "- Read final article completely for visual opportunities",
          "- Identify key concepts and abstract ideas",
          "- Map content sections requiring visual support",
          "- Assess target audience visual preferences",
          "- Review platform-specific image requirements",
          "- Map optimal image sizes and formats",
          "- Plan platform-appropriate visual styles",
          "- Identify platform discovery optimization opportunities",
          "- Design primary visual that captures article essence",
          "- Create concept that works across all platforms",
          "- Ensure emotional impact and click-through appeal",
          "- Map to opening hook and main value proposition",
          "- Identify minimum 2 supporting images needed",
          "- Design section-specific visual concepts",
          "- Plan infographics or data visualizations",
          "- Create visual break points for readability",
          "- Write detailed, specific generation prompts",
          "- Include style, composition, and technical specifications",
          "- Specify brand-appropriate colors and aesthetics",
          "- Create multiple prompt variations for options",
          "- Develop section-specific image prompts",
          "- Ensure visual consistency across all images",
          "- Include platform-specific sizing requirements",
          "- Create technical specifications for each image",
          "- Adapt visual concepts for each platform's algorithms",
          "- Create platform-appropriate sizing specifications",
          "- Optimize for platform discovery and engagement",
          "- Ensure compliance with platform image policies",
          "- Create comprehensive implementation guide",
          "- Include all AI generation prompts ready to use",
          "- Document platform-specific requirements",
          "- Provide quality check criteria",
          "- **Hero Image:** Detailed concept with platform-optimized prompts",
          "- **Supporting Images:** Minimum 2 images with complete prompts",
          "- **Platform Specifications:** All 4 platforms covered",
          "- **Generation Prompts:** Complete and ready to use",
          "- **Style Alignment:** Consistent with voice guide aesthetics",
          "- **Color Harmony:** Brand-appropriate color specifications",
          "- **Quality Level:** Professional, publication-ready standards",
          "- **Visual Narrative:** Cohesive story throughout all images",
          "- **Medium:** Hero image 1920x1080, supporting 1200x800",
          "- **Substack:** Email-optimized sizes, header 1200x600",
          "- **Beehiiv:** Newsletter-focused visuals, email-optimized",
          "- **ElevenReader:** Community-friendly imagery, platform specs",
          "- Medium: [Size and format requirements]",
          "- Substack: [Size and format requirements]",
          "- Beehiiv: [Size and format requirements]",
          "- ElevenReader: [Size and format requirements]",
          "- **Statistical Visualization:** Convert key statistics into visual elements",
          "- **Process Illustration:** Visualize complex concepts and workflows",
          "- **Emotional Resonance:** Create images that connect with audience pain points",
          "- **Authority Building:** Design visuals that establish credibility and expertise",
          "- **Medium:** High contrast, professional imagery for algorithm preference",
          "- **Substack:** Personal, newsletter-friendly visuals for email engagement",
          "- **Beehiiv:** Newsletter and subscriber-focused imagery for email culture",
          "- **ElevenReader:** Reader-centric visuals optimized for discovery",
          "- **Click-Through Appeal:** Design heroes that compel article clicks",
          "- **Scroll Retention:** Place supporting images to maintain engagement",
          "- **Social Sharing:** Create shareable visual moments within content",
          "- **Brand Recognition:** Consistent visual elements for brand building",
          "- Working directory provided as absolute path",
          "- Strategy files in relative `../../../strategy/` or absolute paths",
          "- Final draft with various naming conventions",
          "- Metadata in local directory or parent directory",
          "- Flexible platform requirement specifications",
          "- Verify final draft exists before processing",
          "- Handle missing strategy files gracefully",
          "- Validate metadata accessibility",
          "- Ensure output directory exists before writing",
          "- Ensure all platform specifications included",
          "- Validate AI prompts for completeness and specificity",
          "- Cross-reference visual concepts with brand guidelines",
          "- Verify minimum image requirements met (hero + 2 supporting)"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Final article: path to approved article content",
          "- Platform requirements: target platforms and their image specifications",
          "- Visual style guidance: brand guidelines and aesthetic preferences",
          "- Image quantity: number and types of visuals needed",
          "- Special requirements: specific visual elements or constraints",
          "- **Working directory**: absolute path to article folder (provided by Main Claude)"
        ],
        "optional_context": []
      },
      "execution_patterns": [],
      "business_logic": [
        "thinking: Analyze content for visual opportunities, design platform-specific requirements, generate ",
        "### Input Requirements",
        "- Platform requirements: target platforms and their image specifications",
        "- Special requirements: specific visual elements or constraints",
        "### Visual Design Process"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "audience-profiler",
      "description": "PROACTIVE - Use PROACTIVELY when discussion mentions readers, audience, target market, who will read. Research and profile target audience demographics, preferences, and behaviors for specified genre/niche",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Research agent that analyzes target audience demographics, reading habits, purchase patterns, and content preferences. Combines web research with market analysis to create comprehensive audience profiles. Outputs single consolidated file with confidence scoring for marketing and content strategy decisions.",
      "file_path": ".claude/agents\\audience-profiler.md",
      "component_type": "agent",
      "line_count": 185,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "audience-profiler",
        "description": "PROACTIVE - Use PROACTIVELY when discussion mentions readers, audience, target market, who will read. Research and profile target audience demographics, preferences, and behaviors for specified genre/niche",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-sonnet-4-20250514",
        "thinking": "Research agent that analyzes target audience demographics, reading habits, purchase patterns, and content preferences. Combines web research with market analysis to create comprehensive audience profiles. Outputs single consolidated file with confidence scoring for marketing and content strategy decisions."
      },
      "io_spec": {
        "input_requirements": [
          "- Genre/niche specification for audience research",
          "- Conversation context for research focus",
          "- Search scope parameters (demographic filters, geographic regions)",
          "- Output directory path for knowledge base storage",
          "- Format: \"Research audience for [genre/niche] and save to knowledge base. Context: [context] Search scope: [parameters] Output directory: [path]\""
        ],
        "file_reads": [
          "- [Web sources: Publishing industry reports, survey data, demographic studies]",
          "- [Market research: Reader behavior studies, genre analysis reports]",
          "- [Platform data: Kindle Unlimited stats, library usage, retail trends]"
        ],
        "file_writes": [
          "- Single file: `audience_profile_{timestamp}.json` in specified output directory",
          "- Temporary file: `audience_profile_{timestamp}.tmp` for atomic operation"
        ],
        "output_format": [
          "- Research completion status with confidence metrics",
          "- Audience profile summary with key demographics",
          "- File path of saved comprehensive profile",
          "- Research scope coverage and data reliability notes",
          "- Age ranges and primary target segments",
          "- Gender distribution and preferences",
          "- Geographic distribution (US/international markets)",
          "- Income levels and spending capacity",
          "- Education levels and professional backgrounds",
          "- Family status and lifestyle factors",
          "- Publishing industry demographic reports",
          "- Genre-specific reader surveys",
          "- Book retail analytics and market studies",
          "- Social media audience insights for genre communities",
          "- Reading frequency and volume (books per month/year)",
          "- Format preferences (physical, ebook, audiobook ratios)",
          "- Device usage patterns (Kindle, tablet, phone, dedicated readers)",
          "- Reading environments and contexts (commute, leisure, bedtime)",
          "- Series vs standalone preferences",
          "- Length preferences (word count sweet spots)",
          "- Consumer reading surveys and behavioral studies",
          "- Platform usage statistics and trends",
          "- Genre-specific reading pattern analysis",
          "- Book completion rates and engagement metrics",
          "- Primary discovery channels (social media, recommendations, browsing)",
          "- Influence of reviews and ratings on purchase decisions",
          "- Price sensitivity and promotional response patterns",
          "- Subscription service usage (Kindle Unlimited, library apps)",
          "- Pre-order behaviors and series following patterns",
          "- Word-of-mouth and social sharing behaviors",
          "- Book marketing effectiveness studies",
          "- Discovery platform analytics (Goodreads, BookBub, etc.)",
          "- Price elasticity research for genre",
          "- Retail vs subscription consumption patterns",
          "- Popular subgenres and trending themes within main genre",
          "- Content elements that drive engagement vs avoidance",
          "- Emotional tone preferences (light vs heavy, optimistic vs dark)",
          "- Character archetype preferences and diversity expectations",
          "- Setting and world-building preferences",
          "- Controversial or sensitive topic boundaries",
          "- Genre review analysis and sentiment tracking",
          "- Bestseller list analysis for theme patterns",
          "- Reader discussion forum analysis",
          "- Content rating and tag analysis across platforms",
          "- Primary reading platforms and their market share within demographic",
          "- Social media presence and genre community participation",
          "- Influencer following patterns and trusted recommendation sources",
          "- Book club participation and group reading behaviors",
          "- Fan community engagement levels and content creation",
          "- Cross-platform discovery and discussion patterns",
          "- Platform-specific audience analytics where available",
          "- Social media demographic research for genre hashtags",
          "- Community size and engagement analysis",
          "- Influencer audience overlap studies",
          "- Age ranges with percentage breakdowns",
          "- Gender distribution with confidence levels",
          "- Geographic concentration areas",
          "- Income brackets and spending patterns",
          "- Education and professional background trends",
          "- Reading frequency and volume statistics",
          "- Format and device preference percentages",
          "- Discovery channel effectiveness rankings",
          "- Purchase pattern triggers and price points",
          "- Platform usage distribution",
          "- Content theme popularity rankings",
          "- Subgenre preference distributions",
          "- Emotional tone and style preferences",
          "- Length and format preferences",
          "- Diversity and representation expectations",
          "- Community participation levels",
          "- Social media engagement patterns",
          "- Review and recommendation behaviors",
          "- Series following and loyalty indicators",
          "- Cross-genre reading behaviors",
          "- Source reliability and sample size (industry reports = high, blogs = medium, speculation = low)",
          "- Data recency and market relevance (current year = 1.0, 2+ years = 0.7, 5+ years = 0.4)",
          "- Geographic and demographic representativeness of source data",
          "- Consistency across multiple independent sources",
          "- Statistical significance of reported findings",
          "- metadata (research_date, genre_focus, confidence_overall)",
          "- demographics (detailed breakdown with confidence scores)",
          "- reading_behaviors (habits and patterns with reliability indicators)",
          "- discovery_patterns (how they find books with effectiveness data)",
          "- purchase_behaviors (buying triggers and price sensitivity)",
          "- content_preferences (themes, styles, elements with popularity scores)",
          "- platform_usage (where they read and discover with usage percentages)",
          "- research_notes (methodology, limitations, source quality assessment)",
          "- Primary demographic insights and key findings",
          "- High-confidence behavioral patterns identified",
          "- Content preference recommendations for genre",
          "- Marketing and discovery channel recommendations",
          "- Research scope limitations and areas requiring additional study",
          "- Overall confidence assessment for profile reliability"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Genre/niche specification for audience research",
          "- Conversation context for research focus",
          "- Search scope parameters (demographic filters, geographic regions)",
          "- Output directory path for knowledge base storage",
          "- Format: \"Research audience for [genre/niche] and save to knowledge base. Context: [context] Search scope: [parameters] Output directory: [path]\""
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic"
      ],
      "business_logic": [
        "thinking: Research agent that analyzes target audience demographics, reading habits, purchase patter",
        "### Input Requirements",
        "- Influence of reviews and ratings on purchase decisions",
        "Execute thorough audience research combining multiple data sources for actionable insights that info"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "malformed_tools_config"
      ]
    },
    {
      "name": "bible-generator",
      "description": "Generate comprehensive project bible by synthesizing all research data from knowledge_base subdirectories into production-ready documentation suite with 7 output files including series planning and cultural authenticity guides",
      "tools": "Read, Write, Bash",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Enhanced synthesis agent that reads all research files from knowledge_base subdirectories (trends, competition, audience, voice, topics), analyzes relationships and patterns, creates comprehensive project bible with all decisions, generates 7 production-ready files - series_bible.yaml, voice style guide, consistency checklist, cultural authenticity guide, environmental accuracy standards, 10-book series plan, and character development framework",
      "file_path": ".claude/agents\\bible-generator.md",
      "component_type": "agent",
      "line_count": 586,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "bible-generator",
        "description": "Generate comprehensive project bible by synthesizing all research data from knowledge_base subdirectories into production-ready documentation suite with 7 output files including series planning and cultural authenticity guides",
        "tools": "Read, Write, Bash",
        "model": "claude-sonnet-4-20250514",
        "thinking": "Enhanced synthesis agent that reads all research files from knowledge_base subdirectories (trends, competition, audience, voice, topics), analyzes relationships and patterns, creates comprehensive project bible with all decisions, generates 7 production-ready files - series_bible.yaml, voice style guide, consistency checklist, cultural authenticity guide, environmental accuracy standards, 10-book series plan, and character development framework"
      },
      "io_spec": {
        "input_requirements": [
          "- Project directory path containing knowledge_base with research subdirectories",
          "- Target output directory for comprehensive bible documentation suite",
          "- Optional project name and metadata context",
          "- Format: \"Generate comprehensive project bible suite from research data. Project: [path] Output: [directory] Context: [optional project details]\""
        ],
        "file_reads": [
          "- `knowledge_base/trends/*.json` - Market trend analysis and genre positioning data",
          "- `knowledge_base/competition/*.json` - Competitor analysis and differentiation insights",
          "- `knowledge_base/audience/*.json` - Target audience profiles and demographic data",
          "- `knowledge_base/voice/*.json` - Enhanced voice analysis with comprehensive style data",
          "- `knowledge_base/topics/*.json` - Topic research and theme opportunities",
          "- [Project files: existing bible.yaml, project.yaml for updates]"
        ],
        "file_writes": [
          "- `series_bible.yaml` - Comprehensive project bible with all synthesized decisions",
          "- `VOICE_STYLE_GUIDE.md` - Detailed voice and style documentation with examples",
          "- `VOICE_CONSISTENCY_CHECKLIST.md` - Practical checklist for maintaining voice consistency",
          "- `CARIBBEAN_CULTURAL_AUTHENTICITY_GUIDE.md` - Cultural authenticity guidelines and standards",
          "- `ENVIRONMENTAL_ACCURACY_STANDARDS.md` - Environmental and setting accuracy requirements",
          "- `SERIES_PLAN_10_BOOKS.md` - Comprehensive 10+ book series planning framework",
          "- `CHARACTER_DEVELOPMENT_FRAMEWORK.md` - Character development arc planning system",
          "- Temporary files: `.tmp` files for atomic operations"
        ],
        "output_format": [
          "- Comprehensive bible generation completion status with synthesis quality metrics",
          "- Summary of all 7 generated files with content overview",
          "- File paths of complete documentation suite",
          "- Research coverage analysis and production readiness assessment",
          "- trends_analysis_20250915_142301.json",
          "- competitor_analysis_20250915_143045.json",
          "- caribbean_dialect_usage: \"{appropriate level of Caribbean dialect}\"",
          "- cultural_reference_integration: \"{how to weave cultural references}\"",
          "- authenticity_markers: [\"{specific cultural authenticity indicators}\"]",
          "- \"{key style characteristics from voice research}\"",
          "- \"{writing techniques that resonate with target audience}\"",
          "- \"{cultural storytelling techniques}\"",
          "- Narrative perspective and tone",
          "- Cultural voice integration",
          "- Dialect usage guidelines",
          "- Authenticity markers",
          "- Sentence structure patterns",
          "- Vocabulary preferences",
          "- Cultural storytelling techniques",
          "- Environmental description style",
          "- Voice examples from research",
          "- Style pattern demonstrations",
          "- Cultural integration examples",
          "- Environmental description samples",
          "- [ ] Review voice identity guidelines",
          "- [ ] Confirm cultural authenticity markers",
          "- [ ] Verify environmental accuracy standards",
          "- [ ] Maintain consistent narrative voice",
          "- [ ] Apply appropriate dialect level",
          "- [ ] Include cultural authenticity elements",
          "- [ ] Verify environmental accuracy",
          "- [ ] Voice consistency across chapters",
          "- [ ] Cultural authenticity maintained",
          "- [ ] Environmental details accurate",
          "- [ ] Character voice differentiation clear",
          "- Historical accuracy requirements",
          "- Social structure representation",
          "- Religious and spiritual practices",
          "- Food, music, and traditions",
          "- Appropriate dialect usage levels",
          "- Cultural expressions and idioms",
          "- Code-switching patterns",
          "- Respectful representation guidelines",
          "- Avoiding stereotypes and tropes",
          "- Respectful portrayal standards",
          "- Community representation principles",
          "- Cultural consultant recommendations",
          "- Island geography and topography",
          "- Climate and weather patterns",
          "- Flora and fauna accuracy",
          "- Seasonal variations",
          "- Architecture and building styles",
          "- Urban vs rural distinctions",
          "- Infrastructure representation",
          "- Economic environment portrayal",
          "- Primary source requirements",
          "- Fact-checking protocols",
          "- Cultural consultant validation",
          "- Accuracy review checkpoints",
          "- Overall narrative progression",
          "- Character development across books",
          "- Thematic evolution framework",
          "- Cultural exploration depth",
          "- Book 1-3: Foundation and establishment",
          "- Book 4-6: Development and expansion",
          "- Book 7-9: Climax and resolution",
          "- Book 10+: Extension and spin-off potential",
          "- Character continuity guidelines",
          "- World-building consistency rules",
          "- Cultural authenticity maintenance",
          "- Environmental accuracy standards",
          "- Publishing schedule considerations",
          "- Audience development across series",
          "- Cultural market expansion opportunities",
          "- International market potential",
          "- Primary character arc templates",
          "- Cultural background integration",
          "- Voice differentiation guidelines",
          "- Development milestone framework",
          "- Cultural representation requirements",
          "- Psychological authenticity markers",
          "- Voice consistency across characters",
          "- Growth pattern authenticity",
          "- Multi-book character development",
          "- Relationship evolution framework",
          "- Cultural identity exploration",
          "- Character voice maturation patterns",
          "- Authenticity review checkpoints",
          "- Cultural sensitivity validation",
          "- Voice consistency verification",
          "- Development arc completion assessment",
          "- **Input**: Project directory path with populated knowledge_base containing enhanced research",
          "- **Processing**: Multi-source synthesis into comprehensive production documentation suite",
          "- **Output**: 7 production-ready files providing complete series development framework",
          "- **Status**: Complete production readiness assessment with cultural authenticity and series viability metrics",
          "- **Never use Task tool** (I don't have it - prevents recursion)",
          "- **Never call other agents** (only Main Claude orchestrates)",
          "- **Never generate incomplete documentation suite** (all 7 files or clear error reporting)",
          "- **Never skip cultural authenticity considerations** (respectful representation critical)",
          "- **Never assume series viability** (must be research-backed)",
          "- **Never skip production readiness assessment** (comprehensive evaluation required)",
          "- **Execute comprehensive research synthesis** into 7-file production documentation suite",
          "- **Generate culturally authentic guidelines** with respectful representation standards",
          "- **Create practical voice consistency framework** with actionable guidance for writers",
          "- **Develop comprehensive series planning** for 10+ book market-viable progression",
          "- **Establish environmental accuracy standards** with research verification protocols",
          "- **Build character development framework** supporting authentic cultural representation",
          "- **Assess complete production readiness** for immediate series development launch",
          "- All 7 documentation files generated successfully with comprehensive content",
          "- Cultural authenticity guide meets respectful representation standards",
          "- Voice framework provides practical, actionable guidance for consistent writing",
          "- Series plan demonstrates market viability for 10+ book progression",
          "- Environmental standards ensure research-backed accuracy",
          "- Character framework supports authentic development across series",
          "- Complete documentation suite enables immediate production launch",
          "- Documentation suite completeness (7 files with comprehensive content)",
          "- Cultural authenticity depth and respectfulness (sensitivity and accuracy standards)",
          "- Voice consistency framework practicality (actionable guidance for writers)",
          "- Series planning market viability (research-backed 10+ book progression)",
          "- Production readiness completeness (immediate launch capability assessment)"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Project directory path containing knowledge_base with research subdirectories",
          "- Target output directory for comprehensive bible documentation suite",
          "- Optional project name and metadata context",
          "- Format: \"Generate comprehensive project bible suite from research data. Project: [path] Output: [directory] Context: [optional project details]\""
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "thinking: Enhanced synthesis agent that reads all research files from knowledge_base subdirectories ",
        "### Input Requirements",
        "- `series_bible.yaml` - Comprehensive project bible with all synthesized decisions",
        "- `ENVIRONMENTAL_ACCURACY_STANDARDS.md` - Environmental and setting accuracy requirements",
        "2. **Load and Validate Research Files with Enhanced Processing**:"
      ],
      "violations": [
        "MAJOR: Agent exceeds 500 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "claude-code-expert",
      "description": "MUST BE USED PROACTIVELY for \"claude code\", \"official\", \"best practice\", \"recursion\", \"coordinator\", \"Task tool\", \"subagent\", \"parallel execution\", \"create new agent\", \"create new command\", \"large file\", \"chunked reading\", \"trigger words\", \"prompt too long\", architecture questions, or preventing Claude Code crashes. Expert on official specifications, recursion prevention, trigger word patterns, and large file handling.",
      "tools": "Read, Write, Grep, WebSearch, WebFetch",
      "model": "",
      "thinking": "Analyze Claude Code architecture deeply - focus on recursion prevention, proper tool delegation, coordinator patterns, trigger word avoidance, and Main Claude's orchestration role. Expert in Task tool trigger word patterns that cause false \"Prompt too long\" errors. Expert in large file handling with chunked reading patterns (2000-line chunks) and Python script integration. Stay updated with latest official documentation and community best practices. Remember - coordinators are subagents that CANNOT call other subagents. Also remember - certain file names in Task prompts trigger automatic loading causing failures.",
      "file_path": ".claude/agents\\claude-code-expert.md",
      "component_type": "agent",
      "line_count": 807,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "claude-code-expert",
        "description": "MUST BE USED PROACTIVELY for \"claude code\", \"official\", \"best practice\", \"recursion\", \"coordinator\", \"Task tool\", \"subagent\", \"parallel execution\", \"create new agent\", \"create new command\", \"large file\", \"chunked reading\", \"trigger words\", \"prompt too long\", architecture questions, or preventing Claude Code crashes. Expert on official specifications, recursion prevention, trigger word patterns, and large file handling.",
        "tools": "Read, Write, Grep, WebSearch, WebFetch",
        "thinking": "Analyze Claude Code architecture deeply - focus on recursion prevention, proper tool delegation, coordinator patterns, trigger word avoidance, and Main Claude's orchestration role. Expert in Task tool trigger word patterns that cause false \"Prompt too long\" errors. Expert in large file handling with chunked reading patterns (2000-line chunks) and Python script integration. Stay updated with latest official documentation and community best practices. Remember - coordinators are subagents that CANNOT call other subagents. Also remember - certain file names in Task prompts trigger automatic loading causing failures."
      },
      "io_spec": {
        "input_requirements": [
          "- **Tools**: Only what's needed (Read, Write, etc.) - NO Task",
          "- **Focus**: Single responsibility",
          "- **Communication**: Via file system only",
          "- **I/O Documentation**: REQUIRED - Input/Output specification (NEW)",
          "- **Prompt Documentation**: REQUIRED - Expected input format from Main Claude (NEW)",
          "---",
          "---",
          "- Expected format and parameters",
          "- Required file paths",
          "- Optional context",
          "- Orchestration request format",
          "- Required context for planning"
        ],
        "file_reads": [
          "- Specific input files with purpose",
          "- Files needed for planning",
          "- Coordinators only return JSON plans directly",
          "- Structured JSON execution plan in response text",
          "- Agent specifications with tasks",
          "- Path templates for Main Claude to resolve",
          "- Most agents work fine without model specification",
          "- Only specify when you need specific capabilities",
          "- Coordinators with complex reasoning: Sonnet 4",
          "- Quality-critical operations: Opus 4.1",
          "- Speed-sensitive tasks: Haiku 3.5",
          "- Haiku 3.5: Fastest and cheapest",
          "- Sonnet 4: Balanced performance/cost",
          "- Opus 4.1: Highest cost, use sparingly",
          "---",
          "- **[/CLAUDE.md](/CLAUDE.md)** - System constitution and authoritative rules (v6.2)",
          "- **[/SYSTEM_INDEX.md](/SYSTEM_INDEX.md)** - Master documentation index",
          "- **[/.claude/templates/README.md](/.claude/templates/README.md)** - Template system guide",
          "- **[/.claude/templates/TEMPLATE_command.md](/.claude/templates/TEMPLATE_command.md)** - Command creation",
          "- **[/.claude/templates/TEMPLATE_coordinator.md](/.claude/templates/TEMPLATE_coordinator.md)** - Coordinator creation",
          "- **[/.claude/templates/TEMPLATE_agent.md](/.claude/templates/TEMPLATE_agent.md)** - Agent creation",
          "- **[/.claude/templates/QUICK_REFERENCE.md](/.claude/templates/QUICK_REFERENCE.md)** - Rapid rule lookup",
          "- **[/.claude/templates/ARCHITECTURE_data_layer.md](/.claude/templates/ARCHITECTURE_data_layer.md)** - Deep architecture",
          "---",
          "- **system-check v2.0**: Successfully processes 1MB+ JSON files",
          "- **Chunked reading algorithm**: Verified reliable for 31K+ line files",
          "- **No data loss**: Complete file processing with tool limit compliance",
          "- **Two options only**: Approve/Modify (no Reject needed)",
          "- **Numeric input**: 1/2 choices, avoid long text typing",
          "- **Infinite capability**: Human can modify unlimited times until satisfied",
          "- **Human control**: User decides when to stop, not system limits",
          "- Display content clearly for human review",
          "- Present simple 1/2 choice format",
          "- Collect structured feedback on Modify",
          "- Loop back to display after regeneration",
          "- Continue until human chooses Approve",
          "- Task tool scans prompts for certain patterns",
          "- When it finds file names like \"system_scan.json\"",
          "- It attempts to auto-load the file content",
          "- This causes \"Prompt too long\" even with short prompts",
          "- system_scan.json, system_analysis.json",
          "- .claude/agents/*.md paths",
          "- Any specific .json filename",
          "- Files in .claude directories",
          "- Add warning: \"IMPORTANT: Avoid file names in Task prompts\"",
          "- Use descriptive language in execution instructions",
          "- Return directory + type, not full paths",
          "- Example: {\"report_directory\": \".claude/report\", \"scan_type\": \"system\"}",
          "- Let agents build paths internally",
          "- Implement defensive input handling",
          "- Support multiple input formats",
          "- Build file paths from safe components"
        ],
        "file_writes": [
          "- Universal patterns from 6 proven tests",
          "- Five-layer architecture implementation",
          "- Workflow patterns (Pipeline, Parallel, Human-in-Loop, Multi-Coordinator)",
          "- Communication patterns (Producer-Consumer, Shared Reference, Version Control)",
          "- Compliance checklist and standards",
          "- Novel-specific implementation of universal patterns",
          "- Production-ready patterns for novel generation",
          "- Performance metrics: 3-10x improvement with parallel execution",
          "- Combined patterns for full chapter generation",
          "- New Tool additions",
          "- Performance improvements",
          "- Security updates",
          "- Architecture pattern changes",
          "- Community discovered patterns",
          "- Output files and formats",
          "- Temporary files (.tmp pattern)"
        ],
        "output_format": [
          "-> Task -> Subagent B (no Task tool)",
          "- [ ] NO Unicode characters anywhere?",
          "- [ ] Under 100 lines?",
          "- [ ] Pure delegation pattern?",
          "- [ ] No implementation details?",
          "- [ ] Uses \"Use the [coordinator] subagent...\" for complex tasks?",
          "- [ ] Includes trigger word warning for Task tool calls?",
          "- [ ] Avoids exact file names in execution instructions?",
          "- [ ] NO Unicode characters anywhere?",
          "- [ ] Has `tools:` WITHOUT Task?",
          "- [ ] Returns JSON plan only?",
          "- [ ] Doesn't try to execute agents?",
          "- [ ] Uses natural language, not Task() syntax?",
          "- [ ] Returns safe inputs (directory + type) not file names?",
          "- [ ] Plan uses descriptive task descriptions, not trigger words?",
          "- [ ] NO Unicode characters anywhere?",
          "- [ ] Single responsibility?",
          "- [ ] Minimal tools (no Task)?",
          "- [ ] Clear input/output specification?",
          "- [ ] Communicates via files only?",
          "- [ ] Implements defensive input handling for multiple formats?",
          "- [ ] Builds file paths internally from safe inputs?",
          "- Claude Code is \"low-level and unopinionated\"",
          "- Task tool enables parallel subagent execution",
          "- Each subagent has independent context window",
          "- Parallel execution capped at 10 concurrent tasks",
          "- Hub-and-spoke prevents \"communication chaos\"",
          "- Coordinators as planning layer emerged as best practice",
          "- File-based communication prevents context pollution",
          "- Subagents with Task = recursion crash confirmed",
          "- Coordinators without Task = safe planning layer",
          "- Main Claude orchestration = stable execution",
          "- `projects/{project}/book_{N}/chapter.md`",
          "- `.claude/data/context/current.json`",
          "- `/absolute/path/to/file.yaml`",
          "- `path/to/file.md` (double backtick)",
          "- path/to/file.md (no backticks)",
          "- \"path/to/file.md\" (quotes)",
          "- [Bible files: series_bible.yaml, book_*/bible.yaml]",
          "- [Chapter files: chapters/*/content.md]",
          "- [Dynamic input paths]",
          "- `File saved to output.md`",
          "- `CRITICAL: Multiple writers detected`",
          "- Response format",
          "- Success indicators",
          "- Error handling"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "sequential",
        "pipeline",
        "batch",
        "atomic",
        "coordinator",
        "subagent",
        "task tool",
        "file communication"
      ],
      "business_logic": [
        "**Requirements (2024-2025 Standards):**",
        "- **Length**: <100 lines target, 50-120 acceptable for business completeness",
        "- **Pattern**: Delegation with necessary business context",
        "- **Content**: Declarative instructions with workflow context, NOT implementation code",
        "- **Priority**: Business completeness > arbitrary line limits"
      ],
      "violations": [
        "MAJOR: Agent exceeds 500 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "hardcoded_absolute_paths",
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "competitor-scanner",
      "description": "Analyze competition in specific market niches, find gaps and opportunities. Use PROACTIVELY when discussion mentions competitors, competition, market saturation",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Execute strategic competitor research through multi-phase analysis, identify market gaps and opportunities, calculate confidence scores, save structured competitive intelligence to knowledge_base with atomic operations",
      "file_path": ".claude/agents\\competitor-scanner.md",
      "component_type": "agent",
      "line_count": 272,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "competitor-scanner",
        "description": "Analyze competition in specific market niches, find gaps and opportunities. Use PROACTIVELY when discussion mentions competitors, competition, market saturation",
        "thinking": "Execute strategic competitor research through multi-phase analysis, identify market gaps and opportunities, calculate confidence scores, save structured competitive intelligence to knowledge_base with atomic operations",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-sonnet-4-20250514"
      },
      "io_spec": {
        "input_requirements": [
          "- Target niche or market segment for analysis",
          "- Conversation context (optional for better targeting)",
          "- Search scope specification (geographic, demographic, etc.)",
          "- Output directory path in knowledge_base/competitors/"
        ],
        "file_reads": [
          "- [Existing competitor data: knowledge_base/competitors/*.json]",
          "- [Market context files if referenced]"
        ],
        "file_writes": [
          "- `knowledge_base/competitors/{niche}_{timestamp}.json` (main analysis)",
          "- `knowledge_base/competitors/{niche}_{timestamp}.tmp` (atomic operation temp file)"
        ],
        "output_format": [
          "- Analysis completion status",
          "- Key findings summary (top 3 gaps identified)",
          "- Competitor count analyzed",
          "- Confidence score (0.0-1.0 based on data quality)",
          "- File path of saved analysis",
          "- Target niche/market segment",
          "- Search scope parameters",
          "- Output directory path",
          "- Any conversation context for better targeting",
          "- Use current datetime in format YYYYMMDD_HHMMSS",
          "- Ensure consistent naming across analysis files",
          "- \"top companies in [niche] market 2025\"",
          "- \"[niche] market leaders competitive analysis\"",
          "- \"biggest players in [niche] industry\"",
          "- Industry revenue and growth rates",
          "- Market share distribution",
          "- Geographic presence of major players",
          "- Company background and founding story",
          "- Core products/services and pricing models",
          "- Target audience and customer segments",
          "- Marketing strategies and brand positioning",
          "- Recent news, funding, or strategic moves",
          "- \"[competitor_name] business model revenue\"",
          "- \"[competitor_name] target market customer base\"",
          "- \"[competitor_name] pricing strategy competitors\"",
          "- \"[competitor_name] strengths weaknesses analysis\"",
          "- Underserved customer segments",
          "- Pricing gaps in the market",
          "- Feature gaps in existing solutions",
          "- Geographic markets with limited competition",
          "- Emerging trends not yet addressed",
          "- \"[niche] customer complaints reviews\"",
          "- \"what's missing in [niche] market\"",
          "- \"[niche] unmet needs problems\"",
          "- Product/service quality indicators",
          "- Customer satisfaction metrics",
          "- Market positioning effectiveness",
          "- Innovation capabilities",
          "- Financial stability indicators",
          "- Market presence (1-10)",
          "- Product quality (1-10)",
          "- Customer satisfaction (1-10)",
          "- Innovation level (1-10)",
          "- Financial strength (1-10)",
          "- Market niches with weak competition",
          "- Customer segments being underserved",
          "- Price points not well covered",
          "- Feature combinations not offered",
          "- Distribution channels not utilized",
          "- How to compete against top players",
          "- Unique value propositions to consider",
          "- Market entry strategies",
          "- Positioning recommendations",
          "- Number of reliable sources found (weight: 30%)",
          "- Recency of data available (weight: 25%)",
          "- Depth of competitor information (weight: 25%)",
          "- Consistency across sources (weight: 20%)",
          "- 0.9-1.0: Excellent data, multiple recent sources",
          "- 0.7-0.8: Good data, some gaps but reliable",
          "- 0.5-0.6: Moderate data, missing key information",
          "- 0.3-0.4: Limited data, significant gaps",
          "- 0.0-0.2: Poor data quality, analysis uncertain",
          "- If temp file creation fails, report error with cause",
          "- If atomic move fails, attempt cleanup of temp file",
          "- Provide clear error messages for troubleshooting",
          "- Number of competitors analyzed",
          "- Percentage of competitors with complete data",
          "- Number of market gaps identified",
          "- Number of opportunities discovered",
          "- Overall confidence in findings",
          "- Priority opportunities to investigate further",
          "- Competitors requiring ongoing monitoring",
          "- Market trends to track over time",
          "- Recommended analysis refresh timeline"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Target niche or market segment for analysis",
          "- Conversation context (optional for better targeting)",
          "- Search scope specification (geographic, demographic, etc.)",
          "- Output directory path in knowledge_base/competitors/"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic"
      ],
      "business_logic": [
        "### Input Requirements",
        "- \"[competitor_name] business model revenue\"",
        "### Error Handling and User Decision Points",
        "3. Deep dive each competitor: Business models, pricing, strengths"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "gemini-auditor",
      "description": "PROACTIVE - Gemini CLI interface with intelligent 2.5 model selection. Use PROACTIVELY when user mentions \"gemini\", \"Gemini\", \"call gemini\", \"use gemini\", \"analyze with gemini\", or needs Gemini's 1M token context capabilities.",
      "tools": "Bash",
      "model": "sonnet",
      "thinking": "Determine optimal Gemini model for task requirements, construct appropriate prompts for 1M context window, handle error conditions and retry logic, format results appropriately for user consumption",
      "file_path": ".claude/agents\\gemini-auditor.md",
      "component_type": "agent",
      "line_count": 598,
      "has_unicode": true,
      "yaml_frontmatter": {
        "name": "gemini-auditor",
        "description": "PROACTIVE - Gemini CLI interface with intelligent 2.5 model selection. Use PROACTIVELY when user mentions \"gemini\", \"Gemini\", \"call gemini\", \"use gemini\", \"analyze with gemini\", or needs Gemini's 1M token context capabilities.",
        "tools": "Bash",
        "model": "sonnet",
        "thinking": "Determine optimal Gemini model for task requirements, construct appropriate prompts for 1M context window, handle error conditions and retry logic, format results appropriately for user consumption"
      },
      "io_spec": {
        "input_requirements": [],
        "file_reads": [],
        "file_writes": [],
        "output_format": [
          "- Use severity levels: CRITICAL > HIGH > MEDIUM > LOW > INFO",
          "- Include file paths and line numbers where applicable",
          "- Provide specific, actionable recommendations in English",
          "- Group findings by category (Security, Performance, Maintainability, etc.)",
          "- Include positive findings, not just issues",
          "- Add summary statistics and metrics at the end",
          "- **ENFORCE**: All output must be in English only",
          "- For files: `gemini -m gemini-2.5-flash -p \"Analyze @file.md\"`",
          "- For text: `gemini -m gemini-2.5-flash -p \"Your request here\"`",
          "- For complex: `gemini -m gemini-2.5-pro -p \"Complex analysis request\"`",
          "- User: \"让gemini分析这个文档\" → `gemini -m gemini-2.5-flash -p \"Analyze @document.md\"`",
          "- User: \"用gemini审核代码\" → `gemini -m gemini-2.5-pro -p \"Review code @code.py\"`",
          "- User: \"gemini告诉我今天新闻\" → `gemini -m gemini-2.5-flash -p \"Today's news\"`",
          "- NO `./` prefix - use `@folder` not `@./folder`",
          "- NO trailing `/` - use `@folder` not `@folder/`",
          "- NO glob patterns - Gemini reads entire folders automatically",
          "- User: \"分析整个项目\" → `gemini -m gemini-2.5-pro -p \"Analyze entire project @.\"`",
          "- User: \"递归审核所有代码\" → `gemini -m gemini-2.5-pro -p \"Audit all code in @src\"`",
          "- User: \"检查docs文件夹所有文档\" → `gemini -m gemini-2.5-flash -p \"Review all docs @docs\"`",
          "- User: \"分析src下所有文件\" → `gemini -m gemini-2.5-pro -p \"Analyze @src folder\"`",
          "- Break into logical sections (src/, docs/, tests/)",
          "- Use specific file patterns to limit scope",
          "- Process in phases if needed",
          "- Use gemini-2.5-flash for quick overview scans",
          "- Use gemini-2.5-pro for detailed analysis",
          "- Be specific with patterns to avoid processing unnecessary files",
          "- [ ] Using Bash tool to execute? (NOT analyzing yourself)",
          "- [ ] Correct @ syntax? (no ./ prefix, no trailing /)",
          "- [ ] Valid model name? (gemini-2.5-flash or gemini-2.5-pro)",
          "- [ ] File/folder exists? (use ls to verify first if needed)",
          "- Return Gemini's FULL response as-is",
          "- DO NOT summarize, shorten, or interpret",
          "- DO NOT add your own analysis or comments",
          "- Just pass through whatever Gemini returns"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "batch",
        "task tool"
      ],
      "business_logic": [
        "thinking: Determine optimal Gemini model for task requirements, construct appropriate prompts for 1M",
        "### Model Selection Rules:",
        "- Input validation issues",
        "1. **Pre-prompt validation**: Check all text for non-English characters before sending",
        "### Language Validation Function:"
      ],
      "violations": [
        "CRITICAL: Contains Unicode characters",
        "MAJOR: Agent exceeds 500 lines"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "project-manager",
      "description": "Manages writing projects lifecycle, tracks status, and handles project organization",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Scan project directories, manage index.json, track project status, return JSON plans for project operations",
      "file_path": ".claude/agents\\project-manager.md",
      "component_type": "agent",
      "line_count": 358,
      "has_unicode": true,
      "yaml_frontmatter": {
        "name": "project-manager",
        "description": "Manages writing projects lifecycle, tracks status, and handles project organization",
        "tools": "Read, Write, Bash, Grep",
        "thinking": "Scan project directories, manage index.json, track project status, return JSON plans for project operations"
      },
      "io_spec": {
        "input_requirements": [
          "- \"initialize\" - Create data structure if not exists (ALWAYS RUN FIRST)",
          "- \"scan projects\" - List all projects with status",
          "- \"create project {type} {name}\" - Initialize new project",
          "- \"get project {id}\" - Retrieve specific project details",
          "- \"update status {id} {status}\" - Update project status",
          "- \"get recent\" - Get most recently modified project"
        ],
        "file_reads": [
          "- `.claude/data/projects/index.json` - Project index",
          "- `.claude/data/projects/*/project.json` - Individual project metadata",
          "- `.claude/data/writing/*/` - Quick writing files"
        ],
        "file_writes": [
          "- `.claude/data/projects/index.json` - Update project index",
          "- `.claude/data/projects/{id}/project.json` - Project metadata",
          "- `.claude/data/writing/{type}/{date}/` - Quick writing organization",
          "- Creating/updating index.json",
          "- Creating/updating project.json",
          "- Saving session states",
          "- Any file that could be corrupted by partial writes"
        ],
        "output_format": [
          "- Mark as `paused` if no activity for 30 days",
          "- Mark as `completed` when user confirms",
          "- Update `progress.percentage` based on milestones",
          "- **Partial project creation**: Clean up or complete",
          "- **Incomplete status update**: Revert to last known good",
          "- **Index corruption**: Rebuild from project files",
          "- **Session state mismatch**: Prefer project.json as source of truth",
          "- Provides project list for selection",
          "- Creates new project structures",
          "- Returns routing information",
          "- Identifies most recent project",
          "- Provides status and next action",
          "- Returns project context",
          "- Creates brainstorm subdirectory",
          "- Passes project ID for state management",
          "- Updates project status after brainstorm",
          "- All projects properly indexed",
          "- No data loss during operations",
          "- Quick project access (<1 second)",
          "- Accurate status tracking",
          "- Clean directory structures",
          "- Atomic file operations (write to .tmp first)"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "5. Return project information for routing decisions",
        "### Input Requirements",
        "### Path Handling Rules"
      ],
      "violations": [
        "CRITICAL: Contains Unicode characters"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "system-analyzer",
      "description": "Analyzes scan results to identify relationships, patterns, and compliance violations",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "Read scan results JSON, build complete relationship graph from command to agent calls, identify orphan and missing components, check all CLAUDE.md compliance rules, calculate health scores, and output comprehensive analysis for reporting",
      "file_path": ".claude/agents\\system-analyzer.md",
      "component_type": "agent",
      "line_count": 313,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "system-analyzer",
        "description": "Analyzes scan results to identify relationships, patterns, and compliance violations",
        "thinking": "Read scan results JSON, build complete relationship graph from command to agent calls, identify orphan and missing components, check all CLAUDE.md compliance rules, calculate health scores, and output comprehensive analysis for reporting",
        "tools": "Read, Write, Bash, Grep"
      },
      "io_spec": {
        "input_requirements": [
          "- **From Main Claude**:",
          "- **NEW FORMAT**: Directory path + scan type (e.g., \"report_directory: .claude/report/xxx, scan_type: system\")",
          "- **AGENT CONSTRUCTS**: Full file paths internally to avoid trigger words",
          "- **DO NOT**: Pass file contents in prompt (will exceed token limits)",
          "- **AGENT RESPONSIBILITY**: Read file using chunked approach internally",
          "- Large files (1MB+) require chunked reading with Read tool"
        ],
        "file_reads": [
          "- `{report_directory}/system_scan.json` - Constructed internally from directory + scan_type",
          "- Read ALL chunks sequentially",
          "- Don't skip any part of the file",
          "- Maintain JSON structure integrity",
          "- Handle chunk boundaries carefully (don't split JSON objects)",
          "- Commands using coordinators (proper pattern)",
          "- Commands calling agents directly (simplified pattern)",
          "- Coordinator orchestration complexity",
          "- Command layer: Delegation only",
          "- Coordinator layer: Planning only (no Task)",
          "- Agent layer: Execution only (no Task)",
          "- Check if any agent references create cycles",
          "- Flag potential recursion risks",
          "- Coordinator/Agent has Task tool",
          "- Missing referenced components",
          "- Circular dependencies detected",
          "- Command > 100 lines (target)",
          "- Coordinator > 250 lines",
          "- Agent > 500 lines",
          "- Unicode characters present",
          "- Missing I/O documentation",
          "- No thinking field in agent",
          "- Inconsistent naming patterns",
          "- Weight scores appropriately",
          "- Critical violations: -20 points each",
          "- Major violations: -5 points each",
          "- Minor issues: -1 point each",
          "- Start from 100, subtract penalties",
          "- All relationships correctly mapped",
          "- All violations accurately identified",
          "- Health score fairly calculated",
          "- Actionable recommendations provided",
          "- No false positives in violation detection",
          "- If scan data invalid: Return error with details",
          "- If analysis partially fails: Complete what's possible",
          "- Always generate some output for debugging"
        ],
        "file_writes": [
          "- `{report_directory}/{output_name}` - Typically system_analysis.json"
        ],
        "output_format": [
          "- **Returns to Main Claude**: Analysis summary with health score",
          "- **File Output**: Comprehensive JSON with relationships, violations, and metrics",
          "- ~18 true orphans (15.3% orphan rate)",
          "- Enhanced detection eliminates false positives",
          "- Complete usage patterns included in scan data",
          "- First, get total line count:",
          "- Read the ENTIRE file chunk by chunk:",
          "- Process each chunk:",
          "- Combine all chunks to get complete picture",
          "- Parse the full JSON structure",
          "- Maintain data integrity across chunk boundaries",
          "- Track which agents are called by which commands",
          "- Identify calling patterns"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "thinking: Read scan results JSON, build complete relationship graph from command to agent calls, ide",
        "### Input Requirements",
        "## MANDATORY WORKFLOW",
        "- Process each chunk:",
        "# Process the combined data as needed"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "system-reporter",
      "description": "Generates comprehensive markdown report from analysis results showing complete system architecture",
      "tools": "Read, Write",
      "model": "",
      "thinking": "Read analysis JSON, transform data into human-readable markdown report with architecture diagrams, relationship maps, violation details, health scores, and actionable recommendations formatted for easy understanding",
      "file_path": ".claude/agents\\system-reporter.md",
      "component_type": "agent",
      "line_count": 268,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "system-reporter",
        "description": "Generates comprehensive markdown report from analysis results showing complete system architecture",
        "thinking": "Read analysis JSON, transform data into human-readable markdown report with architecture diagrams, relationship maps, violation details, health scores, and actionable recommendations formatted for easy understanding",
        "tools": "Read, Write"
      },
      "io_spec": {
        "input_requirements": [
          "- **From Main Claude**:",
          "- NEW FORMAT: Directory + file type (e.g., \"report_directory: .claude/report/xxx, input_type: analysis\")",
          "- LEGACY: Direct paths (still supported for backward compatibility)",
          "- Agent constructs full paths internally to avoid trigger words"
        ],
        "file_reads": [
          "- `{input_path}/system_analysis.json` - System analysis results",
          "- agent-7: Not called by any command",
          "- agent-8: Not called by any command",
          "- File: .claude/agents/coordinator-1.md",
          "- Line: 5",
          "- Impact: Recursion risk - system crash possible",
          "- Fix: Remove Task from tools list",
          "- File: .claude/commands/command-2.md",
          "- Lines: 150 (limit: 100)",
          "- Impact: Reduced maintainability",
          "- Fix: Simplify to pure delegation",
          "- File: .claude/agents/agent-3.md",
          "- Impact: Unclear data flow",
          "- Fix: Add Data I/O section",
          "- Scan Duration: [N]ms",
          "- Analysis Duration: [N]ms",
          "- Report Generated: [timestamp]",
          "---",
          "- Report is clear and actionable",
          "- All violations are documented with fixes",
          "- Architecture is clearly visualized",
          "- Relationships are easy to understand",
          "- Health score is prominently displayed",
          "- If analysis data missing: Note in report",
          "- If sections incomplete: Generate partial report",
          "- Always indicate data quality/completeness"
        ],
        "file_writes": [
          "- `{output_path}/system_report.md` - Comprehensive markdown report"
        ],
        "output_format": [
          "- **Returns to Main Claude**: Report generation success with summary",
          "- **File Output**: Detailed markdown report with all findings",
          "- Use Read tool on provided input path",
          "- Parse JSON structure",
          "- Extract all sections for reporting",
          "---",
          "- Total Components: [N]",
          "- Commands: [N]",
          "- Coordinators: [N]",
          "- Agents: [N]",
          "- Total Lines of Code: [N]",
          "- Overall Health: [score]/100",
          "- Critical Issues: [N]",
          "- Major Issues: [N]",
          "- Minor Issues: [N]",
          "- Command -> Coordinator -> Agents: [N] flows",
          "- Command -> Agent (direct): [N] flows",
          "- Orphan Components: [N] unused"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "## MANDATORY WORKFLOW"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "system-scanner",
      "description": "Executes Python script to collect comprehensive raw system data",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "Execute system_check_v5.py with complete semantic extraction and enhanced orphan detection - monitor execution for errors, verify JSON output file is created with full data completeness, extract statistics from output, and report success/failure status back to Main Claude",
      "file_path": ".claude/agents\\system-scanner.md",
      "component_type": "agent",
      "line_count": 120,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "system-scanner",
        "description": "Executes Python script to collect comprehensive raw system data",
        "thinking": "Execute system_check_v5.py with complete semantic extraction and enhanced orphan detection - monitor execution for errors, verify JSON output file is created with full data completeness, extract statistics from output, and report success/failure status back to Main Claude",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- **From Main Claude**:",
          "- Output directory path (e.g., `.claude/report/20250114153045/`)",
          "- Should be an absolute or relative path where scan results will be saved",
          "- **Script reads**:",
          "- `.claude/commands/**/*.md` - All command files",
          "- `.claude/agents/*.md` - All agents and coordinators",
          "- **Script writes**:",
          "- `{output_path}/system_scan.json` - Raw scan data"
        ],
        "file_reads": [],
        "file_writes": [],
        "output_format": [
          "- **Returns to Main Claude**:",
          "- Success/failure status",
          "- Number of components scanned",
          "- Violation counts by category",
          "- Path to generated system_scan.json",
          "- Successful completion message",
          "- Component scan counts",
          "- Violation detection counts",
          "- Any error messages",
          "- Scans all 145 components (commands, coordinators, agents)",
          "- 10 semantic extraction modules (YAML, I/O, prompts, execution, business logic, model hints, violations, division of labor, enhanced orphan detection, coordinator plans)",
          "- Complete data extraction with 17-field ComponentMetadata",
          "- Enhanced orphan detection with 8-pattern recognition",
          "- Comprehensive CLAUDE.md violation detection",
          "- Division of labor analysis",
          "- Outputs comprehensive JSON to timestamped directory (~1MB)",
          "- Confirmation of successful data collection",
          "- Path to system_scan.json",
          "- Summary statistics:",
          "- Total components scanned",
          "- Commands found",
          "- Coordinators found",
          "- Agents found",
          "- Critical violations detected",
          "- Major violations detected",
          "- Minor violations detected",
          "- Script executes without Python errors",
          "- system_scan.json is created successfully",
          "- File contains valid JSON data",
          "- All system components are scanned",
          "- Statistics are extracted and reported",
          "- **Script execution error**: Report Python traceback to Main Claude",
          "- **File not created**: Report missing output file",
          "- **Invalid JSON**: Report data corruption issue",
          "- **Partial scan**: Report which components were missed",
          "- Always provide actionable error information",
          "- This agent only collects raw data via the Python script",
          "- Analysis and scoring are performed by downstream agents",
          "- The script is optimized for bulk file operations (100x faster than individual Read calls)",
          "- Output is structured JSON suitable for agent consumption"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "## MANDATORY WORKFLOW",
        "- 10 semantic extraction modules (YAML, I/O, prompts, execution, business logic, model hints, violat"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-cleanup-agent",
      "description": "Safely cleans up test artifacts while preserving important files",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-cleanup-agent.md",
      "component_type": "agent",
      "line_count": 187,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-cleanup-agent",
        "description": "Safely cleans up test artifacts while preserving important files",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Cleanup scope confirmation",
          "- Files to preserve list",
          "- Safety verification requirements"
        ],
        "file_reads": [
          "- `.claude/testing/reports/` - To verify reports are saved",
          "- `.claude/testing/cleanup_manifest.json` - Cleanup instructions (if exists)"
        ],
        "file_writes": [
          "- `.claude/testing/cleanup_log.txt` - Cleanup operation log",
          "- `.claude/testing/cleanup_complete.flag` - Completion indicator",
          "- `.claude/testing/temp/` - Temporary test files only",
          "- `.claude/testing/fixtures/` - Test fixtures (optional)",
          "- `.claude/testing/reports/` - All test reports",
          "- `.claude/testing/framework/` - Test framework files",
          "- `.claude/commands/` - ANY command files",
          "- `.claude/agents/` - ANY agent files",
          "- Any file outside `.claude/testing/`"
        ],
        "output_format": [
          "- Cleanup completion status",
          "- Files deleted count",
          "- Files preserved count",
          "- Cleanup log location",
          "- `.claude/commands/` - All command files including test commands",
          "- `.claude/agents/` - All agent files including test agents",
          "- `.claude/testing/reports/` - All generated reports",
          "- `.claude/testing/framework/` - Test framework files",
          "- `.claude/templates/` - System templates",
          "- Any `.md` files in `.claude/` root",
          "- `.claude/commands/architecture-test.md`",
          "- `.claude/commands/multi-coordinator-test.md`",
          "- Any file matching `.claude/commands/*test*.md`",
          "- .claude/testing/temp/: 47 files deleted",
          "- .claude/testing/fixtures/: 0 files (not requested)",
          "- .claude/testing/reports/: 5 files preserved",
          "- .claude/testing/framework/: All files preserved",
          "- .claude/commands/: Never touched (production)",
          "- .claude/agents/: Never touched (production)",
          "- Reports preserved: PASS",
          "- Commands intact: PASS",
          "- Agents intact: PASS",
          "- No production files affected: PASS",
          "- [x] Only temp files deleted",
          "- [x] All reports preserved",
          "- [x] No production files touched",
          "- [x] Cleanup log generated",
          "- [x] Safety validation passed",
          "- ONLY cleans `.claude/testing/temp/` by default",
          "- NEVER touches production files",
          "- ALWAYS preserves test reports",
          "- Has multiple safety checks",
          "- Logs everything for audit trail",
          "- Executes real Bash commands, no simulation"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Cleanup scope confirmation",
          "- Files to preserve list",
          "- Safety verification requirements"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Safety verification requirements",
        "### Step 3: Validation",
        "## Actual Execution Process",
        "## Critical Safety Rules"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-content-draft-agent",
      "description": "Generates initial draft content for human-in-loop testing",
      "tools": "Read, Write",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-content-draft-agent.md",
      "component_type": "agent",
      "line_count": 127,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-content-draft-agent",
        "description": "Generates initial draft content for human-in-loop testing",
        "tools": "Read, Write"
      },
      "io_spec": {
        "input_requirements": [
          "- Content requirements",
          "- Any revision feedback (if re-executing)",
          "- Output file path"
        ],
        "file_reads": [
          "- `.claude/testing/human_in_loop/workflow_state.json` (check for feedback)",
          "- `.claude/testing/human_in_loop/requirements.txt` (if exists)",
          "- Timestamp: {timestamp}",
          "- Ready for review: Yes",
          "- Point 1: Real agent execution demonstrated (not simulation)",
          "- Point 2: Actual file created on file system",
          "- Point 3: Content ready for human review and decision",
          "- Content generation",
          "- Revision handling",
          "- State awareness",
          "- File-based output"
        ],
        "file_writes": [
          "- `.claude/testing/human_in_loop/draft_v1.md` (initial draft)",
          "- `.claude/testing/human_in_loop/generation_log.txt` (process log)",
          "- This is the first execution",
          "- Initialize revision_num = 0",
          "- No feedback to incorporate",
          "- Extract revision_count for current phase",
          "- Extract any feedback to incorporate",
          "- Set revision_num accordingly",
          "- Agent executed: test-content-draft-agent"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Content requirements",
          "- Any revision feedback (if re-executing)",
          "- Output file path"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Content requirements",
        "- `.claude/testing/human_in_loop/workflow_state.json` (check for feedback)",
        "- `.claude/testing/human_in_loop/requirements.txt` (if exists)",
        "- `.claude/testing/human_in_loop/generation_log.txt` (process log)"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-content-enhancer-agent",
      "description": "Enhances draft content based on human approval for workflow testing",
      "tools": "Read, Write",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-content-enhancer-agent.md",
      "component_type": "agent",
      "line_count": 121,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-content-enhancer-agent",
        "description": "Enhances draft content based on human approval for workflow testing",
        "tools": "Read, Write"
      },
      "io_spec": {
        "input_requirements": [
          "- Input draft file path",
          "- Enhancement requirements",
          "- Any revision feedback",
          "- Output file path"
        ],
        "file_reads": [
          "- `.claude/testing/human_in_loop/draft_v1.md` (approved draft)",
          "- `.claude/testing/human_in_loop/workflow_state.json` (feedback)"
        ],
        "file_writes": [
          "- `.claude/testing/human_in_loop/draft_v2.md` (enhanced version)",
          "- `.claude/testing/human_in_loop/enhancement_log.txt` (process log)",
          "- Analyze the draft content",
          "- Add substantive improvements",
          "- Calculate real metrics",
          "- Enhance formatting",
          "- Clarity: Enhanced by 40%",
          "- Detail: Added 3 new sections",
          "- Structure: Improved organization",
          "- Readability: Optimized formatting",
          "- Word count: [increased from X to Y]",
          "- Sections: [increased from X to Y]",
          "- Quality score: [calculated from actual metrics]",
          "- Phase 2 sequential processing",
          "- Building on approved phase 1 output",
          "- Quality enhancement capabilities",
          "- Continued human review integration"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Input draft file path",
          "- Enhancement requirements",
          "- Any revision feedback",
          "- Output file path"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "task tool"
      ],
      "business_logic": [
        "description: Enhances draft content based on human approval for workflow testing",
        "### Input Requirements",
        "- Enhancement requirements",
        "- `.claude/testing/human_in_loop/workflow_state.json` (feedback)",
        "- `.claude/testing/human_in_loop/enhancement_log.txt` (process log)"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-content-finalizer-agent",
      "description": "Finalizes content for publication after human approvals in workflow test",
      "tools": "Read, Write",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-content-finalizer-agent.md",
      "component_type": "agent",
      "line_count": 142,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-content-finalizer-agent",
        "description": "Finalizes content for publication after human approvals in workflow test",
        "tools": "Read, Write"
      },
      "io_spec": {
        "input_requirements": [
          "- Input enhanced file path",
          "- Finalization requirements",
          "- Publication format preferences",
          "- Output file path"
        ],
        "file_reads": [
          "- `.claude/testing/human_in_loop/draft_v2.md` (approved enhanced version)",
          "- `.claude/testing/human_in_loop/workflow_state.json` (approval history)"
        ],
        "file_writes": [
          "- `.claude/testing/human_in_loop/final.md` (publication-ready)",
          "- `.claude/testing/human_in_loop/publication_metadata.json`",
          "- `.claude/testing/human_in_loop/finalization_log.txt`",
          "- Calculate actual checksum",
          "- Get real file size",
          "- Add current timestamps",
          "- Insert approval records",
          "- Version: FINAL",
          "- Approvals: Phase 1 [x] | Phase 2 [x] | Phase 3 (pending)",
          "- Quality Score: 95/100",
          "- Ready for: Publication",
          "---",
          "---",
          "- Phase 1: Human approved initial draft",
          "- Phase 2: Human approved enhancements",
          "- Phase 3: Awaiting final publication approval",
          "- Format: Markdown",
          "- Encoding: UTF-8",
          "- Checksum: [calculated]",
          "- Size: [file size]",
          "- Sequential agent execution",
          "- Multiple human approval points",
          "- Conditional workflow progression",
          "- State persistence across phases",
          "- 5-layer architecture compliance",
          "- Completion of multi-phase workflow",
          "- Building on multiple approvals",
          "- Publication preparation",
          "- Workflow validation success"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Input enhanced file path",
          "- Finalization requirements",
          "- Publication format preferences",
          "- Output file path"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "task tool"
      ],
      "business_logic": [
        "description: Finalizes content for publication after human approvals in workflow test",
        "### Input Requirements",
        "- Finalization requirements",
        "- `.claude/testing/human_in_loop/workflow_state.json` (approval history)",
        "Finalize approved content for publication, demonstrating the final phase of human-in-loop workflow."
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-data-analyzer-agent",
      "description": "Analyzes processed data and generates insights for multi-coordinator testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-data-analyzer-agent.md",
      "component_type": "agent",
      "line_count": 166,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-data-analyzer-agent",
        "description": "Analyzes processed data and generates insights for multi-coordinator testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Analysis type (statistical, trend, pattern)",
          "- Data source file path",
          "- Analysis depth level"
        ],
        "file_reads": [
          "- '.claude/testing/multi_coordinator_test/parsed_data.json' - Processed data from parser",
          "- '.claude/testing/multi_coordinator_test/config.json' - Analysis configuration"
        ],
        "file_writes": [
          "- '.claude/testing/multi_coordinator_test/analysis_results.json' - Analysis insights",
          "- '.claude/testing/multi_coordinator_test/analysis_log.txt' - Analysis log"
        ],
        "output_format": [
          "- Analysis completion status",
          "- Number of insights generated",
          "- Key findings summary",
          "- Recommendation count",
          "- [x] Successfully analyze processed data",
          "- [x] Generate statistical insights",
          "- [x] Detect data patterns",
          "- [x] Create actionable recommendations",
          "- [x] Prepare data for content generation phase",
          "- I build upon work from previous agents (parser)",
          "- I generate insights that Phase 2 coordinator will use",
          "- I demonstrate real analytical work in multi-coordinator flow",
          "- I create concrete analysis results for content generation"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Analysis type (statistical, trend, pattern)",
          "- Data source file path",
          "- Analysis depth level"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Analyzes processed data and generates insights for multi-coordinator testing",
        "### Input Requirements",
        "- '.claude/testing/multi_coordinator_test/parsed_data.json' - Processed data from parser",
        "I perform data analysis on processed data for multi-coordinator testing. When called by Main Claude,",
        "1. **Load Processed Data**: Read data from parser agent output"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-data-parser-agent",
      "description": "Parses and processes test data for multi-coordinator collaboration testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-data-parser-agent.md",
      "component_type": "agent",
      "line_count": 121,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-data-parser-agent",
        "description": "Parses and processes test data for multi-coordinator collaboration testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Data file path to process",
          "- Processing parameters (complexity, size)"
        ],
        "file_reads": [
          "- '.claude/testing/multi_coordinator_test/input_data.json' - Raw test data",
          "- '.claude/testing/multi_coordinator_test/config.json' - Processing configuration"
        ],
        "file_writes": [
          "- '.claude/testing/multi_coordinator_test/parsed_data.json' - Processed data results",
          "- '.claude/testing/multi_coordinator_test/parsing_log.txt' - Processing log"
        ],
        "output_format": [
          "- Processing completion status",
          "- Number of records processed",
          "- Output file paths",
          "- Processing statistics",
          "- [x] Successfully parse input data file",
          "- [x] Apply processing transformations",
          "- [x] Generate processing statistics",
          "- [x] Output valid JSON results",
          "- [x] Create processing log file",
          "- I perform real data processing work",
          "- I communicate results through file system",
          "- I support multi-coordinator collaboration by providing concrete results",
          "- I demonstrate actual agent work managed by coordinators"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Data file path to process",
          "- Processing parameters (complexity, size)",
          "- Output format requirements"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Parses and processes test data for multi-coordinator collaboration testing",
        "### Input Requirements",
        "- Data file path to process",
        "- Processing parameters (complexity, size)",
        "- Output format requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-environment-setup-agent",
      "description": "Creates complete test environment for Claude Code architecture validation",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-environment-setup-agent.md",
      "component_type": "agent",
      "line_count": 126,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-environment-setup-agent",
        "description": "Creates complete test environment for Claude Code architecture validation",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Test type to prepare for",
          "- Directory structure requirements",
          "- Component generation needs"
        ],
        "file_reads": [
          "- `.claude/agents/` - To understand current system structure",
          "- `.claude/commands/` - To analyze command patterns"
        ],
        "file_writes": [
          "- `.claude/testing/framework/` - Test framework files",
          "- `.claude/testing/fixtures/` - Test fixtures and components",
          "- `.claude/testing/reports/` - Report directory setup",
          "- `.claude/testing/temp/` - Temporary test files",
          "- `.claude/testing/environment_ready.flag` - Completion indicator"
        ],
        "output_format": [
          "- Environment setup completion status",
          "- Created directories list",
          "- Generated test components count",
          "- Ready flag location",
          "- Use Bash tool to create all required test directories",
          "- Ensure proper hierarchy for test isolation",
          "- Create test fixture files with Write tool",
          "- Generate both valid and violation test cases",
          "- Create configuration files",
          "- Set up test data structures",
          "- Test scenarios configuration",
          "- Validation thresholds",
          "- Cleanup scope definitions",
          "- Create agents with Task tool for violation testing",
          "- Create agents without Task tool for valid testing",
          "- Save to `.claude/testing/fixtures/test_agents/`",
          "- Write to `.claude/testing/environment_ready.flag`",
          "- Check `.claude/testing/framework` exists",
          "- Check `.claude/testing/fixtures` exists",
          "- Check `.claude/testing/reports` exists",
          "- Check `.claude/testing/temp` exists",
          "- Create completion flag with timestamp",
          "- Created 5 main directories",
          "- Generated 8 test components",
          "- Initialized test framework",
          "- Created test data files",
          "- Environment ready flag: .claude/testing/environment_ready.flag",
          "- I only set up the environment, not execute tests",
          "- I have no Task tool (not needed for my role)",
          "- I create fixtures but don't run them",
          "- I prepare everything for the test-execution-agent"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Test type to prepare for",
          "- Directory structure requirements",
          "- Component generation needs"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Creates complete test environment for Claude Code architecture validation",
        "### Input Requirements",
        "- Directory structure requirements",
        "## Actual Execution Process",
        "- Validation thresholds"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-execution-agent",
      "description": "Executes comprehensive Claude Code architecture validation tests",
      "tools": "Read, Write, Bash, Grep",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-execution-agent.md",
      "component_type": "agent",
      "line_count": 199,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-execution-agent",
        "description": "Executes comprehensive Claude Code architecture validation tests",
        "tools": "Read, Write, Bash, Grep"
      },
      "io_spec": {
        "input_requirements": [
          "- Test scenarios to execute",
          "- Test parameters and thresholds",
          "- Environment ready confirmation"
        ],
        "file_reads": [
          "- '.claude/testing/environment_ready.flag' - Environment status",
          "- '.claude/testing/fixtures/' - Test components",
          "- '.claude/agents/' - System components to validate",
          "- test name: 'io_isolation'",
          "- passed: true if atomic operations work",
          "- atomic_write: success status",
          "- concurrent_read: success status",
          "- Commands: Verifies line count limits",
          "- Coordinators: Checks line limits and JSON plan patterns",
          "- Agents: Validates line limits and single responsibility",
          "- File system: Confirms all communication via files",
          "- test name: 'five_layer_architecture'",
          "- passed: true if all layers compliant",
          "- layer_checks: individual layer results",
          "- test name: 'io_competition'",
          "- passed: true if race condition detected",
          "- writers_attempted: 5",
          "- writers_succeeded: actual count",
          "- demonstrates: importance of atomic operations",
          "- test name: 'path_resolution'",
          "- passed: true if all patterns resolve correctly",
          "- patterns_tested: number of patterns",
          "- results: detailed resolution results",
          "- test name: 'concurrency_limit'",
          "- passed: true if limit respected",
          "- tasks_launched: 15",
          "- max_concurrent: peak concurrent count",
          "- limit: 10",
          "- limit_respected: validation result",
          "- test name: 'error_handling'",
          "- passed: true if all scenarios handled",
          "- scenarios_tested: 3",
          "- all_handled: validation result",
          "- scenarios: detailed error handling results",
          "- [x] Zero recursion violations (no Task in coordinators/agents)",
          "- [x] >50% parallel execution efficiency",
          "- [x] 100% I/O operation success",
          "- [x] Complete 5-layer architecture compliance",
          "- I execute tests but don't coordinate them",
          "- I have no Task tool (not needed for execution)",
          "- I write results to files for the collector agent",
          "- I perform real tests, not simulations"
        ],
        "file_writes": [
          "- '.claude/testing/test_results.json' - Test execution results",
          "- '.claude/testing/logs/' - Execution logs",
          "- '.claude/testing/validation_reports/' - Detailed validation reports"
        ],
        "output_format": [
          "- Test execution summary",
          "- Pass/fail status for each test",
          "- Performance metrics",
          "- Violation details if any",
          "- test name: 'recursion_prevention'",
          "- passed: true/false",
          "- violations: list of files with Task tool",
          "- total_checked: number of files scanned",
          "- test name: 'parallel_execution'",
          "- passed: true if efficiency > 50%",
          "- parallel_time: execution time in parallel",
          "- serial_time: execution time in serial",
          "- efficiency_gain: percentage improvement",
          "- agents_tested: 5"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Test scenarios to execute",
          "- Test parameters and thresholds",
          "- Environment ready confirmation"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "atomic",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "description: Executes comprehensive Claude Code architecture validation tests",
        "### Input Requirements",
        "- '.claude/testing/validation_reports/' - Detailed validation reports",
        "### Test 1: Recursion Prevention Validation",
        "### Test 4: Five-Layer Architecture Validation"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-io-patterns-agent",
      "description": "Tests advanced I/O patterns including producer-consumer, shared reference, and version control",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-io-patterns-agent.md",
      "component_type": "agent",
      "line_count": 127,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-io-patterns-agent",
        "description": "Tests advanced I/O patterns including producer-consumer, shared reference, and version control",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Test scenario type (producer-consumer/shared-reference/version-control)",
          "- Test parameters and configuration",
          "- Expected behavior criteria"
        ],
        "file_reads": [
          "- '.claude/testing/temp/' - Test working directory",
          "- '.claude/testing/fixtures/' - Test data files"
        ],
        "file_writes": [
          "- '.claude/testing/io_patterns_results.json' - Pattern test results",
          "- '.claude/testing/temp/' - Test artifacts",
          "- '.claude/testing/logs/io_patterns.log' - Execution logs"
        ],
        "output_format": [
          "- Pattern test completion status",
          "- Success/failure for each pattern",
          "- Performance metrics",
          "- Recommendations",
          "- Use atomic write (temp file + rename)",
          "- Include timestamp and producer ID",
          "- Mark status as complete",
          "- Read from producer's output file",
          "- Process the data",
          "- Write consumer results atomically",
          "- test_producer_consumer_pattern()",
          "- test_shared_reference_pattern()",
          "- test_version_control_pattern()",
          "- test_atomic_operations()",
          "- test name",
          "- passed: true/false",
          "- details of the pattern tested",
          "- any violations found",
          "- [x] Producer-Consumer decoupling",
          "- [x] Shared Reference without conflicts",
          "- [x] Version Control tracking",
          "- [x] Atomic operations prevent corruption",
          "- [x] No direct agent-to-agent calls",
          "- I execute real I/O tests, not simulations",
          "- I have no Task tool (single responsibility)",
          "- I write comprehensive results for analysis",
          "- I validate all Data Layer patterns from ARCHITECTURE_data_layer.md"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Test scenario type (producer-consumer/shared-reference/version-control)",
          "- Test parameters and configuration",
          "- Expected behavior criteria"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "sequential",
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Expected behavior criteria",
        "1. Producer-Consumer pattern validation",
        "2. **Consumer Phase**: Read producer output and process"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-parallel-agent-a",
      "description": "Parallel test agent A for real concurrency testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-parallel-agent-a.md",
      "component_type": "agent",
      "line_count": 83,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-parallel-agent-a",
        "description": "Parallel test agent A for real concurrency testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Parallel execution test parameters",
          "- Work simulation duration",
          "- Result file path"
        ],
        "file_reads": [
          "- '.claude/testing/parallel_test_config.json' - Test configuration",
          "- '.claude/testing/temp/shared_data.json' - Shared test data"
        ],
        "file_writes": [
          "- '.claude/testing/temp/agent_a_result.json' - Test execution results",
          "- '.claude/testing/temp/agent_a_log.txt' - Execution timeline"
        ],
        "output_format": [
          "- Execution completion status",
          "- Performance metrics",
          "- File paths for result collection",
          "- Real computation work (not just sleep)",
          "- Concurrent access to shared data file",
          "- Generation of unique agent results",
          "- Atomic write of result JSON",
          "- Completion status",
          "- Execution duration",
          "- Result file path",
          "- Any errors encountered",
          "- [x] Complete execution without errors",
          "- [x] Generate valid result JSON",
          "- [x] Successfully access shared data",
          "- [x] Record accurate timing metrics",
          "- [x] Execute independently of other agents",
          "- I execute real work, not simulation",
          "- I operate independently from other agents",
          "- I communicate only through file system",
          "- I have no coordination responsibilities",
          "- I demonstrate true parallel execution capability"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Parallel execution test parameters",
          "- Work simulation duration",
          "- Result file path"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-parallel-agent-b",
      "description": "Parallel test agent B for real concurrency testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-parallel-agent-b.md",
      "component_type": "agent",
      "line_count": 83,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-parallel-agent-b",
        "description": "Parallel test agent B for real concurrency testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Parallel execution test parameters",
          "- Work simulation duration",
          "- Result file path"
        ],
        "file_reads": [
          "- '.claude/testing/parallel_test_config.json' - Test configuration",
          "- '.claude/testing/temp/shared_data.json' - Shared test data"
        ],
        "file_writes": [
          "- '.claude/testing/temp/agent_b_result.json' - Test execution results",
          "- '.claude/testing/temp/agent_b_log.txt' - Execution timeline"
        ],
        "output_format": [
          "- Execution completion status",
          "- Performance metrics",
          "- File paths for result collection",
          "- Different computation work from Agent A",
          "- Concurrent access to shared data file",
          "- Generation of unique agent results",
          "- Atomic write of result JSON",
          "- Completion status",
          "- Execution duration",
          "- Result file path",
          "- Any errors encountered",
          "- [x] Complete execution without errors",
          "- [x] Generate valid result JSON",
          "- [x] Successfully access shared data",
          "- [x] Record accurate timing metrics",
          "- [x] Execute independently of other agents",
          "- I execute real work, not simulation",
          "- I operate independently from other agents",
          "- I communicate only through file system",
          "- I have no coordination responsibilities",
          "- I demonstrate true parallel execution capability"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Parallel execution test parameters",
          "- Work simulation duration",
          "- Result file path"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-parallel-agent-c",
      "description": "Parallel test agent C for real concurrency testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-parallel-agent-c.md",
      "component_type": "agent",
      "line_count": 83,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-parallel-agent-c",
        "description": "Parallel test agent C for real concurrency testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Parallel execution test parameters",
          "- Work simulation duration",
          "- Result file path"
        ],
        "file_reads": [
          "- '.claude/testing/parallel_test_config.json' - Test configuration",
          "- '.claude/testing/temp/shared_data.json' - Shared test data"
        ],
        "file_writes": [
          "- '.claude/testing/temp/agent_c_result.json' - Test execution results",
          "- '.claude/testing/temp/agent_c_log.txt' - Execution timeline"
        ],
        "output_format": [
          "- Execution completion status",
          "- Performance metrics",
          "- File paths for result collection",
          "- Hash computation work (different from A and B)",
          "- Concurrent access to shared data file",
          "- Generation of unique agent results",
          "- Atomic write of result JSON",
          "- Completion status",
          "- Execution duration",
          "- Result file path",
          "- Any errors encountered",
          "- [x] Complete execution without errors",
          "- [x] Generate valid result JSON",
          "- [x] Successfully access shared data",
          "- [x] Record accurate timing metrics",
          "- [x] Execute independently of other agents",
          "- I execute real work, not simulation",
          "- I operate independently from other agents",
          "- I communicate only through file system",
          "- I have no coordination responsibilities",
          "- I demonstrate true parallel execution capability"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Parallel execution test parameters",
          "- Work simulation duration",
          "- Result file path"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-python-analyzer-agent",
      "description": "Analyzes transformed data from stage 2 using Python script for pipeline testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-python-analyzer-agent.md",
      "component_type": "agent",
      "line_count": 102,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-python-analyzer-agent",
        "description": "Analyzes transformed data from stage 2 using Python script for pipeline testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Input file path (stage2_data.json)",
          "- Analysis parameters",
          "- Output file paths"
        ],
        "file_reads": [
          "- `.claude/testing/python_pipeline/stage2_data.json` (transformed data)",
          "- `.claude/testing/python_pipeline/stage2_report.json` (transformation report)",
          "- `.claude/testing/python_pipeline/stage1_report.json` (original report)"
        ],
        "file_writes": [
          "- `.claude/testing/python_pipeline/data_analyzer.py` (Python script)",
          "- `.claude/testing/python_pipeline/stage3_final.json` (final analysis)",
          "- `.claude/testing/python_pipeline/stage3_report.json` (analysis report)",
          "- Loads stage2_data.json and all previous reports",
          "- Performs deep analysis on the transformed data",
          "- Validates data flow integrity across pipeline stages",
          "- Identifies patterns, outliers, and correlations",
          "- Saves comprehensive analysis to stage3_analysis.json",
          "- Saves report to stage3_report.json",
          "- Creates human-readable PIPELINE_SUMMARY.txt",
          "- Reading outputs from all previous stages",
          "- Comprehensive Python data analysis",
          "- Pipeline integrity verification",
          "- Final results preparation for Main Claude"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Input file path (stage2_data.json)",
          "- Analysis parameters",
          "- Output file paths"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "pipeline",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-python-generator-agent",
      "description": "Generates test data using Python script for pipeline testing",
      "tools": "Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-python-generator-agent.md",
      "component_type": "agent",
      "line_count": 80,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-python-generator-agent",
        "description": "Generates test data using Python script for pipeline testing",
        "tools": "Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Data size (small/medium/large)",
          "- Output file paths",
          "- Data generation parameters"
        ],
        "file_reads": [],
        "file_writes": [
          "- `.claude/testing/python_pipeline/data_generator.py` (Python script)",
          "- `.claude/testing/python_pipeline/stage1_data.json` (generated data)",
          "- `.claude/testing/python_pipeline/stage1_report.json` (generation report)",
          "- Generates test data based on size parameter",
          "- Calculates statistics on the data",
          "- Creates checksum for integrity",
          "- Saves data to stage1_data.json",
          "- Saves report to stage1_report.json",
          "- Python script creation and execution",
          "- Data generation with statistics",
          "- File output for next stage",
          "- Report generation for tracking"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Data size (small/medium/large)",
          "- Output file paths",
          "- Data generation parameters"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "pipeline",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-python-transformer-agent",
      "description": "Transforms data from stage 1 using Python script for pipeline testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-python-transformer-agent.md",
      "component_type": "agent",
      "line_count": 92,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-python-transformer-agent",
        "description": "Transforms data from stage 1 using Python script for pipeline testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Input file path (stage1_data.json)",
          "- Transformation parameters",
          "- Output file paths"
        ],
        "file_reads": [
          "- `.claude/testing/python_pipeline/stage1_data.json` (input data)",
          "- `.claude/testing/python_pipeline/stage1_report.json` (previous report)"
        ],
        "file_writes": [
          "- `.claude/testing/python_pipeline/data_transformer.py` (Python script)",
          "- `.claude/testing/python_pipeline/stage2_data.json` (transformed data)",
          "- `.claude/testing/python_pipeline/stage2_report.json` (transformation report)",
          "- Loads stage1_data.json and stage1_report.json",
          "- Applies multiple transformations (is_prime, value_squared, value_range, combined_score)",
          "- Calculates transformation statistics",
          "- Saves transformed data to stage2_data.json",
          "- Saves report to stage2_report.json",
          "- Reading output from previous agent",
          "- Python script data transformation",
          "- Maintaining data integrity",
          "- Passing enhanced data to next stage"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Input file path (stage1_data.json)",
          "- Transformation parameters",
          "- Output file paths"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "pipeline",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-rejection-logger-agent",
      "description": "Logs rejection reasons and workflow termination details for human-in-loop testing",
      "tools": "Read, Write",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-rejection-logger-agent.md",
      "component_type": "agent",
      "line_count": 131,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-rejection-logger-agent",
        "description": "Logs rejection reasons and workflow termination details for human-in-loop testing",
        "tools": "Read, Write"
      },
      "io_spec": {
        "input_requirements": [
          "- Rejection phase",
          "- Rejection reason",
          "- Workflow state at rejection",
          "- Files created before rejection"
        ],
        "file_reads": [
          "- `.claude/testing/human_in_loop/workflow_state.json`",
          "- Any draft files created before rejection"
        ],
        "file_writes": [
          "- `.claude/testing/human_in_loop/rejection_log.json`",
          "- `.claude/testing/human_in_loop/termination_report.md`",
          "- Phase where rejection occurred",
          "- Reason provided by human",
          "- Workflow progress at termination",
          "- Files created before rejection",
          "- **Phase**: Phase 2 - Content Enhancement",
          "- **Reason**: Quality standards not met",
          "- **Feedback**: \"Content lacks required technical depth\"",
          "- Phases Completed: 1 of 3",
          "- Files Created: 2",
          "- Human Interactions: 2",
          "- Final Decision: REJECT",
          "- draft_v1.md (Phase 1 - Approved)",
          "- draft_v2.md (Phase 2 - Rejected)",
          "- workflow_state.json (Complete history)",
          "- Human-in-loop control working correctly",
          "- Workflow termination on demand",
          "- State preservation on rejection",
          "- Graceful handling of negative feedback",
          "- Rejection paths execute correctly",
          "- Workflow terminates gracefully",
          "- Reasons are captured and logged",
          "- 5-layer architecture maintained throughout",
          "- Graceful workflow termination",
          "- Rejection reason capture",
          "- Audit trail maintenance",
          "- Test validation of negative paths"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Rejection phase",
          "- Rejection reason",
          "- Workflow state at rejection",
          "- Files created before rejection"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "description: Logs rejection reasons and workflow termination details for human-in-loop testing",
        "### Input Requirements",
        "- Workflow state at rejection",
        "- `.claude/testing/human_in_loop/workflow_state.json`",
        "Log workflow rejections and create termination reports for human-in-loop test validation."
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-report-generator-agent",
      "description": "Generates test reports based on data analysis results for multi-coordinator testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-report-generator-agent.md",
      "component_type": "agent",
      "line_count": 191,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-report-generator-agent",
        "description": "Generates test reports based on data analysis results for multi-coordinator testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Report type (summary, detailed, executive)",
          "- Analysis data source path"
        ],
        "file_reads": [
          "- '.claude/testing/multi_coordinator_test/analysis_results.json' - Analysis insights",
          "- '.claude/testing/multi_coordinator_test/parsed_data.json' - Original processed data",
          "- '.claude/testing/multi_coordinator_test/config.json' - Report configuration"
        ],
        "file_writes": [
          "- '.claude/testing/multi_coordinator_test/test_report.md' - Generated report",
          "- '.claude/testing/multi_coordinator_test/report_metadata.json' - Report metadata"
        ],
        "output_format": [
          "- Report generation completion status",
          "- Report sections generated",
          "- Output file paths",
          "- Report statistics",
          "- Total data points processed: {stats.get('total_count', 0)}",
          "- Average value: {stats.get('mean_value', 0):.2f}",
          "- Value range: {stats.get('min_value', 0)} to {stats.get('max_value', 0)}",
          "- Processing efficiency: Demonstrated successful multi-phase coordination",
          "- **Total Items**: {stats.get('total_count', 0)}",
          "- **Mean Value**: {stats.get('mean_value', 0):.2f}",
          "- **Median Value**: {stats.get('median_value', 0):.2f}",
          "- **Minimum Value**: {stats.get('min_value', 0)}",
          "- **Maximum Value**: {stats.get('max_value', 0)}",
          "- **Low Category**: {categories.get('low', 0)} items",
          "- **Medium Category**: {categories.get('medium', 0)} items",
          "- **High Category**: {categories.get('high', 0)} items",
          "- Data parsing completed successfully",
          "- Statistical analysis generated comprehensive insights",
          "- Phase dependencies handled correctly",
          "- Content generation based on actual analysis results",
          "- Report structure aligned with analysis findings",
          "- Inter-coordinator collaboration validated",
          "---",
          "- [x] Successfully generate comprehensive report",
          "- [x] Include all analysis findings",
          "- [x] Format report for readability",
          "- [x] Demonstrate Phase 2 dependency on Phase 1 results",
          "- [x] Validate multi-coordinator collaboration",
          "- I consume real results from Phase 1 analysis",
          "- I generate actual content based on concrete data",
          "- I demonstrate successful inter-phase collaboration",
          "- I validate that coordinators can manage complex workflows through agents"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Report type (summary, detailed, executive)",
          "- Analysis data source path",
          "- Output format preferences"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- '.claude/testing/multi_coordinator_test/parsed_data.json' - Original processed data",
        "- Total data points processed: {stats.get('total_count', 0)}",
        "- Processing efficiency: Demonstrated successful multi-phase coordination",
        "### Processing Statistics"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-result-collector-agent",
      "description": "Collects and synthesizes test results into comprehensive reports",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-result-collector-agent.md",
      "component_type": "agent",
      "line_count": 173,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-result-collector-agent",
        "description": "Collects and synthesizes test results into comprehensive reports",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Test execution completion confirmation",
          "- Report format requirements",
          "- Analysis depth level"
        ],
        "file_reads": [
          "- '.claude/testing/test_results.json' - Main test results",
          "- '.claude/testing/io_patterns_results.json' - I/O pattern test results",
          "- '.claude/testing/validation_report.json' - Format validation results",
          "- '.claude/testing/logs/' - Execution logs",
          "- '.claude/testing/validation_reports/' - Detailed reports",
          "- '.claude/testing/multi_coordinator_test/' - Multi-coordinator test results"
        ],
        "file_writes": [
          "- '.claude/testing/reports/final_report.md' - Comprehensive test report",
          "- '.claude/testing/reports/summary.json' - Summary statistics",
          "- '.claude/testing/reports/violations.md' - Violation details (if any)"
        ],
        "output_format": [
          "- Test summary statistics",
          "- Critical findings",
          "- Report file locations",
          "- Next steps recommendations",
          "- Recursion violations (CRITICAL)",
          "- Parallel execution failures (HIGH)",
          "- I/O isolation breaches (HIGH)",
          "- Date and timestamp",
          "- Overall status (PASS/FAIL)",
          "- Success rate percentage",
          "- Critical issue count",
          "- Files scanned",
          "- Violations found",
          "- Specific files with Task tool",
          "- Efficiency gain percentage",
          "- Parallel vs serial time",
          "- Performance metrics",
          "- Atomic operation success",
          "- Concurrent access results",
          "- Pattern compliance",
          "- Each layer's compliance status",
          "- Line count violations",
          "- Structure issues",
          "- Phase 1 completion status",
          "- Phase 2 dependency handling",
          "- Data passing success",
          "- Test execution times",
          "- Resource utilization",
          "- Efficiency measurements",
          "- Actionable improvements",
          "- Priority fixes",
          "- Next steps",
          "- Total tests run",
          "- Tests passed/failed",
          "- Success rate",
          "- Critical issues count",
          "- Health score",
          "- Timestamp",
          "- Categorized violations",
          "- Severity levels",
          "- Specific files affected",
          "- Remediation steps",
          "- Base score: Success rate * 100",
          "- Penalties:",
          "- CRITICAL issues: -30 points each",
          "- HIGH issues: -15 points each",
          "- MEDIUM issues: -5 points each",
          "- Final score: Max(0, Min(100, adjusted_score))",
          "- [x] Gathers all test results",
          "- [x] Analyzes multi-coordinator collaboration",
          "- [x] Generates comprehensive report",
          "- [x] Provides actionable recommendations",
          "- [x] Calculates system health score",
          "- I synthesize but don't execute tests",
          "- I have no Task tool (not needed for collection)",
          "- I create readable reports for humans",
          "- I provide clear next-step recommendations"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Test execution completion confirmation",
          "- Report format requirements",
          "- Analysis depth level"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "parallel",
        "atomic",
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "- Report format requirements",
        "- '.claude/testing/validation_report.json' - Format validation results",
        "- '.claude/testing/validation_reports/' - Detailed reports",
        "## Report Generation Process"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "single_task"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-state-updater-agent",
      "description": "Updates workflow state after human responses in human-in-loop testing",
      "tools": "Read, Write",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-state-updater-agent.md",
      "component_type": "agent",
      "line_count": 132,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-state-updater-agent",
        "description": "Updates workflow state after human responses in human-in-loop testing",
        "tools": "Read, Write"
      },
      "io_spec": {
        "input_requirements": [
          "- Current phase",
          "- Human response (APPROVE/REJECT/REVISE)",
          "- Feedback (if REVISE or REJECT)",
          "- Timestamp"
        ],
        "file_reads": [
          "- `.claude/testing/human_in_loop/workflow_state.json` (current state)"
        ],
        "file_writes": [
          "- `.claude/testing/human_in_loop/workflow_state.json` (updated state)",
          "- `.claude/testing/human_in_loop/response_history.log` (audit trail)",
          "- Verify current phase matches expected phase",
          "- Check revision count doesn't exceed maximum (3)",
          "- Ensure workflow isn't already terminated",
          "- Complete audit trail of human decisions",
          "- State consistency across interactions",
          "- Proper handling of all response types",
          "- Recovery capability if workflow interrupted"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Current phase",
          "- Human response (APPROVE/REJECT/REVISE)",
          "- Feedback (if REVISE or REJECT)",
          "- Timestamp"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "description: Updates workflow state after human responses in human-in-loop testing",
        "### Input Requirements",
        "- `.claude/testing/human_in_loop/workflow_state.json` (current state)",
        "- `.claude/testing/human_in_loop/workflow_state.json` (updated state)",
        "Update workflow state after each human interaction to maintain accurate workflow history."
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-summary-generator-agent",
      "description": "Generates executive summaries from analysis results for multi-coordinator testing",
      "tools": "Read, Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-summary-generator-agent.md",
      "component_type": "agent",
      "line_count": 171,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-summary-generator-agent",
        "description": "Generates executive summaries from analysis results for multi-coordinator testing",
        "tools": "Read, Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Summary type (executive, technical, overview)",
          "- Source data file paths",
          "- Target audience specifications"
        ],
        "file_reads": [
          "- '.claude/testing/multi_coordinator_test/analysis_results.json' - Analysis insights",
          "- '.claude/testing/multi_coordinator_test/test_report.md' - Full report content",
          "- '.claude/testing/multi_coordinator_test/config.json' - Summary configuration"
        ],
        "file_writes": [
          "- '.claude/testing/multi_coordinator_test/executive_summary.json' - Summary data",
          "- '.claude/testing/multi_coordinator_test/summary_highlights.txt' - Key highlights"
        ],
        "output_format": [
          "- Summary generation completion status",
          "- Summary sections created",
          "- Key metrics extracted",
          "- Output file locations",
          "- Multi-coordinator collaboration: SUCCESSFUL",
          "- Data processing phases: {summary['key_metrics']['phases_completed']} completed",
          "- Total data points processed: {summary['key_metrics']['total_data_points']}",
          "- Coordination efficiency: {summary['business_impact']['coordination_efficiency']}",
          "- Phase 1 coordinator managed data processing agents effectively",
          "- Phase 2 coordinator successfully consumed Phase 1 outputs",
          "- Inter-coordinator communication via file system: VALIDATED",
          "- Agent management under coordinator guidance: CONFIRMED",
          "- Workflow automation capability: {summary['business_impact']['workflow_automation']}",
          "- System scalability: {summary['business_impact']['scalability']}",
          "- Quality assurance: {summary['business_impact']['quality_assurance']}",
          "---",
          "- [x] Generate executive-level summary",
          "- [x] Extract key business metrics",
          "- [x] Validate collaboration success",
          "- [x] Provide actionable next steps",
          "- [x] Demonstrate summary generation from real analysis",
          "- I synthesize results from multiple analysis sources",
          "- I provide executive-level insights for decision making",
          "- I validate the success of multi-coordinator collaboration",
          "- I demonstrate that Phase 2 agents can build upon Phase 1 results effectively"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Summary type (executive, technical, overview)",
          "- Source data file paths",
          "- Target audience specifications"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "'processing_efficiency': 'high',",
        "f\"Successfully processed {stats.get('total_count', 0)} data points through multi-coordinator collabo",
        "\"Validated multi-coordinator architecture for complex workflows\"",
        "'workflow_automation': 'demonstrated',"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-validation-agent",
      "description": "Validates documentation format standards and JSON plan structures",
      "tools": "Read, Grep",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-validation-agent.md",
      "component_type": "agent",
      "line_count": 161,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-validation-agent",
        "description": "Validates documentation format standards and JSON plan structures",
        "tools": "Read, Grep"
      },
      "io_spec": {
        "input_requirements": [
          "- Validation type (format/json/documentation)",
          "- Files or directories to validate",
          "- Standards to check against"
        ],
        "file_reads": [
          "- '.claude/agents/' - Agent and coordinator files",
          "- '.claude/commands/' - Command files",
          "- '.claude/testing/' - Test outputs for validation",
          "- Coordinators: Planning I/O, JSON Plan Response",
          "- test name: 'documentation_completeness'",
          "- passed: true if complete",
          "- files_checked: count",
          "- issues: missing sections per file",
          "- claude-haiku-3-5-20241022",
          "- claude-sonnet-4-20250514",
          "- claude-opus-4-1-20250805",
          "- test name: 'model_configuration'",
          "- passed: true if all valid",
          "- files_checked: count",
          "- issues: deprecated or invalid models",
          "- No Task() calls",
          "- No \"execute agent\" patterns",
          "- No \"run agent\" patterns",
          "- No \"coordinate workflow\" patterns",
          "- No \"orchestrate task\" patterns",
          "- test name: 'component_interactions'",
          "- passed: true if no violations",
          "- violations: list of improper interactions",
          "- [x] Path formats follow standards",
          "- [x] JSON plans properly structured",
          "- [x] Documentation complete",
          "- [x] Model configurations valid",
          "- [x] Component interactions correct",
          "- Maintainability",
          "- Consistency",
          "- Clarity",
          "- Proper component communication"
        ],
        "file_writes": [
          "- '.claude/testing/validation_report.json' - Validation results",
          "- '.claude/testing/format_violations.md' - Detailed violations"
        ],
        "output_format": [
          "- Validation pass/fail status",
          "- Violation count and details",
          "- Compliance percentage",
          "- Improvement recommendations",
          "- Detect double backticks (wrong)",
          "- Detect emojis in paths (wrong)",
          "- Detect quoted paths instead of backticks (wrong)",
          "- test name: 'path_format_standards'",
          "- passed: true if no violations",
          "- files_checked: count",
          "- violations: detailed list",
          "- compliance_rate: percentage",
          "- plan_name",
          "- phases",
          "- execution_strategy",
          "- test name: 'json_plan_structure'",
          "- passed: true if all valid",
          "- coordinators_checked: count",
          "- invalid_structures: list of issues"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Validation type (format/json/documentation)",
          "- Files or directories to validate",
          "- Standards to check against"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "coordinator",
        "task tool"
      ],
      "business_logic": [
        "name: test-validation-agent",
        "tools: Read, Grep  # NO Task tool - validation only agent",
        "# Test Validation Agent",
        "### Input Requirements",
        "- Validation type (format/json/documentation)"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "potential_broken_references",
        "deprecated_model_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "test-workflow-initializer-agent",
      "description": "Initializes workflow state for human-in-loop testing",
      "tools": "Write, Bash",
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\test-workflow-initializer-agent.md",
      "component_type": "agent",
      "line_count": 108,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "test-workflow-initializer-agent",
        "description": "Initializes workflow state for human-in-loop testing",
        "tools": "Write, Bash"
      },
      "io_spec": {
        "input_requirements": [
          "- Workflow ID",
          "- Test scenario type (simple/complex/iterative)",
          "- Initial configuration"
        ],
        "file_reads": [],
        "file_writes": [
          "- `.claude/testing/human_in_loop/workflow_state.json` (initial state)",
          "- `.claude/testing/human_in_loop/config.json` (test configuration)",
          "- Workflow state exists before other agents try to read it",
          "- Clean initialization for each test run",
          "- Proper directory structure",
          "- No confusion between test runs"
        ],
        "output_format": []
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Workflow ID",
          "- Test scenario type (simple/complex/iterative)",
          "- Initial configuration"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "task tool"
      ],
      "business_logic": [
        "name: test-workflow-initializer-agent",
        "description: Initializes workflow state for human-in-loop testing",
        "# Test Workflow Initializer Agent",
        "### Input Requirements",
        "- `.claude/testing/human_in_loop/workflow_state.json` (initial state)"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "potential_broken_references",
        "malformed_tools_config"
      ]
    },
    {
      "name": "topic-explorer",
      "description": "PROACTIVE - Research and identify trending topics, themes, and story concepts within the target genre. Use PROACTIVELY when conversation mentions story ideas, themes, what to write about, plot concepts",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Execute strategic web searches to discover trending themes and story concepts in target genre, identify market gaps and opportunities, analyze what's working with readers, generate topic options with potential and confidence scores, save comprehensive analysis to knowledge base",
      "file_path": ".claude/agents\\topic-explorer.md",
      "component_type": "agent",
      "line_count": 473,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "topic-explorer",
        "description": "PROACTIVE - Research and identify trending topics, themes, and story concepts within the target genre. Use PROACTIVELY when conversation mentions story ideas, themes, what to write about, plot concepts",
        "thinking": "Execute strategic web searches to discover trending themes and story concepts in target genre, identify market gaps and opportunities, analyze what's working with readers, generate topic options with potential and confidence scores, save comprehensive analysis to knowledge base",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-sonnet-4-20250514"
      },
      "io_spec": {
        "input_requirements": [
          "- genre: Target genre for topic research (e.g., \"science fiction\", \"romance\", \"thriller\")",
          "- output_directory: Where to save results (default: knowledge_base/topics)",
          "- context: Background information about the project or specific interests",
          "- focus_areas: Specific aspects to emphasize (themes, plot concepts, character archetypes)"
        ],
        "file_reads": [
          "- No input files required (web research only)",
          "- May reference existing knowledge base for context awareness"
        ],
        "file_writes": [
          "- `{output_directory}/topic_analysis_{timestamp}.json` - Complete topic analysis with trending themes, market gaps, and recommendations in single comprehensive file",
          "- `.tmp` files for atomic operations during save",
          "- Automatic cleanup after successful completion"
        ],
        "output_format": [
          "- {number} trending topics identified with confidence scores",
          "- {number} market gaps discovered",
          "- {number} actionable themes developed",
          "- Overall market relevance: {score}/1.0",
          "- {topic_analysis_file_path}",
          "- Handle multiple input formats for compatibility:",
          "- Write tool will automatically create directories when saving files",
          "- Never use Read tool on directories (causes EISDIR error)",
          "- Generate timestamp for unique filename",
          "- Previous conversation context for targeted research",
          "- Specific genre parameters or constraints",
          "- Focus areas (themes vs plot concepts vs character types)",
          "- Primary search angles (trending topics, reader preferences, successful themes)",
          "- Target sources (publishing industry, reader communities, bestseller analysis)",
          "- Expected data types (quantitative trends, qualitative themes, reader feedback)",
          "- Success criteria (topic diversity, market evidence, actionability)",
          "- WebSearch: \"trending {genre} themes 2024 2025 popular reader preferences\"",
          "- Target: What topics and themes are currently resonating with readers",
          "- WebSearch: \"bestselling {genre} books themes topics 2024 what readers want\"",
          "- Target: Successful story concepts and proven themes",
          "- WebSearch: \"{genre} underserved themes market gaps emerging trends\"",
          "- Target: Identify opportunities not yet saturated",
          "- WebSearch: \"{genre} readers discussion forums goodreads themes want to read\"",
          "- Target: Direct reader preference data and community trends",
          "- Use WebFetch on publishing industry reports, major review sites",
          "- Extract specific theme patterns and reader preference data",
          "- Validate trend information with publication dates and credibility",
          "- Consistently popular themes across multiple sources",
          "- Emerging trends not yet saturated",
          "- Underserved niches with reader demand",
          "- Seasonal or cyclical topic patterns",
          "- Current market saturation level (oversaturated/balanced/underserved)",
          "- Reader demand indicators (search volume, discussion activity)",
          "- Competition analysis (how many recent releases in this theme)",
          "- Differentiation potential (unique angles available)",
          "- Reader Interest (0.3): Evidence of reader demand and engagement",
          "- Market Gap (0.3): Degree of underserved market opportunity",
          "- Trend Strength (0.2): How strong/consistent the trend evidence is",
          "- Differentiation Potential (0.1): Ability to create unique approaches",
          "- Accessibility (0.1): How achievable for typical author to execute",
          "- Hot Trends: Currently popular with strong evidence",
          "- Emerging Themes: Early stage but growing interest",
          "- Underserved Niches: Reader demand but limited supply",
          "- Evergreen Concepts: Consistently popular over time",
          "- Crossover Opportunities: Themes from related genres gaining traction",
          "- Core Theme: Central concept and appeal",
          "- Market Evidence: Specific data supporting the trend",
          "- Differentiation Angles: Unique approaches to explore",
          "- Target Audience: Reader demographics most interested",
          "- Execution Suggestions: Practical ways to develop the concept",
          "- {number} hot trends identified with avg opportunity score {score}",
          "- {number} market gaps discovered with high potential",
          "- {number} crossover opportunities identified",
          "- Overall research confidence: {overall_confidence}/1.0",
          "- **Input**: Genre and research scope from Main Claude",
          "- **Processing**: Multi-query web research with gap analysis",
          "- **Output**: Structured topic recommendations saved to knowledge_base directory",
          "- **Status**: Confidence-scored insights with actionable recommendations",
          "- **Never use Task tool** (I don't have it - prevents recursion)",
          "- **Never call other agents** (only Main Claude orchestrates)",
          "- **Never recommend oversaturated themes without differentiation** (quality standards)",
          "- **Never skip opportunity scoring** (all topics must be assessed for viability)",
          "- **Never assume file paths** (always use provided output directory)",
          "- **Never skip atomic operations** (data integrity critical)",
          "- **Execute comprehensive topic research** using strategic multi-query approach targeting reader preferences",
          "- **Identify genuine market opportunities** through gap analysis and trend correlation",
          "- **Calculate reliable opportunity scores** based on demand evidence and market saturation",
          "- **Handle genre-specific research effectively** with appropriate source targeting",
          "- **Organize insights systematically** in structured, actionable format",
          "- **Provide differentiation strategies** for identified topics and themes",
          "- Opportunity scores >= 0.70 for recommended topics",
          "- Multiple sources analyzed (minimum 8 for reliable trends)",
          "- Structured JSON files created with comprehensive topic metadata",
          "- Clear differentiation angles provided for each recommendation",
          "- API failures reported with retry recommendations",
          "- Low confidence results flagged with quality warnings",
          "- User decision points for quality threshold violations"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- genre: Target genre for topic research (e.g., \"science fiction\", \"romance\", \"thriller\")",
          "- output_directory: Where to save results (default: knowledge_base/topics)",
          "- context: Background information about the project or specific interests",
          "- focus_areas: Specific aspects to emphasize (themes, plot concepts, character archetypes)"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "### Input Requirements",
        "User decision required: Accept results or request additional research?\"",
        "### Step 1: Input Processing (with Defensive Handling)",
        "- Success criteria (topic diversity, market evidence, actionability)",
        "\"user_decision_required\": true"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "trend-analyzer",
      "description": "Use PROACTIVELY when conversation mentions market trends, what's popular, competition, or business opportunities - automatically research via WebSearch and save insights to knowledge base",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Execute strategic web searches to gather market intelligence, analyze trend patterns, validate data quality, calculate confidence scores based on source credibility and data consistency, save to knowledge_base with atomic operations and comprehensive error handling",
      "file_path": ".claude/agents\\trend-analyzer.md",
      "component_type": "agent",
      "line_count": 470,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "trend-analyzer",
        "description": "Use PROACTIVELY when conversation mentions market trends, what's popular, competition, or business opportunities - automatically research via WebSearch and save insights to knowledge base",
        "thinking": "Execute strategic web searches to gather market intelligence, analyze trend patterns, validate data quality, calculate confidence scores based on source credibility and data consistency, save to knowledge_base with atomic operations and comprehensive error handling",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-sonnet-4-20250514"
      },
      "io_spec": {
        "input_requirements": [
          "- search_scope: Specific area to research (e.g., \"AI market trends\", \"renewable energy adoption\")",
          "- output_directory: Where to save results (default: knowledge_base/trends)",
          "- context: Background information to focus research",
          "- confidence_threshold: Minimum acceptable confidence level (default: 0.70)"
        ],
        "file_reads": [
          "- No input files required (web research only)",
          "- May read existing knowledge base for context awareness"
        ],
        "file_writes": [
          "- `{output_directory}/trend_analysis_{timestamp}.json` - Complete analysis with research data, executive summary, and recommendations in single file",
          "- `.tmp` files for atomic operations during save",
          "- Automatic cleanup after successful completion"
        ],
        "output_format": [
          "- {primary trends with confidence scores}",
          "- {quantitative metrics discovered}",
          "- Overall confidence: {score}/1.0",
          "- {research_file_path}",
          "- {summary_file_path}",
          "- Confidence score >= 0.70 (or specified threshold)",
          "- Multiple sources analyzed (minimum 5 for reliable trends)",
          "- Structured JSON files created with comprehensive metadata",
          "- API failures reported with retry recommendations",
          "- Low confidence results flagged with quality warnings",
          "- User decision points for quality threshold violations"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- search_scope: Specific area to research (e.g., \"AI market trends\", \"renewable energy adoption\")",
          "- output_directory: Where to save results (default: knowledge_base/trends)",
          "- context: Background information to focus research",
          "- confidence_threshold: Minimum acceptable confidence level (default: 0.70)"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic",
        "task tool"
      ],
      "business_logic": [
        "description: Use PROACTIVELY when conversation mentions market trends, what's popular, competition, ",
        "- **Market Research Methodology** - Professional search strategy and data validation techniques",
        "### Step 1: Input Processing (with Defensive Handling)",
        "- Quality requirements or confidence thresholds",
        "- Success criteria (coverage depth, source diversity)"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": "file_based"
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    },
    {
      "name": "visual-creator",
      "description": "",
      "tools": [],
      "model": "",
      "thinking": "",
      "file_path": ".claude/agents\\visual-creator.md",
      "component_type": "agent",
      "line_count": 264,
      "has_unicode": false,
      "yaml_frontmatter": {},
      "io_spec": {
        "input_requirements": [
          "- Article file path to analyze (e.g., \".claude/data/articles/ai_realist/articles/20250118_143022_ai_risks/drafts/final.md\")",
          "- Output directory path for visual guide",
          "- Optional: Platform requirements specification"
        ],
        "file_reads": [
          "- `{article_path}` - Article content for visual analysis",
          "- Referenced files in article content if needed"
        ],
        "file_writes": [
          "- `{output_directory}/visual_production_guide.md` - Complete production guide",
          "- Temporary file: `{output_path}.tmp` for atomic operations"
        ],
        "output_format": [
          "- \"Visual production guide created successfully\"",
          "- \"Output saved to: [file_path]\"",
          "- \"Total images planned: [number]\"",
          "- \"Estimated cost: $[amount]\"",
          "- Complete visual guide with platform specifications",
          "- Optimized Banana prompts for each image",
          "- Post-processing instructions provided",
          "- Production workflow documented",
          "- Missing article file: Clear error with path",
          "- Invalid article format: Format validation message",
          "- Output directory issues: Directory creation guidance",
          "- WHY each image is needed (what argument it supports)",
          "- WHERE it goes in the article (specific placement)",
          "- WHAT platforms require (exact specifications)",
          "- WHAT Banana can deliver (realistic expectations)",
          "- HOW to process the output (bridging the gap)",
          "- PROMPTS to generate the images",
          "- **Article Type**: [Warning/Analysis/Solution]",
          "- **Total Images Needed**: [Number]",
          "- **Estimated Generation Cost**: $[0.039 x images]",
          "- **Post-Processing Required**: [Yes/No - what type]",
          "- **Time Estimate**: [15 min generation + X min processing]",
          "- **Main Argument**: [Core thesis]",
          "- **Supporting Data**:",
          "- [Key statistic 1] -> needs visualization",
          "- [Key statistic 2] -> needs chart",
          "- [Framework] -> needs diagram",
          "- **Emotional Arc**: [How reader should feel]",
          "- **Visual Strategy**: [How images reinforce message]",
          "---",
          "- **Mood**: Professional concern without panic",
          "- **Color Palette**: Navy blue (trust), red accents (warning), white space",
          "- **Style Reference**: McKinsey report meets Bloomberg terminal",
          "- **Composition**: Wide scene that also works when cropped square",
          "- **Critical Elements**: [Specific elements from article]",
          "- [ ] Main subject visible in center 600x600 (for Substack crop)",
          "- [ ] Extended edges look natural",
          "- [ ] Colors match AI Realist brand",
          "- [ ] No text or numbers visible",
          "- [ ] Professional, not decorative",
          "---",
          "- **Type**: Bar chart comparison",
          "- **Data Points**: Expected ROI (300%) vs Actual ROI (12%)",
          "- **Color Coding**: Green (promise) vs Red (reality)",
          "- **Style**: Clean, minimal, Bloomberg-style",
          "- Banana handles simple compositions well",
          "- Square format usually succeeds",
          "- May need to adjust color balance for brand consistency",
          "---",
          "---",
          "- [ ] Cover works at all platform sizes",
          "- [ ] Data visualizations are clear",
          "- [ ] Brand consistency maintained",
          "- [ ] No text/number artifacts",
          "- [ ] Files optimized for web",
          "- **Generation**: 3-4 images x $0.039 = ~$0.15",
          "- **Time**: 15 min generation + 15 min processing = 30 min total",
          "- **Tools Needed**: Gemini access + Basic image editor",
          "- Increase click-through rate by 133% (per data)",
          "- Support article's skeptical positioning",
          "- Look professional without being generic",
          "- Work across all platforms with minimal adjustment",
          "---"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Article file path to analyze (e.g., \".claude/data/articles/ai_realist/articles/20250118_143022_ai_risks/drafts/final.md\")",
          "- Output directory path for visual guide",
          "- Optional: Platform requirements specification"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic"
      ],
      "business_logic": [
        "description: Generate comprehensive visual production guide with platform specs, Banana prompts, and",
        "thinking: Analyze article structure for visual moments, map platform requirements vs AI capabilities",
        "You are a visual production specialist for The AI Realist content series. Your role is to analyze ar",
        "### Input Requirements",
        "- Optional: Platform requirements specification"
      ],
      "violations": [
        "CRITICAL: Subagent has Task tool (recursion risk)"
      ],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "potential_broken_references"
      ]
    },
    {
      "name": "voice-analyzer",
      "description": "PROACTIVE - Comprehensive voice analysis generating complete documentation with 15 samples per voice, sentence patterns, vocabulary tiers, dialogue systems, and implementation guides",
      "tools": "Read, Write, WebSearch, WebFetch",
      "model": "claude-sonnet-4-20250514",
      "thinking": "Research bestselling authors in genre to identify successful voice patterns using 3-3-3+1 framework, create three distinct voice options with extensive samples and comprehensive style documentation, generate complete voice implementation system",
      "file_path": ".claude/agents\\voice-analyzer.md",
      "component_type": "agent",
      "line_count": 449,
      "has_unicode": false,
      "yaml_frontmatter": {
        "name": "voice-analyzer",
        "description": "PROACTIVE - Comprehensive voice analysis generating complete documentation with 15 samples per voice, sentence patterns, vocabulary tiers, dialogue systems, and implementation guides",
        "thinking": "Research bestselling authors in genre to identify successful voice patterns using 3-3-3+1 framework, create three distinct voice options with extensive samples and comprehensive style documentation, generate complete voice implementation system",
        "tools": "Read, Write, WebSearch, WebFetch",
        "model": "claude-sonnet-4-20250514"
      },
      "io_spec": {
        "input_requirements": [
          "- Genre specification for voice analysis",
          "- Conversation context for voice matching",
          "- Completeness level: comprehensive documentation required",
          "- Output directory path for saving analysis"
        ],
        "file_reads": [
          "- [Knowledge base: existing voice analyses for reference]",
          "- [Framework docs: AUTHOR_VOICE_FRAMEWORK.md for 3-3-3+1 model]"
        ],
        "file_writes": [
          "- `knowledge_base/voice/comprehensive_voice_analysis_{timestamp}.json` (atomic .tmp + move)"
        ],
        "output_format": [
          "- Success confirmation with comprehensive analysis file path",
          "- Summary of 3 voice options with complete documentation systems",
          "- Implementation guide overview and consistency framework",
          "---",
          "- Search: \"bestselling [genre] authors voice analysis 2020-2024\"",
          "- Search: \"[genre] series consistency author voice development\"",
          "- Search: \"Caribbean authenticity in [genre] writing successful examples\"",
          "- Search: \"long-running [genre] series voice consistency examples\"",
          "- Extract 15 samples per author covering: opening, action, dialogue, introspection, climax",
          "- Map complete 3-3-3+1 framework with sub-elements",
          "- Identify sentence pattern variations (minimum 12 distinct types)",
          "- Document vocabulary usage across complexity levels",
          "- Analyze dialogue attribution and character voice differentiation",
          "- **Voice Identity**: Name, archetype, market positioning",
          "- **Complete Framework**: All 3-3-3+1 elements with sub-specifications",
          "- **15 Sample Collection**: Varied contexts demonstrating voice consistency",
          "- **12 Sentence Patterns**: Structural examples with usage guidelines",
          "- **Vocabulary Tier System**: Basic/Elevated/Specialized with 100+ examples each",
          "- **Dialogue System**: Character type differentiation with attribution patterns",
          "- **Implementation Guide**: Dos/don'ts with specific examples",
          "- **Series Consistency**: Framework for maintaining voice across multiple books",
          "- **Cultural Integration**: Environmental terminology and authenticity guidelines",
          "- Minimum 20 bestselling authors with sustained success (5+ successful titles)",
          "- Recent market validation (2020-2024) with cultural authenticity",
          "- Critical recognition and reader community loyalty",
          "- Diverse representation within Caribbean and cultural literary traditions",
          "- Long-running series analysis for voice consistency patterns",
          "- 15 sample passages per voice option across varied contexts",
          "- 12 distinct sentence patterns with structural analysis and usage guidelines",
          "- Quantitative vocabulary analysis across three complexity tiers",
          "- Qualitative cultural authenticity assessment with sensitivity protocols",
          "- Market performance correlation with voice characteristics",
          "- Series sustainability analysis for long-term character development",
          "- Each voice targets distinct market segments with clear differentiation",
          "- Complete 3-3-3+1 framework documentation with cultural integration",
          "- 15 authentic sample passages demonstrating voice range and consistency",
          "- Implementation guide with specific dos/don'ts and consistency markers",
          "- Cultural sensitivity protocol with authenticity maintenance guidelines",
          "- Series development framework for 10+ book character voice evolution",
          "- Expand to related Caribbean and cultural literary traditions",
          "- Include diaspora author voices for broader perspective",
          "- Use reader community feedback for authenticity validation",
          "- Consult cultural sensitivity readers and community members",
          "- Flag confidence scores and cultural authenticity limitations",
          "- Document cultural element usage guidelines and authenticity protocols",
          "- Create sensitivity checklists for respectful representation",
          "- Balance cultural specificity with universal theme accessibility",
          "- Provide ongoing cultural research and community consultation guidance",
          "- Address potential cultural appropriation concerns with clear guidelines",
          "- Research breadth: 20+ authors with deep voice pattern analysis",
          "- Cultural authenticity: Community consultation and sensitivity reader validation",
          "- Pattern confidence: >0.85 for established cultural literary traditions",
          "- Sample authenticity: Voice consistency across 15 varied context examples",
          "- Implementation usability: Clear guidelines enabling consistent voice maintenance",
          "- All 3-3-3+1 framework elements with cultural integration specifications",
          "- 15 sample passages per voice demonstrating range and authenticity",
          "- 12 sentence patterns with structural analysis and usage guidelines",
          "- Three-tier vocabulary system with 200+ examples per tier",
          "- Dialogue differentiation system for character types and cultural authenticity",
          "- Implementation guide with specific dos/don'ts and consistency maintenance",
          "- Series development framework for long-term voice evolution",
          "- Environmental terminology guide for authentic Caribbean representation",
          "- Cultural sensitivity protocol with ongoing authenticity maintenance guidelines",
          "- Primary: `comprehensive_voice_analysis_{timestamp}.json`",
          "- Genre-specific: `comprehensive_voice_analysis_{genre}_{timestamp}.json`",
          "- Cultural-specific: `comprehensive_voice_analysis_{culture}_{genre}_{timestamp}.json`",
          "- Link to character-profiler for voice-character fit analysis across series",
          "- Connect to market-researcher for cultural authenticity market validation",
          "- Reference theme-identifier for cultural theme integration",
          "- Support series development planning with voice evolution guidelines",
          "- Enable cultural sensitivity protocol implementation and monitoring"
        ]
      },
      "prompt_spec": {
        "expected_format": "",
        "required_parameters": [
          "- Genre specification for voice analysis",
          "- Conversation context for voice matching",
          "- Completeness level: comprehensive documentation required",
          "- Output directory path for saving analysis"
        ],
        "optional_context": []
      },
      "execution_patterns": [
        "atomic"
      ],
      "business_logic": [
        "### Input Requirements",
        "Requirements: 15 samples per voice, sentence patterns, vocabulary tiers, dialogue systems",
        "5. **Cultural Authenticity**: Regional voice pattern research and validation",
        "5. **Dialogue Differentiation**: Character type voice patterns and consistency rules",
        "## Implementation Process"
      ],
      "violations": [],
      "division_of_labor": {
        "responsibility": "",
        "delegation_pattern": "",
        "coordination_role": "",
        "execution_role": ""
      },
      "orphan_patterns": [
        "missing_error_handling",
        "malformed_tools_config"
      ]
    }
  ],
  "summary": {
    "system_health": "issues_detected",
    "architecture_compliance": 94.2,
    "avg_component_size": 239.57971014492753,
    "orphan_detection_rate": 2.0434782608695654
  }
}